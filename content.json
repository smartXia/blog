{"meta":{"title":"Some","subtitle":"https://smartxia.github.io/blog","description":"以地事秦 犹抱薪救火 薪不尽 火不灭","author":"夏夏天","url":"https://smartxia.github.io/blog","root":"/blog/"},"pages":[{"title":"about","date":"2019-12-17T08:04:45.000Z","updated":"2024-03-12T03:55:12.919Z","comments":false,"path":"about/index.html","permalink":"https://smartxia.github.io/blog/about/index.html","excerpt":"","text":"关于我自己"},{"title":"","date":"2024-03-12T03:55:12.920Z","updated":"2024-03-12T03:55:12.920Z","comments":true,"path":"book/02Go语言的设计哲学之一简单慕课专栏.html","permalink":"https://smartxia.github.io/blog/book/02Go%E8%AF%AD%E8%A8%80%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%93%B2%E5%AD%A6%E4%B9%8B%E4%B8%80%E7%AE%80%E5%8D%95%E6%85%95%E8%AF%BE%E4%B8%93%E6%A0%8F.html","excerpt":"","text":"02 Go语言的设计哲学之一：简单-慕课专栏 02 Go语言的设计哲学之一：简单 更新时间：2020-09-08 09:34:45 一个人追求的目标越高，他的才力就发展得越快，对社会就越有益。——高尔基 Go 语言从诞生那一刻到今天已经有十年多了，Go 语言的魅力使得其在全世界范围内拥有了百万级的拥趸1。那究竟是什么让大量的开发人员学习 Go 或从其他语言转向 Go 语言呢？笔者认为 Go 魅力的根源就来自于 Go 语言的设计哲学。 关于 Go 语言的设计哲学，Go 语言之父们以及 Go 核心团队的开发者们并没有给出明确的官方说法。但在这里我将根据我个人对他们以及 Go 社区主流观点和代码行为的整理、分析和总结，列出四条 Go 语言的设计哲学。理解这些设计哲学将对读者形成 Go 原生编程思维、编写高质量 Go 代码起到积极的影响。 第一条原则: 追求简单，少即是多 简单是一种伟大的美德，但我们需要更艰苦地努力才能实现它，并需要经过一个教育的过程才能去欣赏和领会它。但糟糕的是：复杂的东西似乎更有市场。- 图灵奖获得者迪杰·斯特拉(1984) 通常当我们向 Gopher 们提出这样一个问题：“你为什么喜欢 Go 语言”后，我们会得到很多种答案，诸如： 编译速度快 执行速度快 单一二进制文件，部署简单 好棒的工具集 自带的标准库超级强大 内置并发 interface 很棒 跨平台 Easy … … 图1-2-1 Gopher喜欢Go的原因 但在我们得到的众多答案中：排名靠前而又占据多数的总是“Go 很简单”，这也和官方 Go 语言调查的结果是一致的。 图1-2-2 Go语言2016年调查结果节选[^2] 和那些通过相互借鉴而不断增加新特性来吸引程序员眼球的主流编程语言相比，比如 C++、Java 等，Go 的设计者们在语言设计之初就选择拒绝走语言特性融合的道路，选择了“做减法”，选择了“简单”，他们把复杂性留给了语言自身的设计和实现，留给了 Go 核心开发组自身，而将简单、易用和清晰留给了广大 gopher 们。因此，今天呈现在我们在眼前的是这样一门 Go 语言： 简洁、常规的语法（不需要解析符号表)，它仅有 25 个关键字 内置垃圾收集，降低开发人员内存管理的心智负担 没有头文件 显式依赖（package) 没有循环依赖（package） 常量只是数字 头母大小写决定可见性 任何类型都可以拥有方法（没有类） 没有子类型继承（没有子类） 没有算术转换 接口是隐式的（无需“implements”声明） 方法就是函数 接口只是方法集合（没有数据） 方法仅按名称匹配（不是按类型） 没有构造函数或析构函数 n++和 n–是语句，而不是表达式 没有++n 和–n 赋值不是表达式 在赋值和函数调用中定义的求值顺序（无“序列点”概念） 没有指针算术 内存总是初始化为零值 没有 const 或其他类型注解语法 没有模板/泛型 没有异常(exception) 内置字符串、切片(slice)、字典(map)类型 内置数组边界检查 内置并发支持 … … 任何的设计都存在着权衡与折中（tradeoff）。我们看到 Go 设计者选择的“简单”体现在站在巨人肩膀上去除或优化了以往语言中已被开发者证明为体验不好或难于驾驭的语法元素和语言机制，并提出了自己的一些创新性的设计（比如：头母大小写决定可见性、内存分配初始零值、内置以 go 关键字实现的并发支持等）。并且 Go 设计者推崇“最小方式”思维，即一个事情仅有一种方式或数量尽可能少的方式去完成，这大大减少了开发人员在路径方式选择上以及理解其他人所选择路径方式上的心智负担。 正如 Rob Pike 所说的那样：“Go 语言实际上是复杂的，但只是让大家感觉很简单”。这句话背后的深意就是“简单”选择的背后则是 Go 语言自身实现层面的复杂，而这些复杂性被 Go 语言的设计者“隐藏”起来了，就比如我们通过一个简单的关键字“go”就可以搞定并发，这种简单的背后其实是 Go 团队缜密设计和持续付出的结果。 此外，Go 的简单哲学还体现在 Go1 兼容性2的提出。对于面对工程问题解决的开发人员来说，Go1 大大降低了工程层面上语言版本升级所带来的消耗，让 Go 的工程实践变得格外简单。 Go1兼容性说明摘录 Go1定义了两件事：第一，语言的规范; 第二，一组核心API的规范，即Go标准库的“标准包”。Go1的发布包括两个编译器套件gc和gccgo，以及核心库本身。 编写符合Go1规范的程序将在该规范的生命周期内继续得到正确编译和运行。在某个不确定的点上，可能会出现Go2规范，但在那之前，在Go1的未来版本（Go 1.1，Go 1.2等）下，今天工作的Go程序仍应该继续正常工作。 兼容性体现在源码级别上。版本之间无法保证已编译软件包的二进制兼容性。Go语言新版本发布后，源码需要使用新版本Go重新编译和链接。 API可能会增长，增加新的包和功能，但不会以破坏现有Go1代码的方式进行。 从 Go 1.0 发布至今，Go1 兼容性始终被很好地遵守着，当初使用 Go 1.4 编写的代码如今也可以顺利地通过最新的 Go 1.14 版本的编译并正常运行起来。 就像前面引用的图灵奖获得者迪杰·斯特拉的名言所说的那样，这种创新性的“简单”设计并不是一开始就能得到程序员的理解的，但在真正使用 Go 之后，这种身处设计哲学层面的“简单”便延伸到 Go 语言编程应用的方方面面，持续影响着 Go 语言编程思维的形成。 在 Go 演化进入关键阶段（走向 Go23)的今天，有人曾经向 Go 核心团队提出这样一个问题：Go 后续演化的最大难点是什么？Go 的一名核心团队成员回答道：“最大的难题是如何能继续保持 Go 语言的简单”。 Russ Cox 《How Many Go Developers Are There?》https://research.swtch.com/gophercount ↩︎ Go1 兼容性 https://golang.org/doc/go1compat ↩︎ 走向 Go2 https://blog.golang.org/toward-go2 ↩︎ } 01 Go 语言的前生今世 03 Go 语言的设计哲学之二：组合 扫码加入慕课前沿技术核心用户群 验证信息：2010312025386365复制 QQ讨论群号：729941811 QQ群URL：点击访问 若遇到搜索不到QQ群或加群失败，请联系客服邮箱:kf@imooc.com"},{"title":"","date":"2024-03-12T03:55:12.920Z","updated":"2024-03-12T03:55:12.920Z","comments":true,"path":"book/01Go语言的前生今世慕课专栏.html","permalink":"https://smartxia.github.io/blog/book/01Go%E8%AF%AD%E8%A8%80%E7%9A%84%E5%89%8D%E7%94%9F%E4%BB%8A%E4%B8%96%E6%85%95%E8%AF%BE%E4%B8%93%E6%A0%8F.html","excerpt":"","text":"01 Go 语言的前生今世-慕课专栏 01 Go 语言的前生今世 更新时间：2020-09-08 09:34:16 我要扼住命运的咽喉，它妄想使我屈服，这绝对办不到。生活是这样美好，活他一千辈子吧！——贝多芬 1. Go 语言的诞生 2007 年 9 月 20 日的下午，在谷歌山景城总部的一间办公室里，谷歌的大佬级程序员 Rob Pike1在等待一个 C++ 项目构建的过程中和谷歌的另外两个大佬级程序员 Robert Griesemer2和 Ken Thompson3进行了一次有关设计一门新编程语言的讨论4。 图1-1-1 Go语言之父(从左到右分别是Robert Griesemer、Rob Pike和Ken Thompson) 当时的谷歌内部主要使用 C++ 语言构建各种系统，但 C++ 的巨大复杂性、编译构建速度慢以及在编写服务端程序时对并发支持的不便等让三位大佬产生了重新设计一门新编程语言的想法。在他们的初步构想中，这门新语言应该是能够给程序员带来快乐、匹配未来硬件发展趋势并适合用来开发谷歌内部大规模程序的。 趁热打铁！在第一天的简短讨论后，第二天这三位大佬又在总部的一间名为 Yaounde 的会议室里进行了一场有关这门新语言具体设计的会议。会后的第二天，Robert Griesemer 发出了一封题为“prog lang discussion”的电邮，这封电邮便成为了这门新语言的第一版设计稿，三位大佬在这门语言的一些基础语法特性上达成了初步一致。 9 月 25 日，Rob Pike 在一封回复电邮中把这门新编程语言命名为 Go： Subject: Re: prog lang discussion From: Rob 'Commander' Pike Date: Tue, Sep 25, 2007 at 3:12 PM To: Robert Griesemer, Ken Thompson i had a couple of thoughts on the drive home. 1. name 'go'. you can invent reasons for this name but it has nice properties. it's short, easy to type. tools: goc, gol, goa. if there's an interactive debugger/interpreter it could just be called 'go'. the suffix is .go ... 2. Go 语言的早期团队和演化历程 经过早期讨论，三位 Go 作者在语言设计上达成初步一致后，便开启了 Go 语言迭代设计和实现的过程。 2008 年初，Unix 之父 Ken Thompson 实现了第一版 Go 编译器，用于验证之前的设计。这个编译器先将 Go 代码转换为 C 代码，再由 C 编译器编译成二进制文件。 到 2008 年中旬，Go 的第一版设计基本结束了。这时，同样在谷歌工作的 Ian Lance Taylor 给 Go 语言的三位作者发了一封电子邮件。他宣称为 Go 语言实现了一个 gcc 的前端，这也是 Go 语言的第二个编译器。 Subject: A gcc frontend for Go From: Ian Lance Taylor Date: Sat, Jun 7, 2008 at 7:06 PM To: Robert Griesemer, Rob Pike, Ken Thompson One of my office-mates pointed me at http://.../go_lang.html . It seems like an interesting language, and I threw together a gcc frontend for it. It's missing a lot of features, of course, but it does compile the prime sieve code on the web page. 随后，Ian Lance Taylor 正式加入 Go 语言开发团队，并在后面的 Go 语言发展演进进程中成为了 Go 语言及工具设计和实现的核心人物之一。Russ Cox 也是在 2008 年加入到刚成立不久的 Go 语言开发团队的。随着他的加入，他的一些天赋也随即在语言设计和实现中展现出来，比如io.Reader和io.Writer接口，奠定了所有 I/O 库的整体结构。 3. Go 语言正式公布并开源 2009 年 10 月 30 日，Rob Pike 在 Google Techtalk 上做了一次有关 Go 语言的演讲《The Go Programming Language》，这也是 Go 语言第一次公之于众。 Go 语言项目在 2009 年 11 月 10 日正式开源，之后这一天被官方定位 Go 语言的诞辰。最初 Go 语言项目托管在 code.google.com 上，几年后迁移至 GitHub。 随着 Go 语言的开源，Go 语言吸引了全世界开发者的目光。再加上 Go 三位作者在业界的影响力以及谷歌这座大树的加持，更多有才华的程序员加入到 Go 开发团队中，更多贡献者开始为 Go 语言项目添砖加瓦。于是，Go 在发布的当年(2009 年)就成为了著名编程语言排行榜 TIOBE 的年度最佳编程语言。 Go 发布后就吸引了一些公司，尤其是云计算领域的初创公司成为了 Go 语言的早期接纳者。在经过若干年的磨合后，在这些公司中诞生了不乏像 Docker、Kubernetes 这样的“杀手级”或示范性项目，这些项目也让 Go 被誉为“云计算基础设施新兴语言”或直接称为云计算语言。 在发布后，Go 语言也拥有了自己的“吉祥物” - 一只由 Rob Pike 夫人Renee French设计的地鼠，从此地鼠称为了世界各地 Go 程序员的象征。Go 程序员也被称为 Gopher，Go 语言官方技术大会也被称为 GopherCon。 图1-1-2 Go语言吉祥物 4. Go 语言的版本 和绝大多数编程语言相似，Go 语言也是“站在巨人的肩膀上的”，正如下图所示，Go 继承了诸多编程语言的特性。 图1-1-3 Go的先祖 Go 的基本语法参考了 C 语言，是“C 家族语言”的一个分支；而 Go 的声明语法、包概念则受到了 Pascal/Modula/Oberon 的启发；一些并发的思想则来自于受到了 Tony Hoare 教授 CSP 理论影响的语言，比如：Newsqueak 和 Limbo。 2009 年 11 月 10 日，Go 语言正式对外发布并开源。之后，Go 语言在一段时间内采用了“Weekly Release”的模式，即每周发布一个版本。目前我们在 github.com 上 golang 的官方仓库中仍能找到的早期的 Weekly Release 版本，比如：“weekly.2009-11-06”。 从 2011 年 3 月 7 日开始，除了 Weekly Release，Go 项目还会每月发布一个 Release，即 Monthly Release，比如：release.r56，这种情况一直延续到 Go 1.0 版本发布之前； 2012 年 3 月 28 日，Go 1.0 正式发布。同时 Go 官方发布 Go1 兼容性承诺：只要符合 Go1 语言规范的源代码，Go 编译器将保证向后兼容； 2013 年 5 月 13 日，Go 1.1 版本发布。主要的变动点包括： 新增\"method value\"语法：允许将方法绑定到一个特定的 receiver 实例上，从而形成一个 function； 引入\"terminating statement\"的概念； 将 64 位平台上的 int 类型的字节数升为 8 个字节，即 64 bits； 更为精确的 Heap GC，尤其是针对 32 位平台。 2013 年 12 月 1 日，Go 1.2 版本发布。从 Go 1.2 开始，Go 开发组启动了“以每 6 个月为一个发布周期”的发布计划。Go 1.2 版本主要的变动点包括： 增加 Full slice expression: a[low : high : max]; 实现抢占式 Goroutine 调度器； go test 新增-cover 标志用于计算测试覆盖率。 2014 年 6 月 18 日，Go 1.3 版本发布。主要的变动点包括： 支持更多平台：solaris,dragonfly,plan9,nacl 等； goroutine 的 stack 模型从”segmented“ model 改为了“contiguous” model，改善“Hot stack split”问题； 更为精确的 Stack GC。 2014 年 12 月 10 日，Go 1.4 版本发布。Go 1.4 也是最后一个编译器和 runtime 由 C 语言实现的版本。其主要的变动点包括： 新增 for range x {…}形式的 for-range 语法； 使用 Go 语言替换 runtime 的部分 C 语言实现，这使得 GC 变得全面精确； 由于 contiguous stack 的应用，goroutine 的默认栈大小从 8k 减小为 2k； 增加 internal package 机制； 增加\"canonical import path\"机制； 新增 go generate 子命令； 删除 Go source 树中的 src/pkg/xxx 中 pkg 这一级别，直接使用 src/xxx。 2015 年 8 月 19 日，Go 1.5 版本发布，Go 1.5 版本是一个里程碑式的重要版本。因为从这个版本开始，Go 实现了自举，即无需再依赖 C 编译器。但 Go 编译器的性能照比 Go 1.4 的 C 实现有了较大幅度的下降。其主要的变动点包括： Go 编译器和 runtime 使用 Go 全部重写，原先的 C 实现被彻底移除； 跨平台编译 Go 程序更为简洁，只需设置两个环境变量即可：GOARCH 和 GOOS； 支持 map literal; GOMAXPROCS 的初始默认值由 1 改为了运行环境的 CPU 核数； 大幅度优化 GC 延迟，多数情况 GC \"Stop The World\"的时间低于 10ms； 增加 vendor 机制，改善 Go 包依赖管理； 增加 go tool trace 子命令； go build 增加-buildmode 命令选项，支持将 Go 代码编译为 shared library 形式。 2016 年 2 月 17 日，Go 1.6 版本发布。主要的变动点包括： 进一步优化 GC 延迟，实现 Go 程序在占用大内存的情况下，GC 延迟仍低于 10ms； 自动支持 HTTP/2； 定义了在 C 代码中共享 Go 指针的规则。 2016 年 8 月 15 日，Go 1.7 版本发布。主要的变动点包括： 针对 x86-64，实现了 SSA 后端，使得编译出的 binary file size 减少 20%~30%；运行效率提升 5%~35%； Go 编译器的性能比 Go 1.6 版本提升近一倍； go test 支持 subtests 和 sub-benchmarks； 标准库新增 context 包。 2017 年 2 月 16 日，Go 1.8 版本发布。主要的变动点包括： 支持仅 tags 不同的两个 struct 可以相互做显式类型转换； 标准库增加 sort.Slice 函数； 支持 HTTP/2 Push 机制； 支持支持 HTTP Server 优雅退出； 增加了对 Mutex 和 RWMutex 的 profiling(剖析)支持； 支持 Go plugins，增加 plugin 包； 支持默认的 GOPATH 路径，无需再显式设置； 进一步优化 SSA 后端代码，程序平均性能提升 10%左右； Go 编译器性能进一步提升，平均编译链接的性能提升幅度在 15%左右； GC 的延迟进一步降低，STW(Stop The World)的时间通常将低于 100 微秒，甚至经常低于 10 微秒。 优化 defer 的实现，使得其性能损耗降低了一半。 2017 年 8 月 25 日，Go 1.9 版本发布。主要的变动点包括： 新增了 type alias 语法； 在原先的支持包级别的并发编译的基础上又实现了包函数级别的并发编译，使得 Go 编译性能有 10%左右的提升; 大内存对象分配性能得到显著提升； 增加了对 monotonic clock 的支持； 提供了一个支持并发的 Map 类型：sync.Map； 增加 math/bits 包，将高性能位操作实现收入标准库。 2018 年 2 月 17 日，Go 1.10 版本发布。主要的变动点包括： 支持默认 GOROOT，开发者无需显式设置 GOROOT 环境变量； 增加 GOTMPDIR 环境变量； 通过 cache 大幅提升构建和 go test 执行的性能，并基于源文件内容是否变化判定是否使用 cache 结果； 支持 Unicode 10.0 版本。 2018 年 8 月 25 日，Go 1.11 版本发布。Go 1.11是Russ Cox在GopherCon 2017 大会上发表 \"Toward Go2\"之后的第一个 Go 版本，新的 Go 包管理机制 go modules 在 Go 1.11 中的落地为后续“Go2”的提议渐进落地奠定了良好的基础。该版本主要的变动点包括： 引入 Go module，为 Go 包管理提供了创新性的解决方案； 引入对 WebAssembly 的支持，让 Gopher 可以使用 Go 语言来开发前端 Web 应用； 为调试器增加了一个新的实验功能：允许在调试过程中动态调用 Go 函数。 2019 年 2 月 25 日，Go 1.12 版本发布。主要的变动点包括： 对 Go 1.11 中增加的 go modules 机制做了进一步优化； 增加对 TLS 1.3 的支持； 优化了大量 heap 依然存在时 GC 清理环节的性能，使得一次 GC 后的内存分配延迟得以改善； 运行时更加积极地将释放的内存归还给操作系统，以应对大块内存分配无法重用已存在的堆空间的问题； 该版本中 Build cache 成为必需。 2019 年 9 月 4 日，Go 1.13 版本发布。主要的变动点包括： 增加以 0b 或 0B 开头的二进制数字字面量形式，如：0b111； 增加以\"0o\"或\"0O\"开头的八进制数字字面量形式，如：0o700； 增加以 0x 或 0X 开头的十六进制形式的浮点数字面量，如：0x123.86p+2； 支持在数字字面量中通过数字分隔符\"_\"提高可读性，如：a := 5_3_7等； 取消了移位操作(&gt;&gt;和&lt;&lt;)的右操作数仅能是无符号数的限制； 继续对 Go module 机制进行优化，包括：当GO111MODULE=auto时，无论是在$GOPATH/src 下还是 GOPATH 之外的仓库中&gt;，只要目录下有 go.mod，Go 编译器都会使用 go module 来管理依赖；GOPROXY 支持配置多个代理，默认值为https://proxy.golang.org,direct；提供了 GOPRIVATE 变量，用于指示哪些仓库下的 module 是私有的，即不需要通过 GOPROXY 下载，也不需要通过 GOSUMDB 去验证其校验和； Go 错误处理改善：在标准库中增加 errors.Is 和 As 函数来解决 error value 的比较判定问题；增加 errors.Unwrap 函数来解决 error 的展开(unwrap)问题； defer 性能提升 30%； 支持的 unicode 标准从 10.0 版本升级到Unicode 11.0 版本。 2020 年 2 月 26 日，Go 1.14 版本发布。主要的变动点包括： 支持嵌入接口的方法集可重叠； 支持 goroutine 的异步抢占式调度； defer 性能得到大幅优化，理论上可实现 30%的提升； 重新实现了运行时(runtime)层的 timer； go module 可应用于生产环境； 标准库 testing 包增加Cleanup方法用于实现测试执行后的清理工作。 Go 团队发布的 Go 语言稳定版本总体质量一直很高，少有影响使用的重大 bug。Go 团队一直建议大家使用最新的发布版。Google 的产品，比如 Google App Engine（以下简称为 GAE），向来是这方面的“急先锋” —— 一般在 Go 新版本发布不久后，GAE 便会宣布支持最新版本的 Go。 Go 团队每年发布两次大版本，一般是在二月份和八月份发布。Go 团队对最新的两个 Go 稳定版本提供支持，比如如果目前最新版本是 Go 1.14，那么 Go 团队会为 Go 1.14 和 Go 1.13 提供支持。如果 Go 1.15 版本发布，支持的版本将变成 Go 1.15 和 Go 1.14。支持的范围主要包括修复版本中存在的重大问题、仅文档变更以及安全问题更新。 5. 小结 了解一门编程语言的诞生历史和早期演化史，有助于程序员在学习这门语言的同时产生或加深对语言的认同感。程序员能感同身受，从而能更加有热情的投入到这门语言的学习和使用当中。同时这种认同感也能积极推动程序员在后续的实践中形成语言的原生思维（比如：Go 语言思维），从而更加高效地利用这门语言进行编程，解决实际问题。 同时，了解 Go 版本的发布历史以及不同版本的主要变动点，将有助于程序员根据自身的实际情况选择最为适合的 Go 版本。 Rob Pike（罗伯·派克），早期贝尔实验室成员，参与了 Plan9 操作系统、C 编译器以及多种语言编译器的设计和实现，UTF-8 发明人之一。 ↩︎ Robert Griesemer（罗伯特·格瑞史莫），Java 的 HotSpot 虚拟机和 Chrome 浏览器的 JavaScript V8 引擎的设计者之一。 ↩︎ Ken Thompson（肯·汤普逊），图灵奖得主、Unix 之父以及 C 语言的发明人之一。 ↩︎ “少即是多” - https://commandcenter.blogspot.com/2012/06/less-is-exponentially-more.html ↩︎ } 02 Go语言的设计哲学之一：简单 扫码加入慕课前沿技术核心用户群 验证信息：2010312025386365复制 QQ讨论群号：729941811 QQ群URL：点击访问 若遇到搜索不到QQ群或加群失败，请联系客服邮箱:kf@imooc.com"},{"title":"","date":"2024-03-12T03:55:12.922Z","updated":"2024-03-12T03:55:12.922Z","comments":true,"path":"book/03Go语言的设计哲学之二组合慕课专栏.html","permalink":"https://smartxia.github.io/blog/book/03Go%E8%AF%AD%E8%A8%80%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%93%B2%E5%AD%A6%E4%B9%8B%E4%BA%8C%E7%BB%84%E5%90%88%E6%85%95%E8%AF%BE%E4%B8%93%E6%A0%8F.html","excerpt":"","text":"03 Go 语言的设计哲学之二：组合-慕课专栏 03 Go 语言的设计哲学之二：组合 更新时间：2020-09-08 09:34:57 没有引发任何行动的思想都不是思想，而是梦想。 —— 马丁 第二条原则: 偏好组合，正交解耦 当我们有必要采用另外一种方式处理数据时，我们应该有一些耦合程序的方式，就像花园里将浇水的软管通过预置的螺丝扣拧入另一段那样，这也是 Unix IO 采用的方式。- 道格·麦克罗伊，Unix 管道的发明者(1964) C++、Java 等主流面向对象（以下简称 OO）语言通过庞大的、自上而下的类型体系、继承、显式接口实现等机制将程序的各个部分耦合起来，但在 Go 语言中我们找不到经典 OO 的语法元素、类型体系和继承机制，或者说 Go 语言本质上就不属于经典 OO 语言范畴。针对这种情况，很多人会问：那 Go 语言是如何将程序的各个部分有机地耦合在一起的呢？就像上面引述的道格.麦克罗伊的那句话中的浇水软管那样，Go 语言遵从的设计哲学也是组合。 在诠释组合之前，我们可以先来了解一下 Go 在语法元素设计时是如何为组合哲学的应用奠定基础的。 在 Go 语言设计层面，Go 设计者为 gopher 们提供了正交的语法元素供后续组合使用，包括： Go 语言无类型体系(type hierarchy)，类型之间是独立的，没有子类型的概念； 每个类型都可以有自己的方法集合，类型定义与方法实现是正交独立的； 接口(interface)与其实现之间\"隐式关联\"； 包(package)之间是相对独立的，没有子包的概念。 我们看到无论是包、接口还是一个个具体的类型定义(包括类型的方法集合)，Go 语言为我们呈现了这样的一幅图景：一座座没有关联的“孤岛”，但每个岛内又都很精彩。现在摆在面前的工作就是在这些孤岛之间以最适当的方式建立关联（耦合），形成一个\"整体\"。Go 采用了组合的方式，也是唯一的方式。 Go 语言提供了的最为直观的组合的语法元素就是type embedding，即类型嵌入。通过类型嵌入，我们可以将已经实现的功能嵌入到新类型中，以快速满足新类型的功能需求，这种方式有些类似经典 OO 的“继承”，但在原理上与经典 OO 的继承完全不同。这是一种 Go 精心设计的“语法糖”，被嵌入的类型和新类型两者之间没有任何关系，甚至相互完全不知道对方的存在，更没有经典 OO 那种父类、子类的关系以及向上、向下转型(type casting)。通过新类型实例调用方法时，方法的匹配取决于方法名字，而不是类型。这种组合方式，我称之为“垂直组合”，即通过类型嵌入，快速让一个新类型“复用”其他类型已经实现的能力，实现功能的垂直扩展。 下面是一个类型嵌入的例子： // Go标准库：sync/pool.go type poolLocal struct &#123; private interface&#123;&#125; // Can be used only by the respective P. shared []interface&#123;&#125; // Can be used by any P. Mutex // Protects shared. pad [128]byte // Prevents false sharing. &#125; 我们在 poolLocal 这个 struct 中嵌入类型 Mutex，被嵌入的 Mutex 类型的方法集合会被提升到外面的类型中。比如，这里的 poolLocal 将拥有 Mutex 类型的 Lock 和 Unlock 方法。实际调用时，方法调用实际会被传给 poolLocal 中的 Mutex 实例。 我们在标准库中还经常看到类似如下的 interface 类型嵌入的代码： type ReadWriter interface &#123; Reader Writer &#125; 通过在 interface 中嵌入 interface type，实现接口行为的聚合，组成大接口，这种方式在标准库中尤为常用，并且已经成为了 Go 语言的一种常见的惯用法。 interface 是 Go 语言中真正的魔法，是 Go 语言的一个创新设计，它只是方法集合，并且它与实现者之间的关系是隐式的，它让程序内部各部分之间的耦合降至最低，同时它也是连接程序各个部分之间“纽带”。隐式的 interface 实现会不经意间满足：依赖抽象、里氏替换、接口隔离等原则，这在其他语言中是需要很\"刻意\"的设计谋划才能实现的，但在 Go interface 来看，一切却是自然而然的。 通过 interface 将程序内部各个部分组合在一起的方法，我这里称之为水平组合。水平组合的“模式”很多，比如：一种常见方法就是：通过接受 interface 类型参数的普通函数进行组合，例如下面代码。 func ReadAll(r io.Reader) ([]byte, error) func Copy(dst Writer, src Reader) (written int64, err error) ReadAll 通过 io.Reader 这个接口将 io.Reader 的实现与 ReadAll 所在的包低耦合的水平组合在一起了。类似的水平组合“模式”还有 wrapper、middleware 等，这里就不展开了，在后面讲到 interface 时再详细叙述。 此外，Go 语言内置的并发能力也可以通过组合的方式实现“对计算能力的串联”，比如：通过 goroutine+channel 的组合实现类似 Unix Pipe 的能力。 综上，组合原则的应用塑造了 Go 程序的骨架结构。类型嵌入为类型提供的垂直扩展能力，interface 是水平组合的关键，它好比程序肌体上的“关节”，给予连接“关节”的两个部分各自“自由活动”的能力，而整体上又实现了某种功能。组合也让遵循“简单”原则的 Go 语言的表现力丝毫不逊色于其他复杂的主流编程语言。 } 02 Go语言的设计哲学之一：简单 04 Go语言的设计哲学之三：并发 扫码加入慕课前沿技术核心用户群 验证信息：2010312025386365复制 QQ讨论群号：729941811 QQ群URL：点击访问 若遇到搜索不到QQ群或加群失败，请联系客服邮箱:kf@imooc.com"},{"title":"","date":"2024-03-12T03:55:12.922Z","updated":"2024-03-12T03:55:12.922Z","comments":true,"path":"book/04Go语言的设计哲学之三并发慕课专栏.html","permalink":"https://smartxia.github.io/blog/book/04Go%E8%AF%AD%E8%A8%80%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%93%B2%E5%AD%A6%E4%B9%8B%E4%B8%89%E5%B9%B6%E5%8F%91%E6%85%95%E8%AF%BE%E4%B8%93%E6%A0%8F.html","excerpt":"","text":"04 Go语言的设计哲学之三：并发-慕课专栏 04 Go语言的设计哲学之三：并发 更新时间：2020-09-16 10:09:30 知识是一种快乐，而好奇则是知识的萌芽。——培根 第三条原则: 原生并发，轻量高效 并发(Concurrency)是有关结构的，而并行(Parallelism)是有关执行的 - Rob Pike(2012) 将时钟指针回拨到 2007 年，那时 Go 语言三位设计者 Rob Pike、Robert Griesemer 和 Ken Thompson 都在 Google 使用 C++语言编写服务端代码。当时 C++ 标准委员会正在讨论下一个 C++ 标准（C++0x，也就是后来的 C++11 标准），委员会在标准草案中继续增加大量语言特性的行为让 Go 的三位设计者十分不满，尤其是带有原子类型的新 C++ 内存模型，给本已负担过重的 C++类型系统又增加了额外负担。三位设计者认为 C++ 标准委员会在思路上是短视的，因为硬件很可能在未来十年内发生重大变化，将语言与当时的硬件紧密耦合起来是十分不明智的，是没法给开发人员在编写大规模并发程序时带去太多帮助的。 多年来，处理器生产厂商一直在摩尔定律的指导下，在提高时钟频率这条跑道上竞争，各行业对计算能力的需求推动了处理器处理能力的提高。CPU 的功耗和节能问题，愈来愈成为人们关注的一个焦点，CPU 仅靠提高主频来改进性能的做法遇到了瓶颈，由于主频提高导致 CPU 的功耗和发热量剧增，反过来制约了 CPU 性能的进一步提高。依靠主频的提高带来性能的提升已无法实现，人们开始把研究重点转向通过把多个执行内核放进一个处理器，每个内核在较低的频率下工作来降低功耗同时提高性能。 2007 年处理器领域已开始进入一个全新的多核时代，处理器厂商的竞争焦点从主频转向了多核，多核设计也为摩尔定律带去了新的生命力。与传统的单核 CPU 相比，多核 CPU 带来了更强的并行处理能力、更高的计算密度和更低的时钟频率，并大大减少了散热和功耗。Go 的设计者敏锐地把握了 CPU 向多核方向发展的这一趋势，在决定不再使用 C++ 而去创建一门新语言的时候，果断将面向多核、原生内置并发支持作为了新语言的设计原则之一。 Go 语言原生并发原则的落地是映射到几个层面上的。 1) Go 语言自身实现层面支持面向多核硬件的并发执行和调度 提到并发执行与调度，我们首先想到的就是操作系统对进程、线程的调度。操作系统调度器会将系统中的多个线程按照一定算法调度到物理 CPU 上去运行。传统的编程语言比如 C、C++ 等的并发实现实际上就是基于操作系统调度的，即程序负责创建线程（一般通过 pthread 等函数库调用实现），操作系统负责调度。这种传统支持并发的方式有诸多不足： 复杂 创建容易，退出难：使用 C 语言的开发人员都知道，创建一个 thread（比如利用 pthread）虽然参数也不少，但好歹可以接受。但一旦涉及到 thread 的退出，就要考虑 thread 是 detached，还是需要 parent thread 去 join？是否需要在 thread 中设置 cancel point，以保证 join 时能顺利退出？ 并发单元间通信困难，易错：多个 thread 之间的通信虽然有多种机制可选，但用起来是相当复杂；并且一旦涉及到 shared memory，就会用到各种 lock，死锁便成为家常便饭； thread stack size 的设定：是使用默认的，还是设置的大一些，或者小一些呢？ 难于扩展 一个 thread 的代价已经比进程小了很多了，但我们依然不能大量创建 thread，因为除了每个 thread 占用的资源不小之外，操作系统调度切换 thread 的代价也不小； 对于很多网络服务程序，由于不能大量创建 thread，就要在少量 thread 里做网络多路复用，即：使用 epoll/kqueue/IoCompletionPort 这套机制，即便有 libevent、libev 这样的第三方库帮忙，写起这样的程序也是很不易的，存在大量 callback，给程序员带来不小的心智负担。 为此，Go 采用了用户层轻量级 thread或者说是类 coroutine的概念来解决这些问题，Go 将之称为\"goroutine\"。goroutine 占用的资源非常小，每个 goroutine stack 的 size 默认设置是 2k，goroutine 调度的切换也不用陷入（trap）操作系统内核层完成，代价很低。因此，一个 Go 程序中可以创建成千上万个并发的 goroutine。所有的 Go 代码都在 goroutine 中执行，哪怕是 go 的 runtime 也不例外。将这些 goroutines 按照一定算法放到“CPU”上执行的程序就称为goroutine 调度器或goroutine scheduler。 不过，一个 Go 程序对于操作系统来说只是一个用户层程序，对于操作系统而言，它的眼中只有 thread，它甚至不知道有什么叫 Goroutine 的东西的存在。goroutine 的调度全要靠 Go 自己完成，实现 Go 程序内 goroutine 之间“公平”的竞争“CPU”资源，这个任务就落到了 Go runtime 头上。 Go 语言实现了G-P-M 调度模型和 work stealing 算法，这个模型一直沿用至今，如下图所示： 图1-4-1 Goroutine调度原理模型 G：表示 goroutine，存储了 goroutine 的执行 stack 信息、goroutine 状态以及 goroutine 的任务函数等；另外 G 对象是可以重用的。 P：表示逻辑 processor，P 的数量决定了系统内最大可并行的 G 的数量（前提：系统的物理 cpu 核数&gt;=P 的数量）；P 的最大作用还是其拥有的各种 G 对象队列、链表、一些 cache 和状态。每个 G 要想真正运行起来，首先需要被分配一个 P（进入到 P 的 local runq 中）。对于 G 来说，P 就是运行它的“CPU”，可以说：G 的眼里只有 P。 M：M 代表着真正的执行计算资源，一般对应的是操作系统的线程。从 Goroutine 调度器的视角来看，真正的“CPU”是 M，只有将 P 和 M 绑定才能让 P 的 runq 中 G 得以真实运行起来。这样的 P 与 M 的关系，就好比 Linux 操作系统调度层面用户线程（user thread）与核心线程（kernel thread）的对应关系那样（N x M）。M 在绑定有效的 P 后，进入 schedule 循环；而 schedule 循环的机制大致是从各种队列、p 的本地队列中获取 G，切换到 G 的执行栈上并执行 G 的函数，调用 goexit 做清理工作并回到 m，如此反复。M 并不保留 G 状态，这是 G 可以跨 M 调度的基础。 2) Go 语言为开发者提供的支持并发的语法元素和机制 我们先来看看那些设计并诞生于单核年代的编程语言，诸如：C、C++、Java 在语法元素和机制层面是如何支持并发的。 执行单元：线程； 创建和销毁的方式：调用库函数或调用对象方法； 并发线程间的通信：多基于操作系统提供的 IPC 机制，比如：共享内存、Socket、Pipe 等，当然也会使用有并发保护的全局变量。 和上述传统语言相比，Go 为开发人员提供了语言层面内置的并发语法元素和机制： 执行单元：goroutine； 创建和销毁方式：go+函数调用；函数退出即 goroutine 退出； 并发 goroutine 的通信：通过语言内置的 channel 传递消息或实现同步，并通过 select 实现多路 channel 的并发控制。 对比来看，Go 对并发的原生支持将大大降低开发人员在开发并发程序时的心智负担。 3) 并发原则对 Go 开发者在程序结构设计层面的影响 由于 goroutine 的开销很小（相对线程），Go 官方是鼓励大家使用 goroutine 来充分利用多核资源的。但并不是有了 goroutine 就一定能充分的利用多核资源，或者说即便使用 Go 也不一定能设计编写出一个好的并发程序。 为此 Rob Pike 曾有过一次关于“并发不是并行”1的主题分享，在那次分享中，这位 Go 语言之父图文并茂地讲解了并发（Concurrency）和并行（Parallelism）的区别。Rob Pike 认为： 并发是有关结构的，它是一种将一个程序分解成小片段并且每个小片段都可以独立执行的程序设计方法; 并发程序的小片段之间一般存在通信联系并且通过通信相互协作； 并行是有关执行的，它表示同时进行一些计算任务 。 划重点：并发是一种程序结构设计的方法，它使得并行成为可能。不过这依然很抽象，我们这里也借用 Rob Pike 分享中的那个“搬运书问题”来重新诠释一下并发的含义。搬运书问题要求设计一个方案，使得 gopher 能更快地将一堆废弃的语言手册搬到垃圾回收场烧掉。 最简单的方案莫过于下图： 图1-4-2 搬书问题初始方案 这个方案显然不是并发设计方案，它没有对问题进行任何分解，所有事情都是由一个 gopher 从头到尾按顺序完成的。但即便这样一个并非并发的方案，我们也可以将其放到多核的硬件上并行的执行，只是需要多建立几个 gopher 例程（procedure）的实例罢了： 图1-4-3 搬书问题初始方案的并行化 但和并发方案相比，这种方案是缺乏自动扩展为并行的能力的。Rob Pike 在分享中给出了两种并发方案，也就是该问题的两种分解方案，两种方案都是正确的，只是分解粒度的细致程度不同。 图1-4-4 搬书问题并发方案1 图1-4-5 搬书问题并发方案2 并发方案 1 将原来单一的 gopher 例程执行拆分为 4 个执行不同任务的 gopher 例程，每个例程更简单： 将书搬运到车上（loadBooksToCart）； 推车到垃圾焚化地点（moveCartToIncinerator）； 将书从车上搬下送入焚化炉（unloadBookIntoIncinerator）； 将空车送返（returnEmptyCart）。 理论上并发方案 1 的处理性能能达到初始方案的四倍，并且不同 gopher 例程可以在不同的处理器核上并行执行，而无需像最初方案那样需要建立新实例实现并行。 和并发方案 1 相比，并发方案 2 增加了“暂存区域”，分解的粒度更细，每个部分的 gopher 例程各司其责，这样的程序在单核处理器上也是正常运行的（在单核上可能处理能力不如非并发方案）。但随着处理器核数的增多，并发方案可以自然地提高处理性能，提升吞吐。而非并发方案在处理器核数提升后，也仅仅能使用其中的一个核，无法自然扩展，这一切都是程序的结构所决定的。这也告诉我们：并发程序的结构设计不要局限于在单核情况下处理能力的高低，而是以在多核情况下能够充分提升多核利用率、获得性能的自然提升为最终目的。 除此之外，并发与组合的哲学是一脉相承的，并发是一个更大的组合的概念，它在程序设计的层面对程序进行拆解组合，再映射到程序执行层面上：goroutines 各自执行特定的工作，通过 channel+select 将 goroutines 组合连接起来。并发的存在鼓励程序员在程序设计时进行独立计算的分解，而对并发的原生支持让 Go 语言更适应现代计算环境。 并发不是并行 https://talks.golang.org/2012/waza.slide ↩︎ } 03 Go 语言的设计哲学之二：组合 05 Go 语言的设计哲学之四：面向工程 扫码加入慕课前沿技术核心用户群 验证信息：2010312025386365复制 QQ讨论群号：729941811 QQ群URL：点击访问 若遇到搜索不到QQ群或加群失败，请联系客服邮箱:kf@imooc.com"},{"title":"","date":"2024-03-12T03:55:12.922Z","updated":"2024-03-12T03:55:12.922Z","comments":true,"path":"book/05Go语言的设计哲学之四面向工程慕课专栏.html","permalink":"https://smartxia.github.io/blog/book/05Go%E8%AF%AD%E8%A8%80%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%93%B2%E5%AD%A6%E4%B9%8B%E5%9B%9B%E9%9D%A2%E5%90%91%E5%B7%A5%E7%A8%8B%E6%85%95%E8%AF%BE%E4%B8%93%E6%A0%8F.html","excerpt":"","text":"05 Go 语言的设计哲学之四：面向工程-慕课专栏 05 Go 语言的设计哲学之四：面向工程 更新时间：2020-09-16 09:48:21 机遇只偏爱那些有准备的头脑。——巴斯德 第四条原则: 面向工程，“自带电池” 软件工程指引着 Go 语言的设计。- Rob Pike(2012) 要想理解这条设计哲学，我们依然需要回到三位 Go 语言之父在设计 Go 语言时的初衷：**面向解决真实世界中 Google 内部大规模软件开发存在的各种问题，为这些问题提供答案。**主要的问题包括： 程序构建慢 失控的依赖管理 开发人员使用编程语言的不同子集（比如 C++支持多范式，这样有些人用 OO，有些人用泛型） 代码可理解性差（代码可读性差，文档差等) 功能重复实现 升级更新消耗大 实现自动化工具难度高 版本问题 跨语言构建问题 很多编程语言设计者或其拥趸认为这些问题并不是一门编程语言应该去解决的，但 Go 语言的设计者并不这么看，他们以更高更广阔的视角去审视软件开发领域尤其是大规模软件开发过程中遇到的各种问题，并在 Go 语言最初设计阶段就将解决工程问题作为 Go 的设计原则之一去考虑 Go 语法、工具与标准库的设计，这也是 Go 与其他偏学院派、偏研究性编程语言在设计思路上的一个重大差异。 Go 语言取得阶段性成功后，这种思路也在开始影响着后续新编程语言的设计，并且一些现有的主流编程语言也在借鉴 Go 的一些设计，比如：越来越多的语言认可统一代码风格的优越之处，并开始提供官方统一的 fmt 工具（例如：rust 的 rustfmt）；又比如：Go 创新提出的最小版本选择（minimal version selection，缩写为 mvs）也在被其他语言的包依赖工具所支持（比如：rust 的 cargo 支持 mvs）。 Go 设计者将所有工程问题浓缩为一个词\"scale\"，总觉得将 scale 这个词翻译为任何中文词汇都无法传神地表达其含义，暂译为“规模”吧。这里的规模化有两层含义： 用 Go 构建的软件系统的并发规模，比如：这类系统并发关注点的数量、处理数据的量级、同时与之交互的服务的数量等； 开发过程的规模，包括代码库大小、参与开发、相互协作的工程师的数量等。 从 Go1 开始，Go 的目标就是为了让开发者能够更容易、更高效地构建规模化（scale）的软件。Go 设计者期望 Go 可以游刃有余地应对产品规模和过程规模变大后带来的各种复杂性问题。Go 语言的演进方向也是继续优化和消除 Go 语言自身面对规模化问题时应对不好的地方，比如：Go 1.9 引入的 type alias 以应对大型代码仓库代码重构、Go 1.11 引入的 go module 机制解决不完善的包依赖问题等。 这种设计哲学的落地让 Go 语言具有广泛的规模适应性：既可以被仅有 5 人的初创团队用于开发终端工具，也能够满足像 Google 这样的超巨型公司大规模团队开发大规模网络服务程序的需要。 那么 Go 是如何解决工程领域规模化所带来的问题的呢？我们从语言、标准库和工具三个方面来看一下。 1) 语言 语法是编程语言的用户接口，它直接影响开发人员对于这门语言的使用体验。Go 语言首先是一门简单的语言，简单意味着可读性好，容易理解，容易上手工作，容易修复错误，节省开发者时间，提升开发者间的沟通效率。但作为面向工程的编程语言，光有简单的设计哲学还不够，每个语言设计细节还都要经过“工程规模化”的考验和打磨，需要在细节上做好充分的思考和讨论。 比如 Rob Pike 就曾谈到过 Go 当初为何没有使用 Python 那样的代码缩进来表示程序结构，而是选择了与 C 语言相同的大括号，就是因为他们经过调查发现 Python 的缩进结构在构建小规模程序时的确很方便，但是当代码库变得更大的时候，缩进式的结构非常容易出错。从工程的安全性和可靠性角度考虑，Go 团队最终选择了大括号代码块结构。 类似的面向工程的语音设计细节考量还包括： 重新设计编译单元和目标文件格式，实现 Go 源码快速构建，让大工程的构建时间缩短到类似 Python 的交互式编译的编译速度； 如果源文件导入它不使用的包，则程序将无法编译。这可以充分保证任何 Go 程序的依赖树是精确的。这也可以保证在构建程序时不会编译额外的代码，从而最大限度地缩短编译时间； 去除包的循环依赖，循环依赖会在大规模的代码中引发问题，因为它们要求编译器同时处理更大的源文件集，这会减慢增量构建； 在处理依赖关系时，有时会通过允许一部分重复代码来避免引入较多依赖关系。比如：net 包具有其自己的整数到十进制转换实现，以避免依赖于较大且依赖性较大的格式化 io 包； 包路径是唯一的，而包名不必唯一的。导入路径必须唯一标识要导入的包，而名称只是包的使用者如何引用其内容的约定。包名称不必是唯一的约定大大降低了开发人员给包起唯一名字的心智负担； 故意不支持默认函数参数。因为在规模工程中，很多开发者利用默认函数参数机制，向函数添加过多的参数以弥补函数 API 的设计缺陷，这会导致函数拥有太多的参数，降低清晰度和可读性； 首字母大小写定义标识符可见性，这是 Go 的一个创新。它让开发人员通过名称即可知晓其可见性，而无需回到标识符定义的位置查找并确定其可见性，这提升了开发人员阅读代码的效率； 在语义层面，相对于 C，Go 做了很多改动，提升了语言的健壮性，比如：去除指针算术、去除隐式的数字转型等； 内置垃圾收集，这对于大型工程项目来说，大大降低了程序员在内存管理方面的负担，程序员使用 GC 感受到的好处超过了付出的成本，并且这些成本主要由语言实现者来承担； 内置并发支持，为网络软件带来了简单性，简单又带来了健壮，这是大型工程软件开发所需要的； 增加 type alias，支持大规模代码库的重构。 2) 标准库 Go 被称为“内置电池（battery-included）”的编程语言。“内置电池”原指购买了电子设备后，在包装盒中包含了电池，电子设备可以开箱即用，无需再次出去购买电池。如果说一门编程语言是“自带电池”，则说明这门语言标准库功能丰富，多数功能无需依赖外部的第三方包或库，Go 语言恰是这类编程语言。 由于诞生年代较晚，且目标较为明确，Go 在标准库中提供了各类高质量且性能优良的功能包，其中的 net/http、crypto/xx、encoding/xx 等包充分迎合了云原生时代的关于 API/RPC Web 服务的构建需求，Go 开发者可以直接基于标准库提供的这些包实现一个满足生产要求的 API 服务，从而减少对外部第三方包或库的依赖，降低工程代码依赖管理的复杂性，也降低了开发人员学习第三方库的心智负担。 仅使用标准库来构建系统，这对于开发人员还是蛮有吸引力的。在很多关于选用何种 Go Web 开发框架的调查中，选择标准库的依然占大多数，这也是 Go 社区显著区别于其他编程语言社区的一点。Go 团队还在 golang.org/x 路径下面提供了暂未放入标准库的扩展库/补充库供广大 Gopher 使用，包括：text、net、crypto 等，这些库的质量也是非常高的，标准库中部分包也将 golang.org/x 下的 text、net 和 crypto 包作为依赖包 vendor 到 Go 标准库中。 Go 语言目前在 GUI、mobile 开发领域占有的份额较低，这很可能与 Go 标准库没有内置这类包不无关系。在 2016 年的 Gopher 用户调查中，Gopher 们最希望标准库增加的功能中，GUI 和 mobile 包就排名靠前。 图1-5-1 Go语言2016年调查结果节选 这也或多或少从反向证明了“内置电池”对于工程领域问题解决的重要性。 3) 工具 开发人员在工程过程中需要使用工具。而 Go 语言提供了这个星球上最全面、最贴心的编程语言官方工具链，涵盖了编译、编辑、依赖获取、调试、测试、文档、性能剖析等方方面面。 构建和运行：go build/go run 依赖包查看与获取：go list/go get/go mod xx 编辑辅助格式化：go fmt/gofmt 文档查看：go doc/godoc 单元测试/基准测试/测试覆盖率：go test 代码静态分析：go vet 性能剖析与跟踪结果查看：go tool pprof/go tool trace 升级到新 Go 版本 API 的辅助工具：go tool fix 报告 Go 语言 bug：go bug 值得重点提及的是 gofmt 统一了 Go 语言的编码风格，在其他语言开发者还在为代码风格争论不休的时候，Go 开发者可以更加专注于领域业务中。同时，相同的代码风格让以往困扰开发者的代码阅读、理解和评审工作变得容易了很多，至少 Go 开发者再也不会有那种因代码风格的不同而产生的陌生感。 在提供丰富的工具链的同时，Go 语言的语法、package 系统以及命名惯例的设计也让针对 Go 的工具更容易编写，并且 Go 在标准库中提供了官方的词法分析器、语法解析器和类型检查器相关 package，开发者可以基于这些包快速构建 Go 工具。 我们可以说 Go 构建了一个开放的工具链生态系统，它鼓励社区和开发人员为 Go 添加更多、更实用的工具，而更多、更好的工具反过来又帮助 Go 更好地解决工程上的“规模化”问题，这是一个良性的生态循环。 } 04 Go语言的设计哲学之三：并发 06 参考 Go 项目布局设计你的项目结构 扫码加入慕课前沿技术核心用户群 验证信息：2010312025386365复制 QQ讨论群号：729941811 QQ群URL：点击访问 若遇到搜索不到QQ群或加群失败，请联系客服邮箱:kf@imooc.com"},{"title":"","date":"2024-03-12T03:55:12.941Z","updated":"2024-03-12T03:55:12.941Z","comments":true,"path":"book/06参考Go项目布局设计你的项目结构慕课专栏.html","permalink":"https://smartxia.github.io/blog/book/06%E5%8F%82%E8%80%83Go%E9%A1%B9%E7%9B%AE%E5%B8%83%E5%B1%80%E8%AE%BE%E8%AE%A1%E4%BD%A0%E7%9A%84%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84%E6%85%95%E8%AF%BE%E4%B8%93%E6%A0%8F.html","excerpt":"","text":"06 参考 Go 项目布局设计你的项目结构-慕课专栏 06 参考 Go 项目布局设计你的项目结构 更新时间：2020-09-18 10:03:09 学习这件事不在乎有没有人教你，最重要的是在于你自己有没有觉悟和恒心。 —— 法布尔 除非是像“hello world”这样的简单程序，但凡我们编写一些 non-trivial 的实用程序或库，我们都会遇到采用什么样的项目结构（project structure）的问题（通常一个项目对应一个仓库 repository）。在 Go 语言中，项目结构同样十分重要，因为这决定了项目内部包(package)的布局以及包依赖关系是否合理，同时还会影响到外部项目对该项目中包的依赖。 1. Go 项目的项目结构 我们先来看看世界上第一个 Go 项目- Go 语言自身的项目结构是什么样的。 Go 项目的项目结构从发布 1.0 版本以来一直十分稳定，直到现在 Go 项目的顶层结构基本没有大的改变。截至 go 项目 commit 1e3ffb0c(2019.5.14)，go 项目结构如下： # tree -LF 1 ~/go/src/github.com/golang/go ./go ├── api/ ├── AUTHORS ├── CONTRIBUTING.md ├── CONTRIBUTORS ├── doc/ ├── favicon.ico ├── lib/ ├── LICENSE ├── misc/ ├── PATENTS ├── README.md ├── robots.txt ├── src/ └── test/ 6 directories, 8 files 作为 Go 语言的“创世项目”，其项目结构对后续的其他 Go 语言项目具有重要的参考意义，尤其是 go 项目早期 src 目录下面的结构，以 Go 1.3 版本为例： # tree -LF 1 ./src ./src ├── all.bash* ├── all.bat ├── all.rc* ├── clean.bash* ├── clean.bat ├── clean.rc* ├── cmd/ ├── lib9/ ├── libbio/ ├── liblink/ ├── make.bash* ├── make.bat ├── Make.dist ├── make.rc* ├── nacltest.bash* ├── pkg/ ├── race.bash* ├── race.bat ├── run.bash* ├── run.bat ├── run.rc* └── sudo.bash* 5 directories, 17 files 关于 src 下面的结构，我们总结三个特点： 代码构建的脚本源文件放在 src 下面的顶层目录下； src 下的二级目录 cmd 下面存放着 go 相关可执行文件的相关目录以及 main 包； # tree -LF 1 ./cmd ./cmd ... ... ├── 6a/ ├── 6c/ ├── 6g/ ... ... ├── cc/ ├── cgo/ ├── dist/ ├── fix/ ├── gc/ ├── go/ ├── gofmt/ ├── ld/ ├── nm/ ├── objdump/ ├── pack/ └── yacc/ 26 directories, 0 files src 下的二级目录 pkg 下面存放着上面 cmd 下各程序依赖的包、go 运行时以及 go 标准库的源文件 # tree -LF 1 ./pkg ./pkg ... ... ├── flag/ ├── fmt/ ├── go/ ├── hash/ ├── html/ ├── image/ ├── index/ ├── io/ ├── log/ ├── math/ ... ... ├── net/ ├── os/ ├── path/ ├── reflect/ ├── regexp/ ├── runtime/ ├── sort/ ├── strconv/ ├── strings/ ├── sync/ ├── syscall/ ├── testing/ ├── text/ ├── time/ ├── unicode/ └── unsafe/ 39 directories, 0 files 虽然 Go 1.4 版本中删除了 Go 源码树中“src/pkg/xxx”中 pkg 这一层级目录而直接使用 src/xxx，但早期 Go 项目 src 目录下的这种结构布局特点依然对后续多数 Go 语言项目的项目结构产生了较大的影响。 2. Go 语言典型项目结构（构建二进制可执行文件类型） 基于上述参考项目结构，Go 社区在多年的 Go 语言实践积累后逐渐形成了一种典型项目结构，如下图所示： 图2-6-1 Go语言典型项目结构 上面就是一个支持构建二进制可执行文件（在 cmd 下）的典型 Go 项目的结构。 cmd 目录：存放项目要编译构建的可执行文件对应的 main 包的源文件。如果有多个可执行文件需要构建，每个可执行文件的 main 包单独放在一个子目录中，比如图中的 app1、app2；cmd 目录下的各 app 的 main 包将整个项目的依赖连接在一起；并且通常来说，main 包应该很简洁。我们在 main 包中会做一些命令行参数解析、资源初始化、日志设施初始化、数据库连接初始化等工作，之后就会将程序的执行权限交给更高级的执行控制对象；也有一些 go 项目将 cmd 这个名字改为 app，但其功用并没有变； pkg 目录：存放项目自身要使用、同样也是可执行文件对应 main 包所要依赖的库文件；同时该目录下的包还可以被外部项目引用；也有些项目将 pkg 这个名字改为 lib，但目录用途不变； Makefile：这里的 Makefile 是项目构建工具所用脚本的“代表”。Go 并没有内置如 make、bazel 等级别的项目构建工具，对于一些规模稍大的项目而言，项目构建工具似乎还不可缺少。在 Go 典型项目中，项目构建工具的脚本一般放在项目顶层目录下，比如这里的 Makefile；对于构建脚本较多的项目，也可以建立 build 目录，并将构建脚本的规则属性文件、子构建脚本放入其中； go.mod 和 go.sum：Go 语言包依赖管理使用的配置文件。Go 1.11 版本引入 go modules 机制，因此新项目建议基于 go modules 进行包依赖管理；对于没有使用 go modules 进行包管理的项目，这里可以换为 dep 的 Gopkg.toml 和 Gopkg.lock 或者 glide 的 glide.yaml 和 glide.lock 等； vendor 目录（可选）：vendor 是 Go 1.5 版本引入的用于在项目本地缓存特定版本依赖包的机制，在 go modules 机制引入前，基于 vendor 可以实现可再现构建(reproducible build)，保证基于同一源码构建出的可执行程序是等价的，这个机制是对中国大陆地区的 gopher 们尤为实用。go modules 本身就可以实现可再现构建，而无需 vendor，因此这里将 vendor 目录视为一个可选目录。一般我们仅保留项目根目录下的 vendor 目录，否则会造成不必要的依赖选择的复杂性。 Go 1.11 引入的 module 是一组同属于一个版本管理单元的包的集合。如果项目结构中存在版本管理的“分歧”，比如：app1 和 app2 的发布版本并不总是同步的，那么建议将项目拆分为多个项目（仓库），每个项目单独承载一个 module 进行单独的版本管理和演进。 Go 支持在一个项目/仓库中存在多个 module，但这种管理方式可能要比一定比例的代码重复引入更多的复杂性。 3. Go 语言典型项目结构（构建库类型） Go 1.4 发布时，Go 语言项目自身去掉了 src 下的 pkg 这一层目录，这个结构上的改变对那些只编译为库的 Go 语言库类型项目结构有着一定的影响。我们来看一个典型的 Go 语言库类型项目的结构布局： 图2-6-2 Go语言库项目结构 我们看到库类型项目相比于构建二进制可执行文件的项目要简单一些： 去除了 cmd 和 pkg 两个子目录； vendor 也不再是可选目录：对于库类型项目而言，我们不推荐在项目中放置 vendor 目录去缓存库自身的第三方依赖，库项目仅通过 go.mod（或其他包依赖管理工具的 manifest 文件）明确表述出该项目依赖的模块或包以及版本要求即可。 Go 库项目的初衷是为了对外部（开源或组织内部公开）暴露 API，对于仅限项目内部使用的包，在项目结构上可以通过 Go 1.4 版本中引入的 internal 包机制来实现。对库项目而言，最简单的方式就是在顶层加入一个 internal 目录，将不想暴露到外部的包都放在该目录下，比如下面项目结构中的 ilib1、ilib2： // 带internal的Go库项目结构 GoLibProj ├── LICENSE ├── Makefile ├── README.md ├── go.mod ├── internal/ │ ├── ilib1/ │ └── ilib2/ ├── lib.go ├── lib1/ │ └── lib1.go └── lib2/ └── lib2.go 这样，根据 go internal 机制的作用原理，internal 目录下的 ilib1、ilib2 可以被以 GoLibProj 目录为根目录的其他目录下的代码（比如 lib.go、lib1/lib1.go 等）所导入和使用，但是却不可以为 GoLibProj 目录以外的代码所使用，从而实现选择性的暴露 API 包。当然 internal 也可以放在项目结构中的任一目录层级中，关键是项目结构设计人员明确哪些要暴露到外层代码，哪些仅用于同级目录或子目录中。 4. 小结 以上的两个针对构建二进制可执行文件类型以及库类型的项目参考结构是 Go 社区在多年实践后得到公认且使用较为广泛的项目结构。但它们也不是银弹，在 Go 语言早期，很多项目将所有源文件都放在位于项目根目录下的根包中的作法在一些小规模项目中同样工作得很好，虽然我们现在不推荐这么做了。 对于以构建二进制可执行文件类型为目的的项目来说，受 Go 1.4 项目结构影响，将 pkg 这一层次目录去掉也是很多项目选择的结构布局方式。 上述的参考项目结构与产品设计开发领域的“最小可行产品”（minimum viable product，简称为 mvp）的思路有些异曲同工，开发者可以在这样一个最小的“项目结构核心”的基础上根据实际需要对其进行扩展。 } 05 Go 语言的设计哲学之四：面向工程 07 gofmt：Go代码风格的唯一标准 扫码加入慕课前沿技术核心用户群 验证信息：2010312025386365复制 QQ讨论群号：729941811 QQ群URL：点击访问 若遇到搜索不到QQ群或加群失败，请联系客服邮箱:kf@imooc.com"},{"title":"","date":"2024-03-12T03:55:12.942Z","updated":"2024-03-12T03:55:12.942Z","comments":true,"path":"book/07gofmtGo代码风格的唯一标准慕课专栏.html","permalink":"https://smartxia.github.io/blog/book/07gofmtGo%E4%BB%A3%E7%A0%81%E9%A3%8E%E6%A0%BC%E7%9A%84%E5%94%AF%E4%B8%80%E6%A0%87%E5%87%86%E6%85%95%E8%AF%BE%E4%B8%93%E6%A0%8F.html","excerpt":"","text":"07 gofmt：Go代码风格的唯一标准-慕课专栏 07 gofmt：Go代码风格的唯一标准 更新时间：2020-09-21 14:49:10 横眉冷对千夫指，俯首甘为孺子牛。——鲁迅 1. gofmt：Go 语言在解决规模化问题上的一个最佳实践 gofmt 的代码风格不是某个人的最爱，而是所有人的最爱。 Go 语言设计的目标之一就是解决大型软件系统的大规模开发的问题，也就是说 Go 语言不仅要让某个独立开发人员使用起来感觉良好，还要能将这个良好的体验扩展到某个拥有一定人员规模的团队甚至是大型的开发团队。Go 核心团队将这类问题归结为一个词：规模化（scale），这同样也是目前比较火热的 Go2 演进方案将主要解决的问题。 gofmt 是伴随着 Go 语言诞生的第一批在“规模化”这个目标上的实践和尝试。它试图“消灭”软件开发过程中的阻碍“规模化”的问题，即开发人员在编程语言代码风格上的无休止且始终无法达成一致的争论以及不同代码风格给开发人员在阅读和维护他人代码时候带来的低效。gofmt 先入为主地将一种统一的代码风格内化到 Go 语言之中，并和 Go 语言一起以一种“标准”的形式推广给所有 Go 开发者。 在 Go 语言诞生和推广的初期，也许出现过因 gofmt 所格式化出来的统一代码风格与某个开发人员自己喜好的风格不一致而导致抱怨的情况，但随着 Go 影响力的扩大以及大量采用 gofmt 标准代码风格代码的累积，Go 开发者们渐渐意识到以往在其他编程语言中的那种针对代码风格的“争吵”渐渐少了甚至是消失了。在一致的代码风格下，Go 开发人员阅读和维护他人代码时感觉不再陌生，也变得更有效率了，gofmt 的代码风格成为了所有人能接受的共同的最爱，甚至于在 Go 的世界里代码风格已经变得没有了“存在感”。 gofmt 代码风格已经成为 Go 开发者的一种共识，融入到 Go 语言的开发文化当中了，以至于你让某个 Go 开发者说出 gofmt 后的代码风格是什么样的, 多数 Go 开发者可能说不出，因为代码会被 gofmt 自动变成那种风格，大家已经不再关心风格。gofmt 是 Go 语言在解决规模化问题上的一个最佳实践，并成为了 Go 语言吸引其他语言开发者的一大卖点。很多其他主流语言也在效仿 Go 语言推出自己的 format 工具，比如：Java formatter、Clang formatter、Dartfmt 等。因此，作为 Go 开发人员，请在提交你的代码前使用 gofmt 格式化你的 Go 源码。 2. 使用 gofmt 截至 Go 1.14 稳定版，gofmt 工具一直是放置在 Go 安装包中与 Go 编译器工具一并发布的，这足以说明 gofmt 工具的重要程度。 gofmt 保持了 Go 语言“简单”的设计哲学，这点通过其帮助手册即可看得出来： $ gofmt -help usage: gofmt [flags] [path ...] -cpuprofile string write cpu profile to this file -d display diffs instead of rewriting files -e report all errors (not just the first 10 on different lines) -l list files whose formatting differs from gofmt's -r string rewrite rule (e.g., 'a[b:len(a)] -&gt; a[b:]') -s simplify code -w write result to (source) file instead of stdout gofmt 最大的特点就是没有提供任何关于代码风格设置的命令行选项和参数，这样 Go 开发人员就没法通过设置命令行特定选项来定制自己喜好风格。不过 gofmt 却提供了满足在工程上对代码进行按格式查找、代码重构的足够的命令行选项，我们来看一些实用的用法： 1) 使用 gofmt -s 选项简化代码 Go 语言推崇一个事情仅有一种方式去完成，但难免语言中针对一个事情依然存在多种表达方法，比如下面这个例子： 存在一个字符串切片 v： v := []string&#123;...&#125; 如果要迭代访问字符串切片 v 的各个元素，我们可以这么做： for _ = range v &#123; ... &#125; 我们在 Go 1.4 及后续版本中，我们还可以这么做： for range v &#123; ... &#125; 显然 Go 开发者更推崇后面那一种简化后的写法。这样的例子在 Go 语言的演化过程中还存在一些。Go 官方为了减少将代码转变为简化语法给开发人员带去的额外工作量，在 gofmt 中提供了-s 选项，通过 gofmt -s 可以自动将遗留代码中的非简化代码自动转换为简化写法，并且没有副作用，因此一般“-s”选项都会是 gofmt 执行的默认选项。 2) 使用 gofmt -r 执行代码“微重构” 代码重构是软件工程过程中的日常操作，Go 语言曾经为了支持大规模软件的全局重构加入了type alias语法。gofmt 除了格式化代码的功能，对代码重构也具有一定的支撑能力。我们可以通过-r 命令行选项对代码进行“表达式”级别的替换以实现重构的目的。 下面是-r 选项的用法： gofmt -r 'pattern -&gt; replacement' [other flags] [path ...] gofmt -r 的原理就是在对源码进行重新格式化之前，搜索源码是否有可以匹配 pattern 的表达式，如果有，将所有匹配到的结果替换为 replacement 表达式。gofmt 要求 pattern 和 replacement 都是合法的 Go 表达式。比如： gofmt -r 'a[3:len(a)] -&gt; a[3:]' -w main.go 上面 gofmt -r 命令执行的意图就是将源码文件 main.go 中能与 a[3:len(a)] 匹配的代码替换为 a[3:]，然后再做重新格式化。注意：上述命令中的 a 并不是一个具体的字符，而是代表的一个通配符。出现在‘pattern -&gt; replacement’的小写字母都会被视为通配符。因此上面的命令对下面的源码片段都可以成功匹配： - fmt.Println(s[3:len(s)]) + fmt.Println(s[3:]) - n, err := s.r.Read(s.buf[3:len(s.buf)]) + n, err := s.r.Read(s.buf[s.end:]) - reverseLabels = append(reverseLabels, domain[3:len(domain)]) + reverseLabels = append(reverseLabels, domain[3:]) 我们也可以将 pattern 中的 3 改为一个字母 b（通配符）： gofmt -r 'a[b:len(a)] -&gt; a[b:]' -w xxx.go 这样 pattern 匹配的范围就会更大了： - fmt.Println(s[3:len(s)]) + fmt.Println(s[3:]) - n, err := s.r.Read(s.buf[s.end:len(s.buf)]) + n, err := s.r.Read(s.buf[s.end:]) - reverseLabels = append(reverseLabels, domain[i+1:len(domain)]) + reverseLabels = append(reverseLabels, domain[i+1:]) 3). 使用 gofmt -l 按格式要求输出满足条件的文件列表 gofmt 提供了-l 选项，可以按格式要求输出满足条件的文件列表，比如：输出 $GOROOT/src 下面所有不满足 gofmt 格式要求的文件列表（以 go 1.12.6 版本为例）： $ gofmt -l $GOROOT/src /home/tonybai/.bin/go1.12.6/src/cmd/cgo/zdefaultcc.go /home/tonybai/.bin/go1.12.6/src/cmd/go/internal/cfg/zdefaultcc.go /home/tonybai/.bin/go1.12.6/src/cmd/go/internal/cfg/zosarch.go /home/tonybai/.bin/go1.12.6/src/cmd/go/testdata/src/badpkg/x.go:1:1: expected 'package', found pkg /home/tonybai/.bin/go1.12.6/src/cmd/go/testdata/src/notest/hello.go:6:1: expected declaration, found Hello /home/tonybai/.bin/go1.12.6/src/cmd/go/testdata/src/syntaxerror/x_test.go:3:11: expected identifier /home/tonybai/.bin/go1.12.6/src/go/build/zcgo.go 我们看到即便是 Go 自身源码也有“漏网之鱼”，不过这可能是因为 gofmt 的格式化标准有微调，很多源文件没有及时调整而导致的。 我们也可以将-r 和-l 结合使用，输出匹配到 pattern 的文件列表，比如：查找 $GOROOT/src 下面能匹配到'a[b:len(a)]' pattern 的文件列表： $ gofmt -r 'a[b:len(a)] -&gt; a[b:]' -l $GOROOT/src /home/out1/.bin/go1.12.6/src/bufio/scan.go /home/out1/.bin/go1.12.6/src/crypto/x509/verify.go 不过要注意的是：如果某路径下有很多不符合 gofmt 格式的文件，这些文件也会被一并输出。 3. 使用 goimports Go 编译器在编译源码时会对源码文件 import 的 package 进行检查，对于源文件中没有使用但却导入了的 package 或使用了但没有导入的包，Go 编译器会报错。很遗憾的是 gofmt 工具无法自动增加或删除掉文件首部的 package 导入列表。为此，Go 核心团队的 Brad Fitzpatrick 实现了goimports 工具，后该工具移到官方 golang.org/x/tools/cmd/goimports 下维护。 goimports 在 gofmt 的功能的基础上，增加了对 package 列表的维护功能，可根据源码的最新变动自动从导入包列表中增删包。 安装 goimports 的方法很简单： $go get golang.org/x/tools/cmd/goimports 如果 go 编译器发现$GOPATH/bin 路径存在，就会将 goimports 可执行文件放入该路径下，这时只要保证该路径在$PATH 中即可。goimports 可以看成是在 gofmt 之上又封装了一层，并且 goimports 提供的命令行选项和参数与 gofmt 也十分类似： $ ./goimports -help usage: goimports [flags] [path ...] -cpuprofile string CPU profile output -d display diffs instead of rewriting files -e report all errors (not just the first 10 on different lines) -format-only if true, don't fix imports and only format. In this mode, goimports is effectively gofmt, with the addition that imports are grouped into sections. -l list files whose formatting differs from goimport's -local string put imports beginning with this string after 3rd-party packages; comma-separated list -memprofile string memory profile output -memrate int if &gt; 0, sets runtime.MemProfileRate -srcdir dir choose imports as if source code is from dir. When operating on a single file, dir may instead be the complete file name. -trace string trace profile output -v verbose logging -w write result to (source) file instead of stdout 因此，这里就不再单独对 goimports 进行用法上的赘述了。 4. 将 gofmt/goimports 与编辑器工具集成 日常开发工作中，Go 开发人员多使用各种主流编辑器进行代码的编写、测试和重构工作，对代码的格式化一般是通过将 gofmt/goimports 与编辑器集成后在源文件保存时由编辑器自动调用 gofmt/goimports 完成的，开发人员几乎没有手工敲入 gofmt 命令对源码进行格式化的。下面是将 gofmt/goimport 与主流 Go 源码编辑器集成方法的简要说明。 Visual Studio Code(vscode) Visual Studio Code 是微软开源的开源 IDE 工具，它集成了 git、支持智能提示、提供各种方便的快捷键等，vscode 最为强大的是其插件扩展。通过插件扩展，vscode 迅速抢占了各大编程语言的 IDE 榜单头部位置，Go 语言也不例外。 微软为 Go 提供了官方插件支持：vscode-go。vscode-go 自身也是借助第三方工具试下新了代码智能感知、代码导航、编辑、诊断、调试和单元测试等功能。其中“在文件保存时格式化”就是通过调用 gofmt 或 goimports 实现的。vscode 与 gofmt/goimports 的集成很简单，只需在安装 vscode-go 插件时按照提示安装 vscode-go 所依赖的第三方工具或者自己手工保证 gofmt 在环境变量 PATH 的路径中即可（将$GOROOT/bin 加入到 PATH 环境变量）；如果要使用 goimports，可通过本篇前面 goimports 的安装命令手工安装，并保证 goimports 所在目录在 PATH 环境变量的路径中即可。 Vim Vim 是在*NIX 世界普遍存在的一款历史悠久的著名文本编辑器，也是很多做后端开发工作的开发者最喜欢的编辑工具。vim 的强大之处与 vscode 类似，它也有一个强大的插件扩展机制，基于 vim 插件我们便可以实现想要的各种功能。 Go 和 VIM 两个世界通过vim-go插件连接在一起。vim-go 是由 Digital Ocean 工程师 Fatih Arslan 开发的 vim 插件（需要 Vim 7.4.2009 及以上版本），你可以通过 Pathogen、vim-plug 或 Vundle 中的任一款 vim 插件管理器安装 vim-go 插件。以使用 vim-plug 为例： 先安装 vim-plug 和 vim-go 两个 vim 插件： $ curl -fLo ~/.vim/autoload/plug.vim --create-dirs https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim $ git clone https://github.com/fatih/vim-go.git ~/.vim/plugged/vim-go 编辑~/.vimrc 文件，添加下面内容： call plug#begin() Plug 'fatih/vim-go' call plug#end() 保存退出后再启动 vim，在命令模式（在普通模式下输入\":“进入命令模式）下，执行\"GoInstallBinaries”，vim-go 会自动下载安装其所依赖的第三方工具，其中就包含 goimports 等，默认这些第三方工具都会被放置在 $GOPATH/bin 下。如果没有显式设置 GOPATH，$HOME/go 将被作为默认 GOPATH。因此你要确保 $GOPATH/bin 在 PATH 环境变量中。 vim-go 默认使用 gofmt 在文件保存时对 Go 源文件进行重新格式化，不过你可以设置使用 goimports： 在.vimrc 中，添加下面一行： let g:go_fmt_command = \"goimports\" 这样只要 goimports 可执行文件在 PATH 路径下，vim-go 就可以使用它来格式化你的代码并管理文件头部的包列表了。 Goland Goland 是知名 IDE 厂商 jetbrains 生产的 Go 语言 IDE 产品。jetbrains 在 IDE 领域浸淫多年，积累了丰富的 IDE 产品经验，这让 goland 一经推出就大受 Gopher 们欢迎，开源编辑器提供的功能在 goland 中均能找到，并且体验更佳。因此经过快速发展，目前 goland 已经成为市场占有率最高的商业 Go IDE 产品。 Goland 同样也是通过第三方工具（比如: gofmt/goimports）来实现对代码的格式化，在 goland 中我们可以手动对文件或工程执行格式化，也可以创建 File Watcher 来实现在文件保存时对文件进行自动格式化。 手工格式化调用方法（以 goland 2019.1.3 版本为例，后续版本设置方法可能有所不同）： 【Tools】-&gt; 【Go Tools】-&gt; Go fmt file/Go fmt project/Goimports file 图2-7-1 goland手工执行gofmt/goimports对源文件进行格式化 在文件保存时自动执行 gofmt/goimports 对源文件进行格式化的设置方法如下： 在【Pereferences...】对话框中，选择【Tools】-&gt; 【File Watchers】，然后添加一个File Watcher，选择go fmt模板或goimports模板即可。 图2-7-2 配置goland在文件保存时自动执行gofmt/goimports 5. 小结 gofmt 以及其背后的设计哲学是 Go 语言的一个创新，同样也是对编程世界的一个重要贡献。作为 Go 开发人员，要牢记在提交源码前先用 gofmt 对源码进行格式化，并学会将 gofmt/goimports 工具集成到你使用的 IDE/编辑器工具中去，让这一过程自动化，使得代码格式化这件事在开发过程中变得透明，不会成为开发人员的心智负担。 } 06 参考 Go 项目布局设计你的项目结构 08 Go 标识符的命名惯例 扫码加入慕课前沿技术核心用户群 验证信息：2010312025386365复制 QQ讨论群号：729941811 QQ群URL：点击访问 若遇到搜索不到QQ群或加群失败，请联系客服邮箱:kf@imooc.com"},{"title":"","date":"2024-03-12T03:55:12.942Z","updated":"2024-03-12T03:55:12.942Z","comments":true,"path":"book/08Go标识符的命名惯例慕课专栏.html","permalink":"https://smartxia.github.io/blog/book/08Go%E6%A0%87%E8%AF%86%E7%AC%A6%E7%9A%84%E5%91%BD%E5%90%8D%E6%83%AF%E4%BE%8B%E6%85%95%E8%AF%BE%E4%B8%93%E6%A0%8F.html","excerpt":"","text":"08 Go 标识符的命名惯例-慕课专栏 08 Go 标识符的命名惯例 更新时间：2020-09-24 09:31:52 成功＝艰苦的劳动＋正确的方法＋少谈空话。——爱因斯坦 计算机科学中只有两件难事：缓存失效和命名。 - 菲尔·卡尔顿，Netscape 架构师 从计算编程语言诞生那天起，给标识符命名这件事就一直伴随着程序员。命名这件事看似简单，但在如今大规模软件工程需要程序员个体间紧密协作的背景下，就像上面菲尔·卡尔顿所阐述的那样，做出好的命名并非易事。 命名是编程语言的要求，但是好的命名的目的却是为了提高程序的可读性和可维护性。好的命名是什么样子呢？Go 语言的贡献者和布道师 Dave Cheney 给出了一个隐喻：“好的命名就像一个好笑话。如果你必须解释它，那就不好笑了”。无论哪门编程语言，良好的命名应该遵循一些通用的原则，但就像之前在第一章节中提到的“语言影响思维”的假说那样，不同编程语言在命名上还会有一些个性化的命名惯例。 在 gofmt 的帮助下，Go 语言统一了代码风格标准，Gopher 们再也无需为括号摆放位置、使用制表符还是空格、是否对齐赋值操作等而争论了。在这样的情况下，命名成了广大 gopher 们为数不多可以“自由发挥”的空间了。不过关于命名，Go 语言依然有着自己的期望大家共同遵循的原则。 Go 的设计哲学之一就是追求简单，因此在命名上一样秉承着简单的总体原则。但简单并不意味着一味地为标识符选择短小的名字，而是要选择那种可以在标识符所在上下文中保持其用途清晰明确的名字。Go 自身以及标准库的实现是 Go 命名惯例形成的最初源头，因此如果要寻找良好命名的示范，Go 标准库是一个不错的地方。本节中我们的示例也多来自于 Go 标准库代码，一些结论也是来自于对标准库代码的分析。 要想做好 Go 标识符命名（包括 package 命名)，至少要遵循两个原则： 简单且一致 利用上下文辅助命名 下面我们将详细阐述一下这两个原则以及原则下的一些命名惯例。 1. 简单且一致 对于简单，我们最直观地理解就是“短小”，但这里的简单还包含着清晰明确的前提。短小意味着能用一个单词命名的，就不要使用单词组合；能用单个字母（在特定上下文）表达标识符用途的，就不用完整单词。 甚至在某种情况下，Go 命名惯例选择了简洁命名+注释辅助解释的方式，而不是一个长长的名字。 下面是 Go 语言一些常见类别标识符命名惯例。 1) 包 Go 中的包（package）一般建议以小写形式的单个单词命名，Go 标准库在这方面给我们做出了很好的示范： 图2-8-1 Go标准库包列表（部分） 我们在给包命名时不要有是否与其他包重名的顾虑，因为在 Go 中，包名是可以不唯一的，比如 foo 项目有名为 log 的包，bar 项目也可以有自己的名为 log 的包。但是每个包的导入路径是唯一的，对于包名冲突的情况，可以通过包别名(package alias)语法来解决: import \"github.com/bigwhite/foo/log\" import barlog \"github.com/bigwhite/bar/log\" // package import alias Go 语言建议：包名应尽量与包导入路径(import path)的最后一个路径分段保持一致。比如：包导入路径 golang.org/x/text/encoding 的最后路径分段是 encoding，该路径下包名就应该为 encoding。但在实际情况中，包名与导入路径最后分段不同的也有很多，比如：实时分布式消息队列 nsq 的官方客户端包的导入路径为：github.com/nsqio/go-nsq ，但是该路径下面的包名却是 nsq。个人分析出现这种情况的原因主要是为了在仓库名称上强调该实现是针对 Go 语言的，比如 go-nsq 的意义是这是一份 Go 语言实现的 nsq 客户端 API 库，为的是和 nsq-java、pynsq、rust-nsq 等其他语言的客户端 API 做出显式区分。这种情况在我个人的gocmpp 项目中也存在，gocmpp 项目的导入路径是 github.com/bigwhite/gocmpp，gocmpp 这个仓库名强调的是这是一份cmpp 协议的 Go 实现，但该路径下包的名字却是 cmpp。 那如果将 nsq 的 Go 客户端 API 放入 github.com/nsqio/go-nsq/nsq 下面是否更理想呢？显然在导入路径中出现两次\"nsq\"字样的这种“口吃”现象也不是被 Go 官方推荐的。今天看来如果能将所有 Go 实现放入 github 账号顶层路径下面的 golang 或 go 路径下应该是更好的方案，比如： \"github.com/nsqio/go/nsq\"或\"github.com/nsqio/golang/nsq\" \"github.com/bigwhite/go/cmpp\"或\"github.com/bigwhite/golang/cmpp\" 同时，我们在给包命名的时候，不仅要考虑包自身的名字，还要同时考虑兼顾到该包导出的标识符(如变量、常量、类型、函数等)的命名。由于对这些这些包导出标识符的引用是必须以包名作为前缀的，因此对包导出标识符命名时，在名字中不要再包含包名，比如： strings.Reader [good] strings.StringReader [bad] strings.NewReader [good] strings.NewStringReader [bad] bytes.Buffer [good] bytes.ByteBuffer [bad] bytes.NewByteBuffer [bad] 2) 变量、类型、函数和方法 一个 Go 工程中包的数量还是有限的，变量、类型、函数和方法的命名占据了命名工作的较大比重。 在 Go 中变量分为包级别的变量和局部变量（函数或方法内的变量）。函数或方法的参数、返回值一定程度上都可以视为局部变量。 Go 语言官方要求标识符命名采用驼峰命名法（CamelCase），以变量名为例，如果变量名由一个以上的词组合构成，那么这些词之间紧密相连，不使用任何连接符（比如：下划线）。驼峰命名法有两种形式，一种是第一个词的首字母小写，后面每个词的首字母大写，叫做“小骆峰拼写法”（lowerCamelCase），这也是在 Go 中最常见的标识符命名法；而第一个词的首字母以及后面每个词的首字母都大写，叫做“大驼峰拼写法”（UpperCamelCase），又称“帕斯卡拼写法”（PascalCase）。由于首母大写的标识符在 Go 语言中被视作包导出标识符，因此只有在涉及包导出的情况下，才会用到大驼峰拼写法。不过首字母缩略词要保持全部大写，比如 HTTP(Hypertext Transfer Protocol)、CBC(Cipher Block Chaining) 等。 给变量、类型、函数和方法命名依然要以简单短小为首要考虑的原则，我们对 Go 标准库（Go 1.12 版本）中标识符名称进行统计1的结果如下（去除 Go 关键字和 builtin 函数）： 在$GOROOT/src下面： $cat $(find . -name '*.go') | indents | sort | uniq -c | sort -nr | sed 30q 105896 v 71894 err 54512 Args 49472 t 44090 _ 43881 x 43322 b 36019 i 34432 p 32011 s 28435 AddArg 26185 c 25518 n 25242 e1 23881 r 21681 AuxInt 20700 y ... ... 我们看到了大量单字母的标识符命名，这是 Go 在命名上的一个惯例。 Go 标识符一般来说仍以单个单词作为命名首选。从 Go 标准库代码的不完全统计结果来看，不同类别标识符的命名呈现出下面一些特征： 循环和条件变量多采用单个字母命名(具体见上面的统计数据)； 函数/方法的参数和返回值变量一般以单个单词或单个字母为主2； 方法名由于在调用时会绑定类型信息，因此命名多以单个单词为主3； 函数名则多以多单词的复合词进行命名4； 类型名也多以多单词的复合词进行命名5。 除了上述特征，还有一些惯例是在命名时常用的。 变量名字中不要带有类型信息 比如： userSlice []*User [bad] users []*User [good] 带有类型信息的命名除了让变量看起来更长之外，没有给开发者阅读代码带来任何其他好处。 不过有些开发者依然会质疑：userSlice 中的类型信息可以告诉我们变量所代表的底层存储是一个切片，这样便可以在 userSlice 上应用切片的各种操作了。提出这样质疑的开发者显然忘记了一条编程语言命名的通用惯例：保持变量声明与使用之间的距离越近越好或者说将变量声明在第一次使用该变量之前。这个惯例与 Go 核心团队的安德鲁·杰拉德曾提到的一种说法：“一个名字的声明和使用之间的距离越大，这个名字的长度就越长”异曲同工。如果在一屏之内能看到 users 的声明，那-Slice 这个类型信息显然是不必放在变量的名称中了。 保持简短命名变量含义上的一致性 从上面的统计我们看到，Go 语言中有大量的单字母或单个词或缩写命名的简短命名变量，有人可能会质疑简短命名变量会带来可读性上的下降。Go 语言建议通过保持一致性来维持可读性。一致意味着代码中相同或相似的命名所传达的含义是相同或相似的，这样便于代码阅读者或维护者猜测出变量的用途。 这里大致分析了一下 Go 标准库中常见短变量名字所代表的含义，并且这些含义在整个标准库范畴内一致性保持的很好。 变量v, k, i的常用含义： // 循环语句中的变量 for i, v := range s &#123; ... &#125; // i: 下标变量； v：元素值 for k, v := range m &#123; ... &#125; // k: key变量；v: 元素值 for v := range r &#123; // channel ... &#125; // v: 元素值 // if、switch/case分支语句中的变量 if v := mimeTypes[ext]; v != \"\" &#123; &#125; // v: 元素值 switch v := ptr.Elem(); v.Kind() &#123; ... ... &#125; case v := &lt;-c: // v: 元素值 // 反射的结果值 v := reflect.ValueOf(x) 变量t的常用含义： t := time.Now() // 时间 t := &amp;Timer&#123;&#125;// 定时器 if t := md.typemap[off]; t != nil &#123; &#125;// 类型 变量b的常用含义： b := make([]byte, n) // byte切片 b := new(bytes.Buffer) // byte缓存 3) 常量 在 C 语言家族中，常量通常用全大写的单词名字命名，比如下面的 C 语言和 Java 定义的常量： C语言： #define MAX_VALUE 1000 #define DEFAULT_START_DATA \"2019-07-08\" Java语言： public static final int MAX_VALUE = 1000; public static final String DEFAULT_START_DATA = \"2019-07-08\"; 但在 Go 语言中，常量在命名方式上与变量并无较大差别，并不要求全部大写。只是考虑其含义的准确传递，常量多使用多单词组合的命名。下面是标准库中的例子： // $GOROOT/src/net/http/request.go const ( defaultMaxMemory = 32 &lt;&lt; 20 // 32 MB ) const ( deleteHostHeader = true keepHostHeader = false ) 当然，你也可以为本身就有着大写名称的特定常量使用全大写的名字，比如数学计算中的 PI，又或是为了和系统错误码、系统信号名称保持一致而用全大写： // $GOROOT/src/math/sin.go const ( PI4A = 7.85398125648498535156E-1 // 0x3fe921fb40000000, Pi/4 split into three parts PI4B = 3.77489470793079817668E-8 // 0x3e64442d00000000, PI4C = 2.69515142907905952645E-15 // 0x3ce8469898cc5170, ) // $GOROOT/src/syscall/zerrors_linux_amd64.go // Errors const ( E2BIG = Errno(0x7) EACCES = Errno(0xd) EADDRINUSE = Errno(0x62) EADDRNOTAVAIL = Errno(0x63) EADV = Errno(0x44) EAFNOSUPPORT = Errno(0x61) EAGAIN = Errno(0xb) EALREADY = Errno(0x72) EBADE = Errno(0x34) EBADF = Errno(0x9) EBADFD = Errno(0x4d) EBADMSG = Errno(0x4a) EBADR = Errno(0x35) EBADRQC = Errno(0x38) ... ... ) // Signals const ( SIGABRT = Signal(0x6) SIGALRM = Signal(0xe) SIGBUS = Signal(0x7) SIGCHLD = Signal(0x11) SIGCLD = Signal(0x11) SIGCONT = Signal(0x12) SIGFPE = Signal(0x8) SIGHUP = Signal(0x1) SIGILL = Signal(0x4) SIGINT = Signal(0x2) SIGIO = Signal(0x1d) ... ... ) 在 Go 中数值型常量无需显式赋予类型，常量会在使用时根据左值类型和其他运算操作数的类型做自动的转换，因此常量的名字也不要包含类型信息。 4) 接口 Go 语言中的 interface 是 Go 在编程语言层面上的一个创新，它为 Go 代码提供了强大的“解耦合”能力，因此良好的接口类型设计和接口组合是 Go 程序设计的静态骨架和基础。良好的接口设计自然也离不开良好的接口命名。在 Go 语言中 interface 名字仍然以单个词为优先。对于拥有唯一方法(method)或通过多个拥有唯一方法的接口组合而成的接口，Go 语言的惯例是一般用\"方法名+er\"的方式为 interface 命名。比如： // $GOROOT/src/io/io.go type Writer interface &#123; Write(p []byte) (n int, err error) &#125; type Reader interface &#123; Read(p []byte) (n int, err error) &#125; type Closer interface &#123; Close() error &#125; type ReadWriteCloser interface &#123; Reader Writer Closer &#125; Go 语言推荐尽量定义小接口，并通过接口组合的方式构建程序，在后面的接口章节我们会详细描述。 2. 利用上下文环境，用最短的名字携带足够的信息 Go 在给标识符命名时还有着考虑上下文环境的惯例，即在不影响可读性前提下，结合一致性的原则，尽可能地用长度短小的名字命名标识符。这与其他一些主流语言在命名上的建议有不同，比如 Java 建议遵循“见名知义”的命名原则。我们可以对比一下 Java 和 Go 在循环变量起名上的差异： java vs. go \"index\" vs. \"i\" \"value\" vs. \"v\" 我们在 Go 代码来中分别运用这两个命名方案(index、value）和 (i、 v)，并做比对： for index := 0; index &lt; len(s); index++ &#123; value := s[index] ... ... &#125; vs. for i := 0; i &lt; len(s); i++ &#123; v := s[i] ... ... &#125; 我们看到：至少在 forLoop 这个上下文中，index、value 并没有比 i、v 携带更多额外信息。 这里我引用一下安德鲁·杰拉德在 2014 年的一次关于 Go 命名演讲中的代码，我们再来对比感受一下 Go 命名惯例所带来的效果： [bad] func RuneCount(buffer []byte) int &#123; runeCount := 0 for index := 0; index &lt; len(buffer); &#123; if buffer[index] &lt; RuneSelf &#123; index++ &#125; else &#123; _, size := DecodeRune(buffer[index:]) index += size &#125; runeCount++ &#125; return runeCount &#125; [good] func RuneCount(b []byte) int &#123; count := 0 for i := 0; i &lt; len(b); &#123; if b[i] &lt; RuneSelf &#123; i++ &#125; else &#123; _, n := DecodeRune(b[i:]) i += n &#125; count++ &#125; return count &#125; 3. 小结 我们看到 Go 语言命名惯例深受 C 语言的影响，这和 Go 语言之父有着深厚的 C 语言背景不无关系。Go 语言追求简单一致且利用上下文辅助名字信息传达的命名惯例可能让一些从其他语言转向 Go 的程序员初期有些不适应。但这就是 Go 语言文化的一部分，也许随着编写 Go 代码量的增多，你就能理解这种命名惯例的好处了。 indents命令：https://github.com/bigwhite/go/tree/master/cmd/indents ↩︎ 参数与返回值查询方法：cd $GOROOT/src; cat $(find . -name '*.go') |grep 'func'|grep -v Test|more ↩︎ 方法名查询方法：cd $GOROOT/src; cat $(find . -name '*.go') |grep 'func ('|grep -v Test)|more ↩︎ 函数名查询方法：cd $GOROOT/src; cat $(find . -name '*.go') |grep func|grep -v Test |grep -v 'func (')|more ↩︎ 类型名查询方法：cd $GOROOT/src; cat $(find . -name '*.go') |grep type | more ↩︎ } 07 gofmt：Go代码风格的唯一标准 09 变量声明形式尽量保持一致 扫码加入慕课前沿技术核心用户群 验证信息：2010312025386365复制 QQ讨论群号：729941811 QQ群URL：点击访问 若遇到搜索不到QQ群或加群失败，请联系客服邮箱:kf@imooc.com"},{"title":"","date":"2024-03-12T03:55:12.943Z","updated":"2024-03-12T03:55:12.943Z","comments":true,"path":"book/09变量声明形式尽量保持一致慕课专栏.html","permalink":"https://smartxia.github.io/blog/book/09%E5%8F%98%E9%87%8F%E5%A3%B0%E6%98%8E%E5%BD%A2%E5%BC%8F%E5%B0%BD%E9%87%8F%E4%BF%9D%E6%8C%81%E4%B8%80%E8%87%B4%E6%85%95%E8%AF%BE%E4%B8%93%E6%A0%8F.html","excerpt":"","text":"09 变量声明形式尽量保持一致-慕课专栏 09 变量声明形式尽量保持一致 更新时间：2020-09-25 09:51:31 学习从来无捷径，循序渐进登高峰。 —— 高永祚 和 Python、Ruby 等动态脚本语言不同，Go 语言沿袭了静态语言的传统：使用变量之前需要先进行变量的声明。 这里大致列一下 Go 语言常见的变量声明形式： var a int32 var s string = \"hello\" var i = 13 n := 17 var ( crlf = []byte(\"\\r\\n\") colonSpace = []byte(\": \") ) 如果让 Go 语言的设计者重新来设计一次变量声明语法，我相信他们很大可能不会给予 Gopher 们这么大的变量声明灵活性，但目前这一切都无法改变。对于以面向工程著称且以解决“规模化（scale）”问题为目标的 Go 语言而言，Gopher 们在进行变量声明形式的选择上应该尽量保持项目范围内是一致的。 Go 语言有两类变量： 包级变量（package varible）：即在 package 级别可见的变量。如果是导出变量，则该包级变量也可以被视为全局变量； 局部变量（local varible）：函数或方法体内声明的变量，仅在函数或方法体内可见。 下面我们就来分别说明一下这两类变量在声明形式选择上保持一致性的一些最佳实践。 1. 包级变量的声明形式 包级变量只能使用带有 var 关键字的变量声明形式，但在形式细节上仍有一定灵活度。我们从变量声明的时候是否延迟初始化这个角度对包级变量进行一次分类。 1). 声明并同时显式初始化 下面是摘自 Go 标准库中的代码(Go 版本 1.12)： // $GOROOT/src/io/pipe.go var ErrClosedPipe = errors.New(\"io: read/write on closed pipe\") // $GOROOT/src/io/io.go var ErrShortWrite = errors.New(\"short write\") var ErrShortBuffer = errors.New(\"short buffer\") var EOF = errors.New(\"EOF\") var ErrUnexpectedEOF = errors.New(\"unexpected EOF\") var ErrNoProgress = errors.New(\"multiple Read calls return no data or error\") 我们看到，对于变量声明的同时进行显式初始化的这类包级变量，实践中多使用下面格式： var variableName = InitExpression Go 编译器会自动根据等号右侧 InitExpression 结果值的类型确定左侧声明的变量的类型。对于下面这些声明语句，Go 会为包级变量设置默认类型： var a = 17 var f = 3.14 对于未显式赋予类型的整型变量 a，Go 编译器会将之设置为默认类型 int；而浮点型变量 f 的默认类型则为 float64。如果我们不接受默认类型，而是要显式为 a 和 f 指定类型，那么我们有两种方式： var a int32 = 17 var f float32 = 3.14 vs. var a = int32(17) var f = float32(3.14) 从声明一致性的角度出发，Go 更推荐我们使用后者，这样就统一了接受默认类型和显式指定类型两种声明形式，尤其是在将这些变量放在一个 var 块中声明时，我们更青睐下面这样的形式： var ( a = 17 f = float32(3.14) ) 而不是下面这种看起来不一致的声明形式： var ( a = 17 f float32 = 3.14 ) 2). 声明但延迟初始化 对于声明时并不立即显式初始化的包级变量，我们使用最基本的声明形式： var a int32 var f float64 我们知道，虽然没有显式初始化，Go 语言也会让这些变量拥有初始的“零值”。如果是自定义的类型，保证其零值可用是非常必要的，这个我们在后续章节会详细说明。 3). 声明聚类与就近原则 Go 语言提供 var 块用于将多于一个的变量声明放在一起，并且在语法上不会限制放置在 var 块中的声明类型。但是我们一般将同一类的变量声明放在一个 var 块中，不同类的声明放在不同的 var 块中；或者将延迟初始化的变量声明放在一个 var 块，而将声明且显式初始化的变量放在另一个 var 块中。这里我称之为“声明聚类”。比如下面 Go 标准库中的代码： // $GOROOT/src/net/http/server.go var ( bufioReaderPool sync.Pool bufioWriter2kPool sync.Pool bufioWriter4kPool sync.Pool ) var copyBufPool = sync.Pool&#123; New: func() interface&#123;&#125; &#123; b := make([]byte, 32*1024) return &amp;b &#125;, &#125; ... ... // $GOROOT/src/net/net.go var ( // aLongTimeAgo is a non-zero time, far in the past, used for // immediate cancelation of dials. aLongTimeAgo = time.Unix(1, 0) // nonDeadline and noCancel are just zero values for // readability with functions taking too many parameters. noDeadline = time.Time&#123;&#125; noCancel = (chan struct&#123;&#125;)(nil) ) var threadLimit chan struct&#123;&#125; ... ... 我们看到在 server.go 中，copyBufPool 变量没有放入 var 块就是因为它的声明是带有显式初始化的，而 var 块中的变量声明都是延迟初始化的；net.go 中的 threadLimit 单独放在 var 块外面，一方面是考虑它是延迟初始化的变量声明，另一方面 threadLimit 在含义上与 var 块中标识时间限制的变量也有所不同。 那么大家可能还有一个问题，那就是是否将包级变量的声明全部集中放在源文件头部呢？使用静态编程语言的开发人员都知道，变量声明最佳实践中还有一条：就近原则。即尽可能在靠近第一次使用变量的位置声明该变量。就近原则实际上也是变量的作用域最小化的一种实现手段。在 Go 标准库中我们很容易找到符合就近原则的变量声明的例子： // $GOROOT/src/net/http/request.go // ErrNoCookie is returned by Request's Cookie method when a cookie is not found. var ErrNoCookie = errors.New(\"http: named cookie not present\") // Cookie returns the named cookie provided in the request or // ErrNoCookie if not found. // If multiple cookies match the given name, only one cookie will // be returned. func (r *Request) Cookie(name string) (*Cookie, error) &#123; for _, c := range readCookies(r.Header, name) &#123; return c, nil &#125; return nil, ErrNoCookie &#125; 当然如果一个包级变量在包内部被多处使用，那么这个变量还是放在源文件头部声明比较适合。 2. 局部变量的声明形式 有了包级变量做铺垫，我们再来讲解局部变量就容易很多了。和包级变量相比，局部变量又多了一种短变量声明形式，这也是局部变量采用最多的一种声明形式，下面我们来详细看看。 对于延迟初始化的局部变量声明，采用带有 var 关键字的声明形式。 如下面代码中的变量 buf： // $GOROOT/src/strings/replace.go func (r *byteReplacer) Replace(s string) string &#123; var buf []byte // lazily allocated for i := 0; i &lt; len(s); i++ &#123; b := s[i] if r[b] != b &#123; if buf == nil &#123; buf = []byte(s) &#125; buf[i] = r[b] &#125; &#125; if buf == nil &#123; return s &#125; return string(buf) &#125; 另外最常见的采用 var 关键字的声明的变量之一就是 err： var err error 对于声明且显式初始化的局部变量，建议使用短变量声明形式。 短变量声明形式是局部变量最常用的声明形式，它遍布在 Go 标准库代码中。 对于接受默认类型的变量，我们使用下面形式： a := 17 f := 3.14 s := \"hello, gopher!\" 对于不接受默认类型的变量，我们依然可以使用短变量声明形式，只是在\":=\"右侧要做一个显式转型： a := int32(17) f := float32(3.14) s := []byte(\"hello, gopher!\") 尽量在分支控制时应用短变量声明形式。 这应该是 Go 中短变量声明形式应用最广泛的场景了。在编写 Go 代码时，我们很少单独声明用于分支控制语句中的变量，而是将其与 if、for 等通过短变量声明形式融合在一起，就像下面这样： // $GOROOT/src/strings/strings.go func LastIndexAny(s, chars string) int &#123; if chars == \"\" &#123; // Avoid scanning all of s. return -1 &#125; if len(s) &gt; 8 &#123; // 作者注：在if条件控制语句中使用短变量声明形式 if as, isASCII := makeASCIISet(chars); isASCII &#123; for i := len(s) - 1; i &gt;= 0; i-- &#123; if as.contains(s[i]) &#123; return i &#125; &#125; return -1 &#125; &#125; for i := len(s); i &gt; 0; &#123; // 作者注：在for循环控制语句中使用短变量声明形式 r, size := utf8.DecodeLastRuneInString(s[:i]) i -= size for _, c := range chars &#123; if r == c &#123; return i &#125; &#125; &#125; return -1 &#125; // $GOROOT/src/net/net.go func (v *Buffers) WriteTo(w io.Writer) (n int64, err error) &#123; // 作者注：在for循环控制语句中使用短变量声明形式 if wv, ok := w.(buffersWriter); ok &#123; return wv.writeBuffers(v) &#125; // 作者注：在if条件控制语句中使用短变量声明形式 for _, b := range *v &#123; nb, err := w.Write(b) n += int64(nb) if err != nil &#123; v.consume(n) return n, err &#125; &#125; v.consume(n) return n, nil &#125; 这样的应用方式同时也体现出“就近”原则，也让变量的作用域最小化了。 由于良好的函数/方法设计讲究的是“单一职责”，因此每个函数/方法规模都不大，很少需要应用 var 块来聚类声明局部变量，当然如果你在声明局部变量时遇到适合聚类的应用场景，你也应该毫不犹豫地使用 var 块来声明多于一个的局部变量。比如： // $GOROOT/src/net/dial.go func (r *Resolver) resolveAddrList(ctx context.Context, op, network, addr string, hint Addr) (addrList, error) &#123; ... ... var ( tcp *TCPAddr udp *UDPAddr ip *IPAddr wildcard bool ) ... ... &#125; 或是： // $GOROOT/src/reflect/type.go // 这是一个非常长的函数，因此将所有var声明都聚合在函数的开始处了 func StructOf(fields []StructField) Type &#123; var ( hash = fnv1(0, []byte(\"struct &#123;\")...) size uintptr typalign uint8 comparable = true hashable = true methods []method fs = make([]structField, len(fields)) repr = make([]byte, 0, 64) fset = map[string]struct&#123;&#125;&#123;&#125; // fields' names hasPtr = false // records whether at least one struct-field is a pointer hasGCProg = false // records whether a struct-field type has a GCProg ) ... ... &#125; 3. 小结 使用一致的变量声明是 Go 语言的一个最佳实践，我们用一幅图将变量声明形式做个形象化的小结： 从图中我们看到要想做好代码中变量声明的一致性，我们需要明确要声明的变量是包级变量还是局部变量、是否要延迟初始化、是否接受默认类型、是否是分支控制变量并结合聚类和就近原则。 } 08 Go 标识符的命名惯例 10 无类型常量让代码更简化 扫码加入慕课前沿技术核心用户群 验证信息：2010312025386365复制 QQ讨论群号：729941811 QQ群URL：点击访问 若遇到搜索不到QQ群或加群失败，请联系客服邮箱:kf@imooc.com"},{"title":"","date":"2024-03-12T03:55:12.943Z","updated":"2024-03-12T03:55:12.943Z","comments":true,"path":"book/10无类型常量让代码更简化慕课专栏.html","permalink":"https://smartxia.github.io/blog/book/10%E6%97%A0%E7%B1%BB%E5%9E%8B%E5%B8%B8%E9%87%8F%E8%AE%A9%E4%BB%A3%E7%A0%81%E6%9B%B4%E7%AE%80%E5%8C%96%E6%85%95%E8%AF%BE%E4%B8%93%E6%A0%8F.html","excerpt":"","text":"10 无类型常量让代码更简化-慕课专栏 10 无类型常量让代码更简化 更新时间：2020-09-29 09:36:05 我们活着不能与草木同腐，不能醉生梦死，枉度人生，要有所作为。——方志敏 1. Go 常量溯源 我们先来回顾一下 C 语言。在 C 语言中，字面值（literal）担负着常量的角色（针对整型值，我们还可以使用枚举常量），我们可以使用整型、浮点型、字符串型、字符型字面值来应对不同场合对常量的需求： 0x12345678 10086 3.1415926 \"Hello, Gopher\" 'a' 为了不让这些魔数(magic number)充斥于源码各处，早期 C 语言的常用实践是使用宏(macro)来定义记号来指代这些字面值： #define MAX_LEN 0x12345678 #define CMCC_SERVICE_PHONE_NUMBER 10086 #define PI 3.1415926 #define WELCOME_TO_GO \"Hello, Gopher\" #define A_CHAR 'a' 这种定义有名字面值的实践也被称为宏定义常量。虽然后续的 C 标准中提供了 const 关键字来定义在程序运行过程中不可改变的变量（又称只读变量），但使用宏定义常量的习惯依然被沿袭下来，并且依旧是 C 编码中的主流风格。 宏定义的常量有着诸多不足，比如： 仅是预编译阶段进行替换的字面值，继承了宏替换的复杂性和易错性； 类型不安全； 无法在调试时通过宏名字输出常量的值。 而 C 语言中的 const 修饰的标识符本质上依旧是变量，和其他变量一样，编译器不能像真正的常量那样对其进行代码优化，也无法做为数组初始长度。 Go 语言是站在 C 语言等编程语言的肩膀之上诞生的，它原生提供常量定义的关键字 const。Go 语言中的 const 整合了 C 语言中宏定义常量、const 只读变量和枚举常量三种形式，并消除了每种形式的不足，使得 Go 常量是类型安全且对编译器优化友好的。Go 中所有与常量有关的声明都通过 const 来进行，例如： // $GOROOT/src/os/file.go const ( // Exactly one of O_RDONLY, O_WRONLY, or O_RDWR must be specified. O_RDONLY int = syscall.O_RDONLY // open the file read-only. O_WRONLY int = syscall.O_WRONLY // open the file write-only. O_RDWR int = syscall.O_RDWR // open the file read-write. // The remaining values may be or'ed in to control behavior. O_APPEND int = syscall.O_APPEND // append data to the file when writing. O_CREATE int = syscall.O_CREAT // create a new file if none exists. O_EXCL int = syscall.O_EXCL // used with O_CREATE, file must not exist. O_SYNC int = syscall.O_SYNC // open for synchronous I/O. O_TRUNC int = syscall.O_TRUNC // truncate regular writable file when opened. ) 上面这段标准库中的代码通过 const 声明了一组常量，如果非要进一步细分，可以将这组常量视为枚举的整型常量。然而你可能没想到，上面对常量的声明方式仅仅是 Go 标准库中的少数个例，绝大多数情况下，Go 常量在声明时并不显式指定类型，也就是说使用的是无类型常量（untyped constants）。比如： // $GOROOT/src/io/io.go // Seek whence values. const ( SeekStart = 0 // seek relative to the origin of the file SeekCurrent = 1 // seek relative to the current offset SeekEnd = 2 // seek relative to the end ) 无类型常量是 Go 语言在语法设计方面的一个“微创新”，也是“追求简单”设计哲学的又一次体现，它可以让你的 Go 代码更加简化，接下来我们就来看看无类型常量是如何简化 Go 代码编写的。 2. 有类型常量带来的“烦恼” Go 语言是对类型安全要求十分严格的语言。Go 要求即便两个类型拥有着相同的底层类型（underlying type），但是它们仍然是不同的数据类型，因此它们不可以被相互比较或混在一个表达式中进行运算： type myInt int func main() &#123; var a int = 5 var b myInt = 6 fmt.Println(a + b) // invalid operation: a + b (mismatched types int and myInt) &#125; 我们看到 Go 在处理不同类型的变量间运算时不支持隐式类型转换，Go 设计者认为隐式转换带来的便利性不足以抵消其带来的诸多问题1，因此要解决上面的编译错误，我们必须进行显式地转型： type myInt int func main() &#123; var a int = 5 var b myInt = 6 fmt.Println(a + int(b)) // 输出：11 &#125; 而有类型常量与变量混合在一起进行运算求值时也要遵循这一要求，即如果有类型常量与变量的类型不同，那么混合运算的求值操作会报错： type myInt int const n myInt = 13 const m int = n + 5 // cannot use n + 5 (type myInt) as type int in const initializer func main() &#123; var a int = 5 fmt.Println(a + n) // invalid operation: a + n (mismatched types int and myInt) &#125; 唯有通过显式转型才能让上面代码正常工作： type myInt int const n myInt = 13 const m int = int(n) + 5 func main() &#123; var a int = 5 fmt.Println(a + int(n)) // 输出：18 &#125; 有类型常量给代码简化带来了麻烦，但这也是 Go 语言对类型安全严格要求的结果。 3. 无类型常量消除烦恼，简化代码 我们现在有下面这些字面值： 5 3.1415926 \"Hello, Gopher\" 'a' false 我们挑选三个字面值以魔数的形式直接参与到变量赋值运算中： type myInt int type myFloat float32 type myString string func main() &#123; var j myInt = 5 var f myFloat = 3.1415926 var str myString = \"Hello, Gopher\" fmt.Println(j) // 输出：5 fmt.Println(f) // 输出：3.1415926 fmt.Println(str) // 输出：Hello, Gopher &#125; 我们看到这三个字面值无需显式转型就可以直接赋值给对应的三个自定义类型的变量，这等价于下面代码： var j myInt = myInt(5) var f myFloat = myFloat(3.1415926) var str myString = myString(\"Hello, Gopher\") 但显然之前的无需显式转型的代码更为简单。 Go 的无类型常量恰恰就拥有像字面值这样的特性，该特性使得无类型常量在参与变量赋值和计算过程无需显式转型，从而达到简化代码的目的： const ( a = 5 pi = 3.1415926 s = \"Hello, Gopher\" c = 'a' b = false ) type myInt int type myFloat float32 type myString string func main() &#123; var j myInt = a var f myFloat = pi var str myString = s fmt.Println(j) // 输出：5 fmt.Println(f) // 输出：3.1415926 fmt.Println(str) // 输出：Hello, Gopher &#125; 我们看到无类型常量使得在 Go 这样的具有强类型系统的语言中处理表达式混合数据类型运算时具有较大的灵活性，代码编写也有简化，我们无需在求值表达式中做任何显式转型了。 除此之外，无类型常量也拥有自己的默认类型：无类型的布尔型常量、无类型的整数常量、无类型的字符常量、无类型的浮点数常量、无类型的复数常量、无类型的字符串常量分别对应的默认类型为 bool、int、int32(rune)、float64、complex128 和 string。当常量被赋值给无类型变量、接口变量时，常量默认类型对于确定无类型变量的类型以及接口对应动态类型是至关重要的： const ( a = 5 s = \"Hello, Gopher\" ) func main() &#123; n := a var i interface&#123;&#125; = a fmt.Printf(\"%T\\n\", n) // 输出：int fmt.Printf(\"%T\\n\", i) // 输出：int i = s fmt.Printf(\"%T\\n\", i) // 输出：string &#125; 4. 小结 所有常量表达式的求值计算都可以在编译期完成的，而不是在运行期，这样可以减少运行时的工作，也方便编译器进行编译优化。当操作数是常量时，一些运行时的错误也可以在编译时被发现，例如整数除零、字符串索引越界等。 无类型常量是 Go 语言推荐的实践，它拥有和字面值一样的灵活特性，可以直接用于更多的表达式而不需要显式的类型转换，简化了代码编写。同时按照 Go 官方语言规范2描述，数值型无类型常量还可以提供比基础类型更高精度的算术运算，你可以认为至少有 256bit 的运算精度。 https://golang.org/doc/faq#conversions ↩︎ https://golang.org/ref/spec#Constants ↩︎ } 09 变量声明形式尽量保持一致 11 Go“枚举常量”的惯用实现方法 扫码加入慕课前沿技术核心用户群 验证信息：2010312025386365复制 QQ讨论群号：729941811 QQ群URL：点击访问 若遇到搜索不到QQ群或加群失败，请联系客服邮箱:kf@imooc.com"},{"title":"","date":"2024-03-12T03:55:12.944Z","updated":"2024-03-12T03:55:12.944Z","comments":true,"path":"book/11Go“枚举常量”的惯用实现方法慕课专栏.html","permalink":"https://smartxia.github.io/blog/book/11Go%E2%80%9C%E6%9E%9A%E4%B8%BE%E5%B8%B8%E9%87%8F%E2%80%9D%E7%9A%84%E6%83%AF%E7%94%A8%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%B3%95%E6%85%95%E8%AF%BE%E4%B8%93%E6%A0%8F.html","excerpt":"","text":"11 Go“枚举常量”的惯用实现方法-慕课专栏 11 Go“枚举常量”的惯用实现方法 更新时间：2020-10-27 09:51:11 没有引发任何行动的思想都不是思想，而是梦想。 —— 马丁 C 家族（C-Family）的主流编程语言，如 C++、Java 等都提供了定义枚举常量的语法。在 C 语言中，枚举是一个命名的整型常数的集合，下面是我们使用枚举定义的 Weekday 类型： // C语法 enum Weekday &#123; SUNDAY, MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY &#125;; int main() &#123; enum Weekday d = SATURDAY; printf(\"%d\\n\", d); // 6 &#125; C 语言针对枚举类型还提供了很多语法上的便利，比如：如果没有显式给枚举常量赋初始值，那么枚举类型的第一个常量的值为 0，后续常量的值依次加 1。与使用 define 宏定义的常量相比，C 编译器可以对专用的枚举类型做严格的类型检查，使得程序更为安全。 枚举的存在代表了一类现实需求： 有限数量标识符构成的集合，且多数情况下并不关心集合中标识符实际对应的值 注重类型安全 与其他 C 家族主流语言（如 C++、Java）不同，Go 语言没有提供定义枚举常量的语法。我们通常使用常量语法定义枚举常量，比如用 Go 来定义上面的 Weekday： const ( Sunday = 0 Monday = 1 Tuesday = 2 Wednesday = 3 Thursday = 4 Friday = 5 Saturday = 6 ) 如果仅仅能支持到这种程度，那么 Go 就算不上是“站在巨人的肩膀上”了。首先 Go 的 const 语法提供了“隐式重复前一个非空表达式”的机制，比如下面代码： const ( Apple, Banana = 11, 22 Strawberry, Grape Pear, Watermelon ) 常量定义的后两行没有显式给予初始赋值，Go 编译器将为其隐式使用第一行的表达式，这样上述定义等价于： const ( Apple, Banana = 11, 22 Strawberry, Grape = 11, 22 Pear, Watermelon = 11, 22 ) 不过这显然无法满足“枚举”的要求。Go 在这个机制的基础上又提供了iota“神器”，有了 iota，我们就可以定义满足各种场景的枚举常量了。 iota 是 Go 语言的一个预定义标识符，它表示的含义是 const 声明块（包括单行声明）中每个常量所处位置在块中的偏移值（从零开始）。同时，每一行中的 iota 自身也是一个无类型常量，可以像上一节所提到的无类型常量那样自动参与到不同类型的求值过程中，而无需对其进行显式转型操作。 下面是 Go 标准库中 sync/mutex.go 中的一段枚举常量的定义： // $GOROOT/src/sync/mutex.go (go 1.12.7) const ( mutexLocked = 1 &lt;&lt; iota // mutex is locked mutexWoken mutexStarving mutexWaiterShift = iota starvationThresholdNs = 1e6 ) 这是一个很典型的诠释 iota 含义的例子，我们逐行来看： mutexLocked = 1 &lt;&lt; iota 这里是 const 声明块的第一行，iota 的值是该行在 const 块中的偏移，因此 iota 的值为 0，我们得到 mutexLocked 这个常量的值为 1 &lt;&lt; 0，即 1； mutexWorken 这里是 const 声明块的第二行，由于没有显式的常量初始化表达式，根据 const 声明块的“隐式重复前一个非空表达式”的机制，该行等价于 mutexWorken = 1 &lt;&lt; iota。该行为 const 块中的第二行，因此偏移量 iota 的值为 1，我们得到 mutexWorken 这个常量的值为 1&lt;&lt; 1，即 2； mutexStarving 该常量同 mutexWorken，该行等价于 mutexStarving = 1 &lt;&lt; iota，由于在该行的 iota 的值为 2，因此我们得到 mutexStarving 这个常量的值为 1 &lt;&lt; 2，即 4; mutexWaiterShift = iota 这一行的常量初始化表达式与前三行不同，由于该行为第四行，iota 的偏移值为 3，因此 mutexWaiterShift 的值就为 3。 位于同一行的 iota 即便出现多次，其值也是一样的： const ( Apple, Banana = iota, iota + 10 // 0, 10 (iota = 0) Strawberry, Grape // 1, 11 (iota = 1) Pear, Watermelon // 2, 12 (iota = 2) ) 如果我们要略过 iota = 0，而从 iota = 1 开始正式定义枚举常量，我们可以效仿下面代码： // $GOROOT/src/syscall/net_js.go go 1.12.7 const ( _ = iota IPV6_V6ONLY SOMAXCONN SO_ERROR ) 如果我们要略过某一行，也可以使用类似方式: const ( _ = iota // 0 Pin1 Pin2 Pin3 _ Pin5 // 5 ) iota 的加入让 Go 在枚举常量定义上面的表达力大增： 我们看到和传统 C 枚举常量相比，Go 提供的 iota 预定义标识符可以参与到常量的初始化表达式的计算中，这样我们可以以更为灵活的形式为枚举常量赋予初值。而传统 C 语言的枚举仅可以以已经定义了的常量参与到其他常量的初始值表达式中。比如： C代码： enum Season &#123; spring, summer = spring + 2, fall = spring + 3, winter = fall + 1 &#125;; 和带有 iota（行偏移值）的初始化表达式相比，在阅读上面这段代码时，如果要对 winter 进行求值，我们还要向上查询 fall 的值和 spring 的值。 Go 的枚举常量可不限于整型值，定义浮点型枚举常量也可以。 C 语言无法定义浮点类型的枚举常量，但 Go 语言可以，这其中的部分功劳要归功于 Go 无类型常量。 const ( PI = 3.1415926 // π PI_2 = 3.1415926 / (2 * iota) // π/2 PI_4 // π/4 ) iota 让你维护枚举常量“列表”更容易 我们使用传统的枚举常量声明方式声明一组“颜色”常量： const ( Black = 1 Red = 2 Yellow = 3 ) 常量按照首字母顺序排序。假如我们要增加一个颜色 Blue，根据字母序，这个新常量应该放在 Red 的前面，但这样一来，我们就需要将 Red 到 Yellow 的常量值都手动+1，十分费力。 const ( Blue = 1 Black = 2 Red = 3 Yellow = 4 ) 我们使用 iota 重新定义这组“颜色”枚举常量： const ( _ = iota Blue Red Yellow ) 现在无论后期增加多少种颜色，我们只需将常量名插入到对应位置即可，其他无需做任何手工调整。 使用有类型枚举常量保证类型安全。 枚举常量多数也是无类型常量。如果要严格考虑类型安全，可以定义有类型枚举常量。下面是 Go 标准库中一段定义有类型枚举常量的例子： // $GOROOT/src/time/time.go type Weekday int const ( Sunday Weekday = iota Monday Tuesday Wednesday Thursday Friday Saturday ) 这样，后续要使用 Sunday~Saturday 这些有类型枚举常量，必须匹配 Weekday 类型的变量。 最后，我还要提一个“反例”。在一些枚举常量名称与其初始值有强烈对应关系的时候，枚举常量会直接使用显式数值作为常量的初始值，这样的情况极其少见，在 Go 标准库中我仅找到这一处： // $GOROOT/bytes/buffer.go // Don't use iota for these, as the values need to correspond with the // names and comments, which is easier to see when being explicit. const ( opRead readOp = -1 // Any other read operation. opInvalid readOp = 0 // Non-read operation. opReadRune1 readOp = 1 // Read rune of size 1. opReadRune2 readOp = 2 // Read rune of size 2. opReadRune3 readOp = 3 // Read rune of size 3. opReadRune4 readOp = 4 // Read rune of size 4. ) } 10 无类型常量让代码更简化 12 定义“零值可用”的类型 扫码加入慕课前沿技术核心用户群 验证信息：2010312025386365复制 QQ讨论群号：729941811 QQ群URL：点击访问 若遇到搜索不到QQ群或加群失败，请联系客服邮箱:kf@imooc.com"},{"title":"","date":"2024-03-12T03:55:12.944Z","updated":"2024-03-12T03:55:12.944Z","comments":true,"path":"book/12定义“零值可用”的类型慕课专栏.html","permalink":"https://smartxia.github.io/blog/book/12%E5%AE%9A%E4%B9%89%E2%80%9C%E9%9B%B6%E5%80%BC%E5%8F%AF%E7%94%A8%E2%80%9D%E7%9A%84%E7%B1%BB%E5%9E%8B%E6%85%95%E8%AF%BE%E4%B8%93%E6%A0%8F.html","excerpt":"","text":"12 定义“零值可用”的类型-慕课专栏 12 定义“零值可用”的类型 更新时间：2020-10-09 10:18:08 横眉冷对千夫指，俯首甘为孺子牛。——鲁迅 保持零值有用 - Go 谚语 1. Go 类型的零值 作为 C 程序员出身的我，我总是喜欢用在使用 C 语言的”受过的苦“与 Go 语言中得到的”甜头“做比较，从而来证明 Go 语言设计者在当初设计 Go 语言时是做了充分考量的。 在 C99 规范中，有一段是否对栈上局部变量进行自动清零初始化的描述： 如果未显式初始化且具有自动存储持续时间的对象，则其值是不确定的。 规范的用语总是晦涩难懂的。这句话大致的意思就是：如果是在栈上分配的局部变量，且在声明时未对其进行显式初始化，那么这个变量的值是不确定的。比如： // varinit.c #include &lt;stdio.h&gt; static int cnt; void f() &#123; int n; printf(\"local n = %d\\n\", n); if (cnt &gt; 5) &#123; return; &#125; cnt++; f(); &#125; int main() &#123; f(); return 0; &#125; 编译上面的程序并执行： // 环境 centos linux gcc 版本 4.1.2 // 注意：在您的环境中执行上述代码，输出的结果很大可能与这里有所不同 $ gcc varinit.c $ ./a.out local n = 0 local n = 10973 local n = 0 local n = 52 local n = 0 local n = 52 local n = 52 我们看到分配在栈上的未初始化变量的值是不确定的，虽然一些编译器的较新版本也都提供一些命令行参数选项用于对栈上变量进行零值初始化，比如 GCC 就提供如下命令行选项： -finit-local-zero -finit-derived -finit-integer=n -finit-real=&lt;zero|inf|-inf|nan|snan&gt; -finit-logical=&lt;true|false&gt; -finit-character=n 但这并不能改变 C 语言原生不支持对未显式初始化局部变量进行零值初始化的事实。资深 C 程序员是深知这个陷阱带来的问题是有多严重的。因此同样出身于 C 语言的 Go 设计者们在 Go 中彻底对这个问题进行的修复和优化。根据Go 语言规范： 当通过声明或调用new为变量分配存储空间，或者通过复合文字字面量或make调用创建新值， 并且还不提供显式初始化的情况下，Go会为变量或值提供默认值。 Go 语言的每种原生类型都有其默认值，这个默认值就是这个类型的零值。下面是 Go 规范定义的内置原生类型的默认值（零值）。 所有整型类型：0 浮点类型：0.0 布尔类型：false 字符串类型：\"\" 指针、interface、slice、channel、map、function：nil 另外 Go 的零值初始是递归的，即诸如数组、结构体等类型的零值初始化就是对其组成元素逐一进行零值初始化。 2. 零值可用 我们现在知道了 Go 类型的零值，接下来我们来说“可用”。 Go 从诞生以来就秉承着尽量保持“零值可用”的理念，我们来看两个例子。 第一个例子是关于 slice 的： var zeroSlice []int zeroSlice = append(zeroSlice, 1) fmt.Println(zeroSlice) // 输出：[1] 我们声明了一个 []int 类型的 slice：zeroSlice，我们并没有对其进行显式初始化，这样 zeroSlice 这个变量被 Go 编译器置为零值：nil。按传统的思维，对于值为 nil 这样的变量我们要给其赋上合理的值后才能使用。但是 Go 具备零值可用的特性，我们可以直接对其使用 append 操作，并且不会出现引用 nil 的错误。 第二个例子是通过 nil 指针调用方法的： // callmethodthroughnilpointer.go package main import ( \"fmt\" \"net\" ) func main() &#123; var p *net.TCPAddr fmt.Println(p) //输出：&lt;nil&gt; &#125; 我们声明了一个 net.TCPAddr 的指针变量，我们并未对其显式初始化，指针变量 p 会被 Go 编译器赋值为 nil。我们在标准输出上输出该变量，fmt.Println 会调用 p.String()。我们来看看 TCPAddr 这个类型的 String 方法实现： // $GOROOT/src/net/tcpsock.go func (a *TCPAddr) String() string &#123; if a == nil &#123; return \"&lt;nil&gt;\" &#125; ip := ipEmptyString(a.IP) if a.Zone != \"\" &#123; return JoinHostPort(ip+\"%\"+a.Zone, itoa(a.Port)) &#125; return JoinHostPort(ip, itoa(a.Port)) &#125; 我们看到 Go 标准库在定义 TCPAddr 类型以及其方法时充分考虑了“零值可用”的理念，使得通过值为 nil 的 TCPAddr 指针变量依然可以调用 String 方法。 在 Go 标准库和运行时代码中还有很多践行“零值可用”理念的好例子，最典型的莫过于 sync.Mutex 和 bytes.Buffer 了。 我们先来看看 sync.Mutex。在 C 语言中，如果我们要使用线程互斥锁，我们需要这么做： pthread_mutex_t mutex; // 不能直接使用 // 必须先进行初始化 pthread_mutex_init (&amp;mutex, NULL); // 然后才能执行lock或unlock pthread_mutex_lock(&amp;mutex); pthread_mutex_unlock(&amp;mutex); 但是在 Go 语言中，我们只需这么做： var mu sync.Mutex mu.Lock() mu.Unlock() Go 标准库的设计者很“贴心”地将 sync.Mutex 结构体的零值状态设计为可用状态，这样让 Mutex 的调用者可以“省略”对 Mutex 的初始化而直接使用 Mutex。 Go 标准库中的 bytes.Buffer 亦是如此： // bytesbufferwrite.go package main import ( \"bytes\" ) func main() &#123; var b bytes.Buffer b.Write([]byte(\"Effective Go\")) fmt.Println(b.String()) // 输出：Effective Go &#125; 我们看到我们无需对 bytes.Buffer 类型的变量 b 进行任何显式初始化即可直接通过 b 调用其方法进行写入操作，这源于 bytes.Buffer 底层存储数据的是同样支持零值可用策略的 slice 类型： // $GOROOT/src/bytes/buffer.go // A Buffer is a variable-sized buffer of bytes with Read and Write methods. // The zero value for Buffer is an empty buffer ready to use. type Buffer struct &#123; buf []byte // contents are the bytes buf[off : len(buf)] off int // read at &amp;buf[off], write at &amp;buf[len(buf)] lastRead readOp // last read operation, so that Unread* can work correctly. &#125; 3. 小结 Go 语言零值可用的理念给内置类型、标准库的使用者带来很多便利。不过 Go 并非所有类型都是零值可用的，并且零值可用也是有一定限制的，比如：slice 的零值可用不能通过下标形式操作数据： var s []int s[0] = 12 // 报错！ s = append(s, 12) // OK 另外像 map 这样的内置类型也没有提供零值可用的支持： var m map[string]int m[\"tonybai\"] = 1 // 报错！ m1 := make(map[string]int m1[\"tonybai\"] = 1 // OK 另外零值可用的类型要注意尽量避免值拷贝： var mu sync.Mutex mu1 := mu // Error: 避免值拷贝 foo(mu) // Error: 避免值拷贝 我们可以通过指针方式传递类似 Mutex 这样的类型。 对于我们 Go 开发者而言，保持与 Go 一致的理念，给自定义的类型一个合理的零值，并坚持保持自定义类型是零值可用的，这样我们的 Go 代码会表现的更加符合 Go 惯用法。 } 11 Go“枚举常量”的惯用实现方法 13 用复合字面值作初值构造器 扫码加入慕课前沿技术核心用户群 验证信息：2010312025386365复制 QQ讨论群号：729941811 QQ群URL：点击访问 若遇到搜索不到QQ群或加群失败，请联系客服邮箱:kf@imooc.com"},{"title":"","date":"2024-03-12T03:55:12.944Z","updated":"2024-03-12T03:55:12.944Z","comments":true,"path":"book/13用复合字面值作初值构造器慕课专栏.html","permalink":"https://smartxia.github.io/blog/book/13%E7%94%A8%E5%A4%8D%E5%90%88%E5%AD%97%E9%9D%A2%E5%80%BC%E4%BD%9C%E5%88%9D%E5%80%BC%E6%9E%84%E9%80%A0%E5%99%A8%E6%85%95%E8%AF%BE%E4%B8%93%E6%A0%8F.html","excerpt":"","text":"13 用复合字面值作初值构造器-慕课专栏 13 用复合字面值作初值构造器 更新时间：2020-10-12 10:37:23 知识是一种快乐，而好奇则是知识的萌芽。——培根 在上一节中，我们了解到了“零值可用”对于编写出符合 Go 惯用法的代码是大有裨益的。但有些时候，零值并非是最好的选择，我们有必要要为变量赋予适当的初值以保证其后续以正确的“状态”参与到业务流程计算中去，尤其是 Go 语言中的一些类型为复合类型的变量。Go 语言中的复合类型包括结构体、数组、切片和 map。 对于复合类型变量，最常见的值构造方式就是对其内部元素做逐个赋值，比如： var s myStruct s.name = \"tony\" s.age = 23 var a [5]int a[0] = 13 a[1] = 14 ... ... a[4] = 17 sl := make([]int, 5, 5) sl[0] = 23 sl[1] = 24 ... ... sl[4] = 27 m := make(map[int]string) m[1] = \"hello\" m[2] = \"gopher\" m[3] = \"!\" 但这样的值构造方式让代码显得有些“繁琐”，尤其是在构造组成较为复杂的复合类型变量初值的时候。Go 提供的复合字面值（composite literals）语法可以作为复合类型变量的初值构造器。使用复合字面值上述代码可以改写成下面这样： s := myStruct &#123;\"tony\", 23&#125; a := [5]int&#123;13, 14, 15, 16, 17&#125; sl := []int&#123;23, 24, 25, 26, 27&#125; m := map[int]string &#123;1:\"hello\", 2:\"gopher\", 3:\"!\"&#125; 显然，代码得到了很大的简化。 我们看到复合字面值由两部分组成，一部分是类型，比如上述例子中赋值操作符右侧的 myStruct、[5]int、[]int、map[int]string，另外一部分是由大括号 {} 包裹的字面值。这里的字面值形式还仅仅是 Go 复合字面值作为值构造器的基本用法。下面我们来分别看看复合字面值对于不同复合类型的“高级用法”。 1. 结构体复合字面值 使用 go vet 工具对 Go 源码进行过静态代码分析的童鞋们可能会知道，go vet 工具中默认内置了一条检查规则：“composites”。下面是源码中对该规则的描述： 此分析器对源码中使用复合字面值对struct变量赋值的行为进行诊断： 如果源码使用从另一个包(package)中导入的struct类型，但不使用field:value语法形式进行值构造的，分析器认为这样的复合字面值是脆弱的。因为一旦结构体增加了一个新的字段（即使未导出），这种值构造方式也将导致编译失败。 举个例子： err = &amp;net.DNSConfigError&#123;err&#125; 应该替换为： err = &amp;net.DNSConfigError&#123;Err: err&#125; Go 推荐使用 “field:value” 格式的复合字面值形式对 struct 类型变量进行值构造，这种值构造方式可以降低结构体类型使用者与结构体类型设计者之间的耦合。这也是 Go 语言的惯用法，在 Go 标准库中，通过\"field:value\"格式复合字面值进行结构体类型变量初值构造的例子比比皆是： // $GOROOT/src/net/http/transport.go var DefaultTransport RoundTripper = &amp;Transport&#123; Proxy: ProxyFromEnvironment, DialContext: (&amp;net.Dialer&#123; Timeout: 30 * time.Second, KeepAlive: 30 * time.Second, DualStack: true, &#125;).DialContext, MaxIdleConns: 100, IdleConnTimeout: 90 * time.Second, TLSHandshakeTimeout: 10 * time.Second, ExpectContinueTimeout: 1 * time.Second, &#125; // $GOROOT/src/io/pipe.go type pipe struct &#123; wrMu sync.Mutex // Serializes Write operations wrCh chan []byte rdCh chan int once sync.Once // Protects closing done done chan struct&#123;&#125; rerr atomicError werr atomicError &#125; func Pipe() (*PipeReader, *PipeWriter) &#123; p := &amp;pipe&#123; wrCh: make(chan []byte), rdCh: make(chan int), done: make(chan struct&#123;&#125;), &#125; return &amp;PipeReader&#123;p&#125;, &amp;PipeWriter&#123;p&#125; &#125; 我们看到这种 “field:value” 形式的复合字面值初值构造器颇为强大。和之前普通复合字面值形式相比，“field:value” 形式字面值中的字段可以以任意次序出现，未显式出现在字面值的结构体中的字段将采用其对应类型的零值。以上面的 pipe 为例，Pipe 函数在使用复合字面值对其类型变量进行初值构造时仅对 wrCh、rdCh 和 done 做了 “field:value” 形式的显式赋值，这样 pipe 结构体中的其他变量的值将为其类型的初值，比如 wrMu。 从上面例子我们还可以看到：通过在复合字面值值构造器的类型前面增加&amp;，我们可以得到对应类型的指针类型变量，如上面例子中的 p 的类型为 Pipe 类型指针。 复合字面值作为结构体值构造器的大量使用，使得即便采用类型零值时我们也会使用字面值构造器形式： s := myStruct&#123;&#125; 而较少使用 new 这一个 Go 预定义的函数来创建结构体变量实例： s := new(myStruct) 值得注意的是：使用从其他包导入的结构体中的未导出字段作为复合字面值中的 field 是不被允许的，会导致编译错误。 2. 数组/切片复合字面值 和结构体类型不同，数组/切片使用下标（index）作为 “field:value” 形式中 “field”，从而实现数组/切片初始元素值的高级构造形式： numbers := [256]int&#123;'a': 8, 'b': 7, 'c': 4, 'd': 3, 'e': 2, 'y': 1, 'x': 5&#125; // [10]float&#123;-1, 0, 0, 0, -0.1, -0.1, 0, 0.1, 0, -1&#125; fnumbers := [...]float&#123;-1, 4: -0.1, -0.1, 7:0.1, 9: -1&#125; // $GOROOT/src/sort/search_test.go var data = []int&#123;0: -10, 1: -5, 2: 0, 3: 1, 4: 2, 5: 3, 6: 5, 7: 7, 8: 11, 9: 100, 10: 100, 11: 100, 12: 1000, 13: 10000&#125; var sdata = []string&#123;0: \"f\", 1: \"foo\", 2: \"foobar\", 3: \"x\"&#125; 和结构体复合字面值较多采用 “field:value” 形式作为值构造器不同的是，数组/切片由于其固有的特性，采用 “index:value” 为其构造初值主要应用在少数场合，比如：为非连续（稀疏）元素构造初值（上面的 numbers、fnumbers)、让编译器根据最大元素下标值推导数组的 Size（如上面的 fnumbers）等。 另外在编写单元测试时，为了更显著体现元素对应的下标值，可能会使用 “index:value” 形式来为数组/切片进行值构造，如上面标准库单元测试源码中的 data、sdata。 3. map 复合字面值 和结构体、数组/切片相比，map 类型变量使用复合字面值作为初值构造器就显得自然了许多，因为 map 类型具有原生的 “key:value” 抽象形式： // $GOROOT/src/time/format.go var unitMap = map[string]int64&#123; \"ns\": int64(Nanosecond), \"us\": int64(Microsecond), \"µs\": int64(Microsecond), // U+00B5 = micro symbol \"μs\": int64(Microsecond), // U+03BC = Greek letter mu \"ms\": int64(Millisecond), \"s\": int64(Second), \"m\": int64(Minute), \"h\": int64(Hour), &#125; // $GOROOT/src/net/http/server.go type ConnState int const ( StateNew ConnState = iota StateActive StateIdle StateHijacked StateClosed ) var stateName = map[ConnState]string&#123; StateNew: \"new\", StateActive: \"active\", StateIdle: \"idle\", StateHijacked: \"hijacked\", StateClosed: \"closed\", &#125; 对于数组/切片类型而言，当元素的类型为复合类型时，我们可以省去元素复合字面量中的类型，比如： type Point struct &#123; x float64 y float64 &#125; sl := []Point&#123; &#123;1.2345, 6.2789&#125;, // Point&#123;1.2345, 6.2789&#125; &#123;2.2345, 19.2789&#125;, // Point&#123;2.2345, 19.2789&#125; &#125; 但是对于 map 类型而言，这一优化在 Go 1.5 中才得以引入。引入后，当 key 或 value 的类型为复合类型时，我们可以省去 key 或 value 中的复合字面量中的类型： // Go 1.5版本之前: m := map[Point]string&#123; Point&#123;29.935523, 52.891566&#125;: \"Persepolis\", Point&#123;-25.352594, 131.034361&#125;: \"Uluru\", Point&#123;37.422455, -122.084306&#125;: \"Googleplex\", &#125; vs. // Go 1.5版本及之后 m := map[Point]string&#123; &#123;29.935523, 52.891566&#125;: \"Persepolis\", &#123;-25.352594, 131.034361&#125;: \"Uluru\", &#123;37.422455, -122.084306&#125;: \"Googleplex\", &#125; m1 := map[string]Point&#123; \"Persepolis\": &#123;29.935523, 52.891566&#125;, \"Uluru\": &#123;-25.352594, 131.034361&#125;, \"Googleplex\": &#123;37.422455, -122.084306&#125;, &#125; 对于 key 或 value 为指针类型的情况，我们也可以省略 “&amp;T”： m2 := map[string]*Point&#123; \"Persepolis\": &#123;29.935523, 52.891566&#125;, // &amp;Point &#123;29.935523, 52.891566&#125; \"Uluru\": &#123;-25.352594, 131.034361&#125;, // &amp;Point&#123;-25.352594, 131.034361&#125; \"Googleplex\": &#123;37.422455, -122.084306&#125;, // &amp;Point&#123;37.422455, -122.084306&#125; &#125; fmt.Println(m2) // map[Googleplex:0xc0000ae050 Persepolis:0xc0000ae030 Uluru:0xc0000ae040] 4. 小结 对于零值不适用的场景，我们要为变量赋予一定的初值。对于复合类型而言，我们应该首选 Go 提供的复合字面值作为初值构造器。对于不同复合类型，我们要记住下面几点： 使用 “field:value” 形式的复合字面值为结构体类型的变量赋初值； 在为稀疏元素赋值或让编译器推导数组 Size 的时候，多使用 “index:value” 的形式为数组/切片类型变量赋初值； 使用 “key:value” 形式的复合字面值为 map 类型的变量赋初值。 } 12 定义“零值可用”的类型 14 深入理解和高效运用切片(slice) 扫码加入慕课前沿技术核心用户群 验证信息：2010312025386365复制 QQ讨论群号：729941811 QQ群URL：点击访问 若遇到搜索不到QQ群或加群失败，请联系客服邮箱:kf@imooc.com"},{"title":"","date":"2024-03-12T03:55:12.944Z","updated":"2024-03-12T03:55:12.944Z","comments":true,"path":"book/14深入理解和高效运用切片(slice)慕课专栏.html","permalink":"https://smartxia.github.io/blog/book/14%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%92%8C%E9%AB%98%E6%95%88%E8%BF%90%E7%94%A8%E5%88%87%E7%89%87(slice)%E6%85%95%E8%AF%BE%E4%B8%93%E6%A0%8F.html","excerpt":"","text":"14 深入理解和高效运用切片(slice)-慕课专栏 14 深入理解和高效运用切片(slice) 更新时间：2020-10-14 10:25:38 要成就一件大事业，必须从小事做起。——列宁 每当您花费大量时间使用某种特定工具时，深入了解它并了解如何高效地使用它是很值得的。- 佚名 slice，中文多译为“切片”，是 Go 语言在数组之上提供的一个重要的抽象数据类型。在 Go 语言中，绝大多数需要使用数组的场合，切片都实现了完美替代。并且和数组相比，切片提供了更通用、功能更强大且便捷的数据序列访问接口。 1. 切片究竟是什么 在对切片一探究竟之前，我们先来简略了解一下 Go 语言中的数组。 Go 语言数组是一个固定长度的、容纳同构类型元素的连续序列。因此 Go 数组类型具有两个属性：元素类型和数组长度。但凡这两个属性相同的数组类型是等价的。比如下面变量 a、b、c 对应的数组类型是三个不同的数组类型： var a [8]int var b [8]byte var c [9]int 变量 a、b 对应的数组类型长度属性相同，但元素类型不同（一个是 int，一个是 byte）；变量 a、c 对应的数组类型的元素类型相同，都是 int，但数组类型的长度不（一个是 8，一个是 9）。 Go 的数组是值语义，这意味着一个数组变量表示的是整个数组，这点与 C 语言完全不同。在 C 语言中，数组变量可视为指向数组第一个元素的指针。因此，在 Go 语言中传递数组是纯粹的值拷贝，对于元素类型 Size 较大或元素个数较多的数组，如果直接以数组类型参数传递到函数中会有不小的性能损耗。这时很多人会使用数组指针类型来定义函数参数，然后将数组地址传进函数，这样做的确可以避免性能损耗，但这是 C 语言的惯用法，在 Go 语言中，更地道的方式是使用切片。 切片之于数组就像是文件描述符之于文件。在 Go 语言中，数组更多是“退居幕后”，承担的是底层存储空间的角色；而切片则走向“前台”，为底层的存储（数组）打开了一个访问的“窗口”。 图3-5-1：切片打开访问底层数组的“窗口” 因此，我们可以称切片是数组的“描述符”。切片之所以能在函数参数传递时避免较大性能损耗也是因为它是“描述符”的特性，切片这个描述符是固定大小的，无论底层的数组元素类型有多大和切片打开的窗口长度有多长。 下面是切片在 Go 运行时（runtime）层面的内部表示： //$GOROOT/src/runtime/slice.go type slice struct &#123; array unsafe.Pointer len int cap int &#125; 我们看到每个切片包含三个字段： array：是指向下层数组某元素的指针，该元素也是切片的起始元素； len：是切片的长度，即切片中当前元素的个数； cap：是切片的最大容量，cap &gt;= len。 在运行时中，每个切片变量都是一个 runtime.slice 结构体的实例。我们用下面语句创建一个 slice 实例： s := make([]byte, 5) 下面的图展示了切片的内部表示： 图3-5-2：切片运行时表示（新切片） 我们看到通过上述语句创建的切片，编译器会自动为切片建立一个底层数组，如果没有在 make 中指定 cap 参数，那么 cap = len，即编译器建立的数组长度为 len。 我们还可以创建对已存在数组进行操作的切片，这种语法 u[low:max] 称为数组的切片化： u := [10]byte&#123;11, 12, 13, 14, 15, 16, 17, 18, 19, 20&#125; s := u[3:7] 我们用另外一幅图看看这个切片的内部表示： 图3-5-3：切片运行时表示（以已有数组为底层存储的切片） 我们看到切片 s 为我们打开了一个操作数组 u 的窗口，我们通过 s 看到的第一个元素是 u[3]，我们通过 s 能看到并操作的数组元素为 4 个（max-low）。切片的 cap 值取决于底层数组的长度。我们看到从切片 s 的第一个元素 s[0]，即 u[3] 到数组末尾一共有 7 个元素，因此切片 s 的 cap 为 7。 我们可以为一个已存在数组建立多个操作数组的切片。 图3-5-4：切片运行时表示(基于统一数组建立多个切片） 我们看到既然上图中的三个切片 s1、s2、s3 都是数组 u 的“描述符”，那么无论通过哪个切片对数组进行的修改操作都会反映到其他切片中。比如：将 s3[0] 置为 24，那么 s1[2] 也会变成 24，因为 s3[0]直接操作的是底层数组 u 的第四个元素 u[3]。 当切片作为函数参数传递给函数时，实际传递的就是切片的内部表示，也就是上面的 runtime.slice 结构体实例，因此无论切片“描述”的底层数组有多大，切片作为参数传递带来的性能损耗都是小到可以忽略不计的。这就是为什么函数在参数中多使用切片而不用数组指针的原因之一。当然另外一个原因就是切片可以提供比指针更为强大的功能，比如下标访问、边界溢出校验、动态扩容等。指针本身在 Go 语言中的功能也受到的限制，比如不支持指针算术运算。 2. 切片的高级特性：动态扩容 如果仅仅是提供通过下标值来操作元素的类数组操作接口，那么切片就不会在 Go 中占据重要的位置。Go 切片还支持一个重要的高级特性：动态扩容。在“第 11 条 尽量定义零值可用的类”一节中我们提到过切片类型是“部分”满足零值可用理念的，即零值切片也可以通过 append 预定义函数进行元素赋值操作： var s []byte // s被赋予零值nil s = append(s, 1) 由于初值为零值，s 这个“描述符”并没有绑定对应的底层数组。而经过 append 操作后，s 显然已经“绑定”了属于它的底层数组。为了方便查看切片是如何动态扩容的，我们打印出每次 append 后的 s 的 len 和 cap 值： // slice_append.go var s []int // s被赋予零值nil s = append(s, 11) fmt.Println(len(s), cap(s)) //1 1 s = append(s, 12) fmt.Println(len(s), cap(s)) //2 2 s = append(s, 13) fmt.Println(len(s), cap(s)) //3 4 s = append(s, 14) fmt.Println(len(s), cap(s)) //4 4 s = append(s, 15) fmt.Println(len(s), cap(s)) //5 8 我们看到 s 的 len 值是线性增长的，但 cap 值却呈现出不规则的变化。通过下图我们可以更容易看清楚多次 append 操作究竟是如何让 slice 进行动态扩容的。 图3-5-5：切片动态扩容 我们看到 append 会根据 slice 对底层数组容量的需求对底层数组进行动态调整： 最初 s 初值为零值(nil)，此时 s 没有“绑定”底层数组； 通过 append 操作向切片 s 添加一个元素 11，此时 append 会首先分配底层数组 u1（数组长度 1），然后将 s 内部表示中的 array 指向 u1，并设置 len = 1, cap = 1; 通过 append 操作向切片 s 再添加一个元素 12，此时 len(s) = 1，cap(s) = 1，append 判断底层数组剩余空间不足以满足添加新元素的要求，于是创建了一个新的底层数组 u2，长度为 2（u1 数组长度的 2 倍），并将 u1 中的元素拷贝到 u2 中，最后将 s 内部表示中的 array 指向 u2，并设置 len = 2, cap = 2； 通过 append 操作向切片 s 再添加一个元素 13，此时 len(s) = 2，cap(s) = 2，append 判断底层数组剩余空间不足以满足添加新元素的要求，于是创建了一个新的底层数组 u3，长度为 4（u2 数组长度的 2 倍），并将 u2 中的元素拷贝到 u3 中，最后将 s 内部表示中的 array 指向 u3，并设置 len = 3, cap 为 u3 数组长度，即 4 ； 通过 append 操作向切片 s 再添加一个元素 14，此时 len(s) = 3, cap(s) = 4，append 判断底层数组剩余空间可以满足添加新元素的要求，于是将 14 放在下一个元素的位置（数组 u3 末尾），并将 s 内部表示中的 len 加 1，变为 4； 通过 append 操作向切片 s 添加最后一个元素 15，此时 len(s) = 4，cap(s) = 4，append 判断底层数组剩余空间不足以满足添加新元素的要求，于是创建了一个新的底层数组 u4，长度为 8（u3 数组长度的 2 倍），并将 u3 中的元素拷贝到 u4 中，最后将 s 内部表示中的 array 指向 u4，并设置 len = 5, cap 为 u4 数组长度，即 8。 我们看到 append 会根据 slice 的需要，在当前底层数组容量无法满足的情况下，动态分配新的数组，新数组长度会按一定规律扩展（这里针对元素是 int 型的数组，新数组的容量为当前数组的 2 倍。其他类型的扩展系数可能有所不同），新数组建立后，append 会把旧数组中的数据 copy 到新数组中，之后新数组便成为了 slice 的底层数组，旧数组会被垃圾回收掉。 append 操作有些时候会给 Gopher 带来一些困惑，比如通过语法 u[low:max] 形式进行数组切片化而创建的切片，一旦切片 cap 触碰到数组的上界，再对切片进行 append，切片就会和原数组的解除“绑定”： // slice_unbind_orig_array.go package main import \"fmt\" func main() &#123; u := []int&#123;11, 12, 13, 14, 15&#125; fmt.Println(\"array:\", u) // [11, 12, 13, 14, 15] s := u[1:3] fmt.Printf(\"slice(len=%d, cap=%d): %v\\n\", len(s), cap(s), s) // [12, 13] s = append(s, 24) fmt.Println(\"after append 24, array:\", u) fmt.Printf(\"after append 24, slice(len=%d, cap=%d): %v\\n\", len(s), cap(s), s) s = append(s, 25) fmt.Println(\"after append 25, array:\", u) fmt.Printf(\"after append 25, slice(len=%d, cap=%d): %v\\n\", len(s), cap(s), s) s = append(s, 26) fmt.Println(\"after append 26, array:\", u) fmt.Printf(\"after append 26, slice(len=%d, cap=%d): %v\\n\", len(s), cap(s), s) s[0] = 22 fmt.Println(\"after reassign 1st elem of slice, array:\", u) fmt.Printf(\"after reassign 1st elem of slice, slice(len=%d, cap=%d): %v\\n\", len(s), cap(s), s) &#125; 运行这段代码，我们得到如下结果： $go run slice_unbind_orig_array.go array: [11 12 13 14 15] slice(len=2, cap=4): [12 13] after append 24, array: [11 12 13 24 15] after append 24, slice(len=3, cap=4): [12 13 24] after append 25, array: [11 12 13 24 25] after append 25, slice(len=4, cap=4): [12 13 24 25] after append 26, array: [11 12 13 24 25] after append 26, slice(len=5, cap=8): [12 13 24 25 26] after reassign 1st elem of slice, array: [11 12 13 24 25] after reassign 1st elem of slice, slice(len=5, cap=8): [22 13 24 25 26] 我们看到当 append 25 之后，切片的元素已经触碰到了底层数组 u 的边界；此后再 append 26 后，append 发现底层数组已经无法满足 append 的要求，于是新创建了一个底层数组（数组长度为 cap(s)的 2 倍，即 8），并将 slice 的元素拷贝到新数组中了。这之后，我们即便再修改 slice 的第一个元素值，原数组 u 的元素也没有发生任何改变了，因为此时切片 s 与数组 u 已经解除了“绑定关系”，s 已经不再是数组 u 的“描述符”了。 3. 尽量使用 cap 参数创建 slice 我们看到 append 操作是一并利器，它让 slice 类型部分满足了“零值可用”的理念。但从 append 的原理中我们也能看到重新分配底层数组并拷贝元素的操作代价还是蛮大的，尤其是当元素较多的情况下。那么如何减少或避免为过多内存分配和拷贝付出的代价呢？一种有效的方法就是根据 slice 的使用场景在为新创建的 slice 赋初值时使用 cap 参数。 s := make([]T, 0, cap) 下面是一个使用 cap 和不使用 cap 参数的 slice 的基准测试： // slice_benchmark_test.go package main import \"testing\" const sliceSize = 10000 func BenchmarkSliceInitWithoutCap(b *testing.B) &#123; for n := 0; n &lt; b.N; n++ &#123; sl := make([]int, 0) for i := 0; i &lt; sliceSize; i++ &#123; sl = append(sl, i) &#125; &#125; &#125; func BenchmarkSliceInitWithCap(b *testing.B) &#123; for n := 0; n &lt; b.N; n++ &#123; sl := make([]int, 0, sliceSize) for i := 0; i &lt; sliceSize; i++ &#123; sl = append(sl, i) &#125; &#125; &#125; 下面是基本测试运行的结果(go 1.12.7，macbook pro i5 8 核，16G 内存)： $go test -benchmem -bench=. slice_benchmark_test.go goos: darwin goarch: amd64 BenchmarkSliceInitWithoutCap-8 50000 36484 ns/op 386297 B/op 20 allocs/op BenchmarkSliceInitWithCap-8 200000 9250 ns/op 81920 B/op 1 allocs/op PASS ok command-line-arguments 4.163s 通过结果我们看到，使用 cap 参数创建的 slice 进行 append 操作的平均性能（9250ns）是不带 cap 参数的 slice（36484ns）的 4 倍左右，并且每操作平均仅需一次内存分配。 因此，如果可以预估出切片底层数组需要承载的元素数量，强烈建议在创建 slice 时带上 cap 参数。 4. 小结 切片是 Go 语言提供的重要数据类型，也是 Gopher 日常 Go 编码是最常使用的类型之一。切片是数组的“描述符”，在大多数场合替代了数组，并减少了数组指针作为函数参数的使用。 append 在切片上的运用让切片类型部分支持了零值可用的理念，并且 append 对 slice 的动态扩充将 Gopher 们从手工管理底层存储的工作中解放了出来。 在可以预估出元素容量的前提下，使用 cap 参数创建 slice 可以提升 append 的平均操作性能，减少或消除因动态扩容带来的性能损耗。 } 13 用复合字面值作初值构造器 15 注意：Go 字符串是原生类型 扫码加入慕课前沿技术核心用户群 验证信息：2010312025386365复制 QQ讨论群号：729941811 QQ群URL：点击访问 若遇到搜索不到QQ群或加群失败，请联系客服邮箱:kf@imooc.com"},{"title":"","date":"2024-03-12T03:55:12.945Z","updated":"2024-03-12T03:55:12.945Z","comments":true,"path":"book/15注意Go字符串是原生类型慕课专栏.html","permalink":"https://smartxia.github.io/blog/book/15%E6%B3%A8%E6%84%8FGo%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%98%AF%E5%8E%9F%E7%94%9F%E7%B1%BB%E5%9E%8B%E6%85%95%E8%AF%BE%E4%B8%93%E6%A0%8F.html","excerpt":"","text":"15 注意：Go 字符串是原生类型-慕课专栏 15 注意：Go 字符串是原生类型 更新时间：2020-10-19 16:56:55 才能一旦让懒惰支配，它就一无可为。——克雷洛夫 1. Go 语言的字符串类型 字符串类型是现代编程语言中最常使用的数据类型之一。在 Go 语言的先祖之一 C 语言当中，字符串类型并没有被显式定义，而是以字符串字面值常量或以’\\0’结尾的字符类型（char）数组来呈现的： #define GOAUTHERS \"Robert Griesemer, Rob Pike, and Ken Thompson\" const char * s = \"hello world\" char s[] = \"hello gopher\" 这给 C 程序员在使用字符串时带来一些问题，诸如： 类型安全性差； 字符串操作要时时刻刻考虑结尾的’\\0’； 字符串数据可变（主要指以字符数组形式定义的字符串类型）； 获取字符串长度代价大（O(n)时间复杂度）； 未内置对非 ASCII 字符（如中文字符）的处理。 Go 内置了 string 类型，统一了对“字符串”的抽象。这样无论是字符串常量、字符串变量或是代码中出现的字符串字面值，它们的类型都被统一设置为 string： // sources/string_type.go package main import \"fmt\" const ( s = \"string constant\" ) func main() &#123; var s1 string = \"string variable\" fmt.Printf(\"%T\\n\", s) // string fmt.Printf(\"%T\\n\", s1) // string fmt.Printf(\"%T\\n\", \"temporary string literal\") // string &#125; Go string 类型设计充分吸取了 C 语言字符串设计的经验教训，并结合了其他主流语言在字符串类型设计上的最佳实践，最终为 Gopher 呈现的 Go string 类型具有如下功能特点： string 类型的数据是不可变的 一旦声明了一个 string 类型的标识符，无论是变量还是变量，那么该标识符所指代的数据在整个程序的生命周期内便无法被更改。下面我来尝试修改一下 string 数据，看看能得到怎样的结果。先来看第一种方法： // sources/string_immutable1.go package main import ( \"fmt\" ) func main() &#123; // original string var s string = \"hello\" fmt.Println(\"original string:\", s) // reslice it and try to change the original string sl := []byte(s) sl[0] = 't' fmt.Println(\"slice:\", string(sl)) fmt.Println(\"after reslice, the original string is:\", string(s)) &#125; 该程序的运行结果如下： $go run string_immutable1.go original string: hello slice: tello after reslice, the original string is: hello 我们看到在例子中我们试图通过将 string 转换为一个 slice 并通过该 slice 对其内容进行修改，但结果事与愿违。对 string 进行 slice 转换后，Go 编译器会为 slice 变量重新分配底层存储而不是共用 string 的底层存储，因此对 slice 的修改并未对原 string 的数据产生任何影响。 我们再来试试通过更为“暴力”一些的手段对 string 的数据发起“攻击”： // sources/string_immutable2.go package main import ( \"fmt\" \"unsafe\" ) func main() &#123; // original string var s string = \"hello\" fmt.Println(\"original string:\", s) // try to change the original string through unsafe pointer modifyString(&amp;s) fmt.Println(s) &#125; func modifyString(s *string) &#123; // 取出第一个8字节的值 p := (*uintptr)(unsafe.Pointer(s)) // 获取底层数组的地址 var array *[5]byte = (*[5]byte)(unsafe.Pointer(*p)) var len *int = (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(s)) + unsafe.Sizeof((*uintptr)(nil)))) for i := 0; i &lt; (*len); i++ &#123; fmt.Printf(\"%p =&gt; %c\\n\", &amp;((*array)[i]), (*array)[i]) p1 := &amp;((*array)[i]) v := (*p1) (*p1) = v + 1 //try to change the character &#125; &#125; 我们试图通过 unsafe 指针指向 string 在运行时内部表示结构（具体参考本节后面的讲解）中的数据存储块的地址，然后通过指针修改那块内存中存储的数据。我们运行这段程序得到下面的结果： $go run string_immutable2.go original string: hello 0x10d1b9d =&gt; h unexpected fault address 0x10d1b9d fatal error: fault [signal SIGBUS: bus error code=0x2 addr=0x10d1b9d pc=0x109b079] 我们看到：对 string 的底层的数据存储区仅能做只读操作，一旦试图修改那块区域的数据，便会得到 SIGBUS 的运行时错误。 零值可用 Go string 类型支持零值可用的理念。Go 字符串无需像 C 语言中那样考虑结尾’\\0’字符，因此其零值为\"\"，长度为 0。 var s string fmt.Println(s) // s = \"\" fmt.Println(len(s)) // 0 获取长度的时间复杂度是 O(1) 级别 Go string 类型数据是不可变的，因此一旦有了初值后，那块数据就不会改变，其长度也不会改变。Go 将这个长度作为一个字段存储在了运行时的 string 类型结构中了（在本节后面有说明）。这样获取 string 长度的操作，即 len(s) 实际上就是读取存储在运行时中的那个长度值，这是一个代价极低的 O(1)操作。 支持通过+/+=操作符进行字符串连接 通过+/+=操作符进行的字符串连接是对开发者体验最好的字符串连接操作，Go 语言支持这种操作。 s := \"Rob Pike, \" s = s + \"Robert Griesemer, \" s += \" Ken Thompson\" fmt.Println(s) // Rob Pike, Robert Griesemer, Ken Thompson 支持各种比较关系操作符：==、!= 、&gt;=、&lt;=、&gt; 和 &lt; Go 支持各种比较关系操作符： // sources/string_compare.go package main import \"fmt\" func main() &#123; // == s1 := \"世界和平\" s2 := \"世界\" + \"和平\" fmt.Println(s1 == s2) // true // != s1 = \"Go\" s2 = \"C\" fmt.Println(s1 != s2) // true // &lt; and &lt;= s1 = \"12345\" s2 = \"23456\" fmt.Println(s1 &lt; s2) // true fmt.Println(s1 &lt;= s2) // true // &gt; and &gt;= s1 = \"12345\" s2 = \"123\" fmt.Println(s1 &gt; s2) // true fmt.Println(s1 &gt;= s2) // true &#125; 鉴于 Go string 是不可变的，因此如果两个字符串的 length 不相同，那么无需比较具体字符串数据，也可以断定两个字符串是不同的；如果 length 相同，则要进一步判断数据指针是否指向同一块底层存储数据。如果相同，则两个字符串是等价的，如果不同，则还需进一步去比对实际的数据内容。 对非 ASCII 字符提供原生支持 Go 源文件的字符编码默认为 UTF-8 编码。UTF-8 编码是目前市面上最流行的字符编码格式，囊括了几乎所有主流非 ASCII 字符（包括汉语字符）。Go string 类型也是以 UTF-8 编码作为内码存储将对应的文本存储在内存当中的。我们来看一个例子： // sources/string_nonascii.go package main import \"fmt\" func main() &#123; // 中文字符 Unicode CodePoint(码点) UTF8编码 // 中 U+4E2D E4B8AD // 国 U+56FD E59BBD // 欢 U+6B22 E6ACA2 // 迎 U+8FCE E8BF8E // 您 U+60A8 E682A8 s := \"中国欢迎您\" rs := []rune(s) sl := []byte(s) for i, v := range rs &#123; var utf8Bytes []byte for j := i * 3; j &lt; (i+1)*3; j++ &#123; utf8Bytes = append(utf8Bytes, sl[j]) &#125; fmt.Printf(\"%s =&gt; %X =&gt; %X\\n\", string(v), v, utf8Bytes) &#125; &#125; $go run string_nonascii.go 中 =&gt; 4E2D =&gt; E4B8AD 国 =&gt; 56FD =&gt; E59BBD 欢 =&gt; 6B22 =&gt; E6ACA2 迎 =&gt; 8FCE =&gt; E8BF8E 您 =&gt; 60A8 =&gt; E682A8 我们看到字符串变量 s 中存储的文本是”中国欢迎你“五个汉字字符（非 ASCII 字符范畴），这里我们输出了每个中文字符对应的 Unicode 码点（Code Point，见输出结果的第二列），一个 rune 对应一个码点。UTF-8 编码是 Unicode 码点的一种字符编码形式，也是最常用的一种编码格式，也是 Go 默认的字符编码格式。我们还可以使用其他字符编码格式来映射 Unicode 码点，比如：UTF-16 等。 在 UTF-8 中，大多数中文字符都使用三个字节表示。[]byte(s)的转型让我们获得了 s 底层存储的“复制品”，从而我们得到了每个汉字字符对应的 UTF-8 编码字节(见输出结果的第三列)。 原生支持多行字符串 C 语言中要构造多行字符串，要么使用多个字符串的自然拼接，要么需要结合续行符\"\\\"，很难控制好格式： #include &lt;stdio.h&gt; char *s = \"好雨知时节，当春乃发生。\\n\" \"随风潜入夜，润物细无声。\\n\" \"野径云俱黑，江船火独明。\\n\" \"晓看红湿处，花重锦官城。\"; char *s1 = \"好雨知时节，当春乃发生。\\n\\ 随风潜入夜，润物细无声。\\n\\ 野径云俱黑，江船火独明。\\n\\ 晓看红湿处，花重锦官城。\"; int main() &#123; printf(\"%s\\n\", s); printf(\"%s\\n\", s1); &#125; Go 语言直接提供了通过反引号(`)构造“所见即所得”的多行字符串的方法： // sources/string_multilines.go package main import \"fmt\" const s = `好雨知时节，当春乃发生。 随风潜入夜，润物细无声。 野径云俱黑，江船火独明。 晓看红湿处，花重锦官城。` func main() &#123; fmt.Println(s) &#125; $go run string_multilines.go 好雨知时节，当春乃发生。 随风潜入夜，润物细无声。 野径云俱黑，江船火独明。 晓看红湿处，花重锦官城。 2. 字符串的内部表示 Go string 类型上述特性的实现与 Go 运行时对 string 类型的内部表示是分不开的。Go string 在运行时表示为下面结构： // $GOROOT/src/runtime/string.go type stringStruct struct &#123; str unsafe.Pointer len int &#125; 我们看到 string 类型也是一个“描述符”，它本身并不真正存储数据，而仅是由一个指向底层存储的指针和字符串的长度字段组成。我们结合一个 string 的实例化过程来看。下面是 runtime 包中实例化一个字符串对应的函数： // $GOROOT/src/runtime/string.go // rawstring allocates storage for a new string. The returned // string and byte slice both refer to the same storage. // The storage is not zeroed. Callers should use // b to set the string contents and then drop b. func rawstring(size int) (s string, b []byte) &#123; p := mallocgc(uintptr(size), nil, false) stringStructOf(&amp;s).str = p stringStructOf(&amp;s).len = size *(*slice)(unsafe.Pointer(&amp;b)) = slice&#123;p, size, size&#125; return &#125; 我们用下面示意图来表示 rawstring 调用后的一个 string 实例的状态： 图3-6-1 string类型在运行时的表示 我们看到每个字符串类型变量/常量对应一个 stringStruct 实例，经过 rawstring 实例化后，stringStruct 中的 str 指针指向真正存储字符串数据的底层内存区域，len 字段存储的是字符串的长度（这里是 5）；rawstring 同时还创建了一个临时的 slice，该 slice 的 array 指针也同样指向存储字符串数据的底层内存区域。注意 rawstring 调用后，新申请的内存区域还未被写入数据，该 slice 就是用于后续 runtime 层向其写入数据（“hello”）用的，写完数据后，该 slice 就可以被回收掉了，这也是上图中将 slice 结构以虚线框表示的原因。 通过 string 在运行时的表示我们可以得到这样一个结论，那就是我们直接将 string 类型通过函数/方法参数传入也不会有太多的损耗，因为传入的仅仅是一个“描述符”，而不是真正的字符串数据。我们可以通过一个简单的基准测试来验证一下： // sources/string_as_param_benchmark_test.go package main import ( \"testing\" ) var s string = `Go, also known as Golang, is a statically typed, compiled programming language designed at Google by Robert Griesemer, Rob Pike, and Ken Thompson. Go is syntactically similar to C, but with memory safety, garbage collection, structural typing, and communicating sequential processes (CSP)-style concurrency.` func handleString(s string) &#123; _ = s + \"hello\" &#125; func handlePtrToString(s *string) &#123; _ = *s + \"hello\" &#125; func BenchmarkHandleString(b *testing.B) &#123; for n := 0; n &lt; b.N; n++ &#123; handleString(s) &#125; &#125; func BenchmarkHandlePtrToString(b *testing.B) &#123; for n := 0; n &lt; b.N; n++ &#123; handlePtrToString(&amp;s) &#125; &#125; 运行该基准测试： $go test -bench . -benchmem string_as_param_benchmark_test.go goos: darwin goarch: amd64 BenchmarkHandleString-8 15668872 70.7 ns/op 320 B/op 1 allocs/op BenchmarkHandlePtrToString-8 15809401 71.8 ns/op 320 B/op 1 allocs/op PASS ok command-line-arguments 2.407s 我们看到直接传入 string 与传入 string 指针两者的基准测试结果几乎一模一样。Gopher 们大可放心地直接使用 string 作为函数/方法参数类型。 3. 字符串的高效构造 前面提到过，Go 原生支持通过 +/+= 操作符来连接多个字符串以构造一个更长的字符串，并且通过 +/+= 操作符的字符串连接构造是最自然、开发体验最好的一种。但 Go 还提供了其他一些构造字符串的方法，比如： 使用 fmt.Sprintf 使用 strings.Join 使用 strings.Builder 使用 bytes.Buffer 在这些方法中哪种方法更为高效呢？我们使用基准测试的数据来做参考： // sources/string_concat_benchmark_test.go package main import ( \"bytes\" \"fmt\" \"strings\" \"testing\" ) var sl []string = []string&#123; \"Rob Pike \", \"Robert Griesemer \", \"Ken Thompson \", &#125; func concatStringByOperator(sl []string) string &#123; var s string for _, v := range sl &#123; s += v &#125; return s &#125; func concatStringBySprintf(sl []string) string &#123; var s string for _, v := range sl &#123; s = fmt.Sprintf(\"%s%s\", s, v) &#125; return s &#125; func concatStringByJoin(sl []string) string &#123; return strings.Join(sl, \"\") &#125; func concatStringByStringsBuilder(sl []string) string &#123; var b strings.Builder for _, v := range sl &#123; b.WriteString(v) &#125; return b.String() &#125; func concatStringByStringsBuilderWithInitSize(sl []string) string &#123; var b strings.Builder b.Grow(64) for _, v := range sl &#123; b.WriteString(v) &#125; return b.String() &#125; func concatStringByBytesBuffer(sl []string) string &#123; var b bytes.Buffer for _, v := range sl &#123; b.WriteString(v) &#125; return b.String() &#125; func concatStringByBytesBufferWithInitSize(sl []string) string &#123; buf := make([]byte, 0, 64) b := bytes.NewBuffer(buf) for _, v := range sl &#123; b.WriteString(v) &#125; return b.String() &#125; func BenchmarkConcatStringByOperator(b *testing.B) &#123; for n := 0; n &lt; b.N; n++ &#123; concatStringByOperator(sl) &#125; &#125; func BenchmarkConcatStringBySprintf(b *testing.B) &#123; for n := 0; n &lt; b.N; n++ &#123; concatStringBySprintf(sl) &#125; &#125; func BenchmarkConcatStringByJoin(b *testing.B) &#123; for n := 0; n &lt; b.N; n++ &#123; concatStringByJoin(sl) &#125; &#125; func BenchmarkConcatStringByStringsBuilder(b *testing.B) &#123; for n := 0; n &lt; b.N; n++ &#123; concatStringByStringsBuilder(sl) &#125; &#125; func BenchmarkConcatStringByStringsBuilderWithInitSize(b *testing.B) &#123; for n := 0; n &lt; b.N; n++ &#123; concatStringByStringsBuilderWithInitSize(sl) &#125; &#125; func BenchmarkConcatStringByBytesBuffer(b *testing.B) &#123; for n := 0; n &lt; b.N; n++ &#123; concatStringByBytesBuffer(sl) &#125; &#125; func BenchmarkConcatStringByBytesBufferWithInitSize(b *testing.B) &#123; for n := 0; n &lt; b.N; n++ &#123; concatStringByBytesBufferWithInitSize(sl) &#125; &#125; 运行该基准测试： $go test -bench=. -benchmem ./string_concat_benchmark_test.go goos: darwin goarch: amd64 BenchmarkConcatStringByOperator-8 11744653 89.1 ns/op 80 B/op 2 allocs/op BenchmarkConcatStringBySprintf-8 2792876 420 ns/op 176 B/op 8 allocs/op BenchmarkConcatStringByJoin-8 22923051 49.1 ns/op 48 B/op 1 allocs/op BenchmarkConcatStringByStringsBuilder-8 11347185 96.6 ns/op 112 B/op 3 allocs/op BenchmarkConcatStringByStringsBuilderWithInitSize-8 26315769 42.3 ns/op 64 B/op 1 allocs/op BenchmarkConcatStringByBytesBuffer-8 14265033 82.6 ns/op 112 B/op 2 allocs/op BenchmarkConcatStringByBytesBufferWithInitSize-8 24777525 48.1 ns/op 48 B/op 1 allocs/op PASS ok command-line-arguments 8.816s 从基准测试的输出结果的第三列，即每操作耗时的数值来看： 做了预初始化的 strings.Builder 连接构建字符串效率最高； 带有预初始化的 bytes.Buffer 和 strings.Join 两种方法不相伯仲，分列二三位； 未预初始的 strings.Builder、bytes.Buffer 和操作符连接在第三档次； fmt.Sprintf性能最差，排在末尾。 由此可以得出一些结论： 在能预估出最终字符串长度的情况下，使用预初始化的 strings.Builder 连接构建字符串效率最高； strings.Join 连接构造字符串的平均性能最稳定，如果输入的多个字符串是以[]string 承载，那么 strings.Join 也是不错的选择； 使用操作符连接的方式最直观、最自然；如果在编译器可以知晓预连接的字符串个数，那么使用此种方式可以得到编译器的优化处理； fmt.Sprintf 虽然效率不高，但也不是一无是处；如果是由多种不同类型变量来构造特定格式的字符串，那么这种方式还是最适合的。 4. 字符串相关的高效转换 在前面的例子中，我们看到了 string 到[]rune 以及 string 到[]byte 的转换，这两个转换也是可逆的，也就是说 string 和[]rune、[]byte 可以双向相互转换。下面就是从[]rune 或[]byte 反向转换为 string 的例子： // sources/string_slice_to_string.go package main import \"fmt\" func main() &#123; rs := []rune&#123; 0x4E2D, 0x56FD, 0x6B22, 0x8FCE, 0x60A8, &#125; s := string(rs) fmt.Println(s) sl := []byte&#123; 0xE4, 0xB8, 0xAD, 0xE5, 0x9B, 0xBD, 0xE6, 0xAC, 0xA2, 0xE8, 0xBF, 0x8E, 0xE6, 0x82, 0xA8, &#125; s = string(sl) fmt.Println(s) &#125; $go run string_slice_to_string.go 中国欢迎您 中国欢迎您 无论是 string 转 slice 还是 slice 转 string，转换都是要付出代价的，这些代价的根源在于 string 是不可变的，运行时要为转换后的类型分配新内存。我们以 byte slice 与 string 相互转换为例，看看转换过程的内存分配情况： // sources/string_mallocs_in_convert.go package main import ( \"fmt\" \"testing\" ) func byteSliceToString() &#123; sl := []byte&#123; 0xE4, 0xB8, 0xAD, 0xE5, 0x9B, 0xBD, 0xE6, 0xAC, 0xA2, 0xE8, 0xBF, 0x8E, 0xE6, 0x82, 0xA8, 0xEF, 0xBC, 0x8C, 0xE5, 0x8C, 0x97, 0xE4, 0xBA, 0xAC, 0xE6, 0xAC, 0xA2, 0xE8, 0xBF, 0x8E, 0xE6, 0x82, 0xA8, &#125; _ = string(sl) &#125; func stringToByteSlice() &#123; s := \"中国欢迎您，北京换欢您\" _ = []byte(s) &#125; func main() &#123; fmt.Println(testing.AllocsPerRun(1, byteSliceToString)) fmt.Println(testing.AllocsPerRun(1, stringToByteSlice)) &#125; 运行这个例子： $go run string_mallocs_in_convert.go 1 1 我们看到：针对\"中国欢迎您，北京换欢您\"这个长度的字符串，在 string 与 byte slice 互转的过程中都要有一次的内存分配操作。 在 Go 运行时层面，字符串与 rune slice、byte slice 相互转换对应的函数如下： // $GOROOT/src/runtime/string.go slicebytetostring: []byte -&gt; string slicerunetostring: []rune -&gt; string stringtoslicebyte: string -&gt; []byte stringtoslicerune: string -&gt; []rune 我们以 byte slice 为例，看看 slicebytetostring 和 stringtoslicebyte 的实现： // $GOROOT/src/runtime/string.go // The constant is known to the compiler. // There is no fundamental theory behind this number. const tmpStringBufSize = 32 type tmpBuf [tmpStringBufSize]byte func stringtoslicebyte(buf *tmpBuf, s string) []byte &#123; var b []byte if buf != nil &amp;&amp; len(s) &lt;= len(buf) &#123; *buf = tmpBuf&#123;&#125; b = buf[:len(s)] &#125; else &#123; b = rawbyteslice(len(s)) &#125; copy(b, s) return b &#125; func slicebytetostring(buf *tmpBuf, b []byte) (str string) &#123; l := len(b) if l == 0 &#123; // Turns out to be a relatively common case. // Consider that you want to parse out data between parens in \"foo()bar\", // you find the indices and convert the subslice to string. return \"\" &#125; // ... ... 此处省略一些代码 if l == 1 &#123; stringStructOf(&amp;str).str = unsafe.Pointer(&amp;staticbytes[b[0]]) stringStructOf(&amp;str).len = 1 return &#125; var p unsafe.Pointer if buf != nil &amp;&amp; len(b) &lt;= len(buf) &#123; p = unsafe.Pointer(buf) &#125; else &#123; p = mallocgc(uintptr(len(b)), nil, false) &#125; stringStructOf(&amp;str).str = p stringStructOf(&amp;str).len = len(b) memmove(p, (*(*slice)(unsafe.Pointer(&amp;b))).array, uintptr(len(b))) return &#125; 欲要更高效地进行转换，唯一的方法就是减少和避免额外的内存分配操作。我们看到运行时实现转换的函数中已经加入了一些避免每种情况都要分配新内存操作的优化(比如：tmpBuf 的复用)。 slice 类型是不可比较的，而 string 类型是可比较的，因此在日常 Go 编码中，我们会经常遇到将 slice 临时转换为 string 的情况。Go 编译器为这样的场景提供了优化。在运行时中有一个名为 slicebytetostringtmp 的函数就是协助实现这一优化的： // $GOROOT/src/runtime/string.go func slicebytetostringtmp(b []byte) string &#123; if raceenabled &amp;&amp; len(b) &gt; 0 &#123; racereadrangepc(unsafe.Pointer(&amp;b[0]), uintptr(len(b)), getcallerpc(), funcPC(slicebytetostringtmp)) &#125; if msanenabled &amp;&amp; len(b) &gt; 0 &#123; msanread(unsafe.Pointer(&amp;b[0]), uintptr(len(b))) &#125; return *(*string)(unsafe.Pointer(&amp;b)) &#125; 该函数的“秘诀”就在于不为 string 新开辟一块内存，而是直接使用 slice 的底层存储。当然使用这个函数的前提是：在原 slice 被修改后，这个 string 不能再被使用了。因此这样的优化是针对特定场景的，包括： string(b)用在 map 类型的 key 中 b := []byte&#123;'k', 'e', 'y'&#125; m := make(map[string]string) m[string(b)] = \"value\" m[[3]string&#123;string(b), \"key1\", \"key2\"&#125;] = \"value1\" string(b)用在字符串连接语句中 b := []byte&#123;'t', 'o', 'n', 'y'&#125; s := \"hello \" + string(b) + \"!\" string(b)用于字符串比较中 s := \"tom\" b := []byte&#123;'t', 'o', 'n', 'y'&#125; if s &lt; string(b) &#123; ... ... &#125; Go 编译器对用在 for-range 循环中的 string 到[]byte 的转换也有优化处理，Go 编译器不会为[]byte 做额外的内存分配，而是直接使用 string 的底层数据。我们看下面例子： // sources/string_for_range_covert_optimize.go package main import ( \"fmt\" \"testing\" ) func convert() &#123; s := \"中国欢迎您，北京欢迎您\" sl := []byte(s) for _, v := range sl &#123; _ = v &#125; &#125; func convertWithOptimize() &#123; s := \"中国欢迎您，北京欢迎您\" for _, v := range []byte(s) &#123; _ = v &#125; &#125; func main() &#123; fmt.Println(testing.AllocsPerRun(1, convert)) fmt.Println(testing.AllocsPerRun(1, convertWithOptimize)) &#125; 运行这个例子程序： $go run string_for_range_covert_optimize.go 1 0 从结果我们看到，convertWithOptimize 函数将 string 到[]byte 的转换放在 for-range 循环中，Go 编译器对其进行了优化，节省了一次内存分配操作。 在如今的强大的硬件算力面前，少数的几次 string 和 slice 的转换代价可能微不足道。但能充分理解 Go 编译器对 string 和 slice 互转在特定场景下的优化依然是大有裨益的。在性能敏感的领域，这些优化也许能起到大作用。 5. 小结 在本小节中，我们了解到 Go 语言内置了 string 类型，统一了对字符串的抽象，并且为 string 类型提供了强大的内置操作支持，包括：基于 +/+= 的字符串连接操作、基于 =、!=、&gt;、&lt; 等的比较操作、O(1) 复杂度的长度获取操作、对非 ASCII 字符提供原生支持、对 string 类型与 slice 类型的相互转换提供优化等。 与此同时，Go 语言还在标准库中提供了 strings 和 strconv 包，可以辅助 Gopher 们对 string 类型数据进行更多高级操作。鉴于篇幅有限，这里就不赘述了，大家可以自行查阅以上两个包的使用说明文档。 } 14 深入理解和高效运用切片(slice) 16 理解包导入路径的含义 扫码加入慕课前沿技术核心用户群 验证信息：2010312025386365复制 QQ讨论群号：729941811 QQ群URL：点击访问 若遇到搜索不到QQ群或加群失败，请联系客服邮箱:kf@imooc.com"},{"title":"","date":"2024-03-12T03:55:12.945Z","updated":"2024-03-12T03:55:12.945Z","comments":true,"path":"book/16理解包导入路径的含义慕课专栏.html","permalink":"https://smartxia.github.io/blog/book/16%E7%90%86%E8%A7%A3%E5%8C%85%E5%AF%BC%E5%85%A5%E8%B7%AF%E5%BE%84%E7%9A%84%E5%90%AB%E4%B9%89%E6%85%95%E8%AF%BE%E4%B8%93%E6%A0%8F.html","excerpt":"","text":"16 理解包导入路径的含义-慕课专栏 16 理解包导入路径的含义 更新时间：2020-10-21 10:33:30 才能一旦让懒惰支配，它就一无可为。——克雷洛夫 Go 语言是使用包（package）作为基本单元来组织源码的，可以说一个 Go 程序就是由一些包链接在一起构建而成的。虽然与 Java、Python 等语言相比这算不上什么创新，但与祖辈 C 语言的头文件包含机制相比则是“先进”了许多。 编译速度快是这种”先进性“的一个突出表现，即便是每次编译都是从零开始。Go 语言的这种以包为基本构建单元的构建模型使得依赖分析变得十分简单，避免了 C 语言那种通过头文件分析依赖的巨大开销。Go 编译速度快的原因具体体现在三个方面： Go 要求每个源文件在开头处显式地列出所有依赖的包导入，这样 Go 编译器不必读取和处理整个文件就可以确定其依赖的包列表； Go 要求包之间不能存在循环依赖，这样一个包的依赖关系便形成了一张有向无环图。由于无环，包可以被单独编译，也可以并行编译； 已编译的 Go 包对应的目标文件(file_name.o 或 package_name.a)中不仅记录了该包本身的导出符号信息，还记录了其所依赖包的导出符号信息。这样，Go 编译器在编译某包 P 时，针对 P 依赖的每个包导入(比如：导入包 Q)，只需读取一个目标文件即可（比如：Q 包编译成的目标文件，该目标文件中已经包含了 Q 包的依赖包的导出信息），而无需再读取其他文件中的信息了。 Go 语言中包的定义和使用十分简单。 通过 package 关键字声明 Go 源文件所属的包： // xx.go package a ... ... 上述源码表示：文件 xx.go 是包 a 的一部分。 使用 import 关键字导入依赖的标准库包或第三方包： package main import ( \"fmt\" // 标准库包导入 \"a/b/c\" // 第三方包导入 ) func main() &#123; c.Func1() fmt.Println(\"Hello, Go!\") &#125; 很多 Gopher 看到上面代码都会想当然地将 import 后面的 “c”、“fmt” 与 c.Func1()和 fmt.Println() 中的 c 和 fmt 认作为同一个语法元素：包名。但在深入学习 Go 语言后，大家会发现事实并非如此。比如在使用实时分布式消息框架 nsq 提供的官方 client 包时，我们包导入这样来写： import \"github.com/nsqio/go-nsq\" 但在使用该包提供的导出函数时，我们使用的不是 go-nsq.xx 而是 nsq.xxx： q, _ := nsq.NewConsumer(\"write_test\", \"ch\", config) 很多 Gopher 在学习 Go 包导入时都或多或少有些疑惑： import 后面路径中的最后一个分段到底代表的是什么? 是包名还是一个路径？本节我就和大家一起来深入探究和理解一下 Go 语言的包导入。 1. Go 程序构建过程 我们先来简单了解一下 Go 程序的构建过程，来作为后续理解 Go 包导入的前导知识。和主流静态编译型语言一样，Go 程序的构建简单来讲也是由编译（compile）和链接（link）两个阶段组成的。 一个非 main 包在编译后会对应生成一个.a 文件，该文件可以理解为是 Go 包的目标文件（实则是通过 pack 工具（$GOROOT/pkg/tool/darwin_amd64/pack）对 .o 文件打包后形成的 .a）。默认情况下在编译过程中 .a 文件生成在临时目录下，除非使用 go install 安装到 $GOPATH/pkg 下（Go 1.11 版本之前），否则你看不到 .a 文件。如果是构建可执行程序，那么 .a 文件会在构建可执行程序的链接阶段起使用。 标准库包的源码文件在$GOROOT/src 下面，而对应的 .a 文件存放在$GOROOT/pkg/darwin_amd64 下（以 MacOS 上为例;如果是 linux，则是 linux_amd64）： // Go 1.13 $tree -FL 1 $GOROOT/pkg/darwin_amd64 ├── archive/ ├── bufio.a ├── bytes.a ├── compress/ ├── container/ ├── context.a ├── crypto/ ├── crypto.a ├── database/ ├── debug/ ├── encoding/ ├── encoding.a ├── errors.a ├── expvar.a ├── flag.a ├── fmt.a ├── go/ ├── hash/ ├── hash.a ... ... “求甚解”的读者可能会提出这样的一个问题：构建 Go 程序时，编译器会重新编译依赖包的源文件还是直接链接包的.a 文件呢？我们通过一个实验来给大家答案。Go 1.10 版本引入了 build cache，为了避免 build cache 给实验过程和分析带来的复杂性，我们使用 Go 1.9.7 版本(Go 1.10 之前的版本均可）来进行这个实验。 我们建立如下实验环境的目录结构： $GOPATH/src/github.com/bigwhite/effective-go-book $tree -F chapter3-demo1 chapter3-demo1 ├── cmd/ │ └── app1/ │ └── main.go └── pkg/ └── pkg1/ └── pkg1.go 由于仅是演示目的，pkg1.go 和 main.go 的源码都很简单： // cmd/app1/main.go package main import ( \"github.com/bigwhite/effective-go-book/chapter3-demo1/pkg/pkg1\" ) func main() &#123; pkg1.Func1() &#125; // pkg/pkg1/pkg1.go package pkg1 import \"fmt\" func Func1() &#123; fmt.Println(\"pkg1.Func1 invoked\") &#125; 进入 chapter3-demo1，执行下面命令： $go install github.com/bigwhite/effective-go-book/chapter3-demo1/pkg/pkg1 之后，我们就可以在$GOPATH/pkg/darwin_amd64/github.com/bigwhite/effective-go-book/chapter3-demo1/pkg 下面看到 pkg1 包对应的目标文件 pkg1.a： $ls $GOPATH/pkg/darwin_amd64/github.com/bigwhite/effective-go-book/chapter3-demo1/pkg pkg1.a 我们继续在 chapter3-demo1 路径下编译可执行程序 app1： $go build github.com/bigwhite/effective-go-book/chapter3-demo1/cmd/app1 执行完上述命令后，我们会在 chapter3-demo1 下面看到一个可执行文件 app1，执行该文件： $GOPATH/src/github.com/bigwhite/effective-go-book/chapter3-demo1 $ls app1* cmd/ pkg/ $./app1 pkg1.Func1 invoked 这符合我们的预期。但现在我们仍无法知道编译 app1 是到底使用的是 pkg1 包的源码还是目标文件 pkg1.a，因为目前它们的输出都是一致的。我们修改一下 pkg1.go 的代码： // pkg/pkg1/pkg1.go package pkg1 import \"fmt\" func Func1() &#123; fmt.Println(\"pkg1.Func1 invoked - Again\") &#125; 重新编译执行 app1，我们得到结果如下： $go build github.com/bigwhite/effective-go-book/chapter3-demo1/cmd/app1 $./app1 pkg1.Func1 invoked - Again 这样的实验结果告诉我们：在使用第三方包的时候，当第三方包源码存在且对应的 .a 已安装的情况下，编译器链接的仍是根据第三方包最新源码编译出的 .a 文件，而不是之前已经安装到$GOPATH/pkg/darwin_amd64 下面的目标文件。 那么是否可以只链接依赖包的已安装的 .a 文件，而不用第三方包源码呢？我们临时删除掉 pkg1 目录，但保留之前已经 install 到 $GOPATH/pkg/darwin_amd64 下面的 pkg1.a 文件。我们再来编译一下 app1： $go build github.com/bigwhite/effective-go-book/chapter3-demo1/cmd/app1 cmd/app1/main.go:4:2: cannot find package \"github.com/bigwhite/effective-go-book/chapter3-demo1/pkg/pkg1\" in any of: /Users/tonybai/.bin/go1.9.7/src/github.com/bigwhite/effective-go-book/chapter3-demo1/pkg/pkg1 (from $GOROOT) /Users/tonybai/Go/src/github.com/bigwhite/effective-go-book/chapter3-demo1/pkg/pkg1 (from $GOPATH) 我们看到 Go 编译器报错！ Go 编译器还是尝试去找 pkg1 包的源码，而不是直接链接已经安装了的 pkg1.a。 下面我们让 Go 编译器输出详细信息，我们来看看为什么 Go 编译器会选择链接根据第三方包最新源码编译出的.a 文件，而不是之前已经安装到 $GOPATH/pkg/darwin_amd64 下面的目标文件。我们在编译 app1 时给 go build 命令传入 -x -v 命令行选项： $go build -x -v github.com/bigwhite/effective-go-book/chapter3-demo1/cmd/app1 WORK=/var/folders/cz/sbj5kg2d3m3c6j650z0qfm800000gn/T/go-build878870664 github.com/bigwhite/effective-go-book/chapter3-demo1/pkg/pkg1 mkdir -p $WORK/github.com/bigwhite/effective-go-book/chapter3-demo1/pkg/pkg1/_obj/ mkdir -p $WORK/github.com/bigwhite/effective-go-book/chapter3-demo1/pkg/ cd /Users/tonybai/Go/src/github.com/bigwhite/effective-go-book/chapter3-demo1/pkg/pkg1 /Users/tonybai/.bin/go1.9.7/pkg/tool/darwin_amd64/compile -o $WORK/github.com/bigwhite/effective-go-book/chapter3-demo1/pkg/pkg1.a -trimpath $WORK -goversion go1.9.7 -p github.com/bigwhite/effective-go-book/chapter3-demo1/pkg/pkg1 -complete -buildid 5508f4ff15d0000af68a19c84d5200be6b52aac0 -D _/Users/tonybai/Go/src/github.com/bigwhite/effective-go-book/chapter3-demo1/pkg/pkg1 -I $WORK -pack ./pkg1.go github.com/bigwhite/effective-go-book/chapter3-demo1/cmd/app1 mkdir -p $WORK/github.com/bigwhite/effective-go-book/chapter3-demo1/cmd/app1/_obj/ mkdir -p $WORK/github.com/bigwhite/effective-go-book/chapter3-demo1/cmd/app1/_obj/exe/ cd /Users/tonybai/Go/src/github.com/bigwhite/effective-go-book/chapter3-demo1/cmd/app1 /Users/tonybai/.bin/go1.9.7/pkg/tool/darwin_amd64/compile -o $WORK/github.com/bigwhite/effective-go-book/chapter3-demo1/cmd/app1.a -trimpath $WORK -goversion go1.9.7 -p main -complete -buildid d116bd4b4731d2f7eac18df2368f87eee7bc7977 -D _/Users/tonybai/Go/src/github.com/bigwhite/effective-go-book/chapter3-demo1/cmd/app1 -I $WORK -I /Users/tonybai/Go/pkg/darwin_amd64 -pack ./main.go cd . /Users/tonybai/.bin/go1.9.7/pkg/tool/darwin_amd64/link -o $WORK/github.com/bigwhite/effective-go-book/chapter3-demo1/cmd/app1/_obj/exe/a.out -L $WORK -L /Users/tonybai/Go/pkg/darwin_amd64 -extld=clang -buildmode=exe -buildid=d116bd4b4731d2f7eac18df2368f87eee7bc7977 $WORK/github.com/bigwhite/effective-go-book/chapter3-demo1/cmd/app1.a mv $WORK/github.com/bigwhite/effective-go-book/chapter3-demo1/cmd/app1/_obj/exe/a.out app1 我们看到 app1 的构建过程大致分为几步： 建立临时工作路径，命名为 WORK，以后的编译、链接均以$WORK 为当前工作目录； 编译 app1 的依赖包 pkg1，将目标文件打包后放入 $WORK/github.com/bigwhite/effective-go-book/chapter3-demo1/pkg/pkg1.a; 编译 app1 的 main 包，将目标文件打包后放入 $WORK/github.com/bigwhite/effective-go-book/chapter3-demo1/cmd/app1.a ; 链接器将 app1.a、pkg1.a 链接成 $WORK/github.com/bigwhite/effective-go-book/chapter3-demo1/cmd/app1/_obj/exe/a.out ; 最后，将 a.out 改名为 app1。这个 app1 是在执行 go build 命令的目录中。 我们细致看看链接器进行目标文件链接所执行的命令： /Users/tonybai/.bin/go1.9.7/pkg/tool/darwin_amd64/link -o $WORK/github.com/bigwhite/effective-go-book/chapter3-demo1/cmd/app1/_obj/exe/a.out -L $WORK -L /Users/tonybai/Go/pkg/darwin_amd64 -extld=clang -buildmode=exe -buildid=d116bd4b4731d2f7eac18df2368f87eee7bc7977 $WORK/github.com/bigwhite/effective-go-book/chapter3-demo1/cmd/app1.a 为了方便查看，我将这行命令中的一些不必要的信息去掉，命令简化后是这样的： link -o a.out -L $WORK -L $GOPATH/pkg/darwin_amd64 -buildmode=exe app1.a 我们在链接器的执行语句中并未显式看到 app1 链接的是 $WORK/github.com/bigwhite/effective-go-book/chapter3-demo1/pkg 下 pkg1.a。但是从传给链接器的-L 参数来看：$WORK 这个路径排在了$GOPATH/pkg/darwin_amd64 的前面。这样链接器会优先使用 $WORK 下面的 github.com/bigwhite/effective-go-book/chapter3-demo1/pkg/pkg1.a，而不是 $GOPATH/pkg/darwin_amd64/github.com/bigwhite/effective-go-book/chapter3-demo1/pkg/pkg1.a。 为了验证我们的推论，我们可按照编译器输出，按顺序手工执行了一遍上述命令序列，但在最后执行链接命令时，去掉 -L $WORK 或将 -L $WORK 放到 -L $GOPATH/pkg/darwin_amd64 的后面。考虑到篇幅原因，下面省略了中间的执行过程： $export WORK=/Users/tonybai/temp ... ... $/Users/tonybai/.bin/go1.9.7/pkg/tool/darwin_amd64/link -o $WORK/github.com/bigwhite/effective-go-book/chapter3-demo1/cmd/app1/_obj/exe/a.out -L /Users/tonybai/Go/pkg/darwin_amd64 -extld=clang -buildmode=exe -buildid=d116bd4b4731d2f7eac18df2368f87eee7bc7977 $WORK/github.com/bigwhite/effective-go-book/chapter3-demo1/cmd/app1.a ... ... 再执行这次手动执行命令序列的成果物： $./app1 pkg1.Func1 invoked 我们看到这回链接器链接的是 /Users/tonybai/Go/pkg/darwin_amd64 下面的 pkg1.a，输出的是 pkg1 包修改之前的打印信息。到这里我们明白了所谓的使用第三方包源码，实际上是链接了以该最新包源码编译的存放在临时目录下的包的.a 文件而已。 到这里肯定又会有读者会问题：Go 标准库中的包也是这样么？编译时 Go 编译器到底使用的是根据$GOROOT/src 下源码编译出的.a 目标文件，还是 $GOROOT/pkg 下已经随 Go 安装包编译好的.a 文件呢？我们再来做个实验！我们编写一个简单的 Go 文件： // main.go package main import \"fmt\" func main() &#123; b := true s := fmt.Sprintf(\"%t\", b) fmt.Println(s) &#125; 有了前面的经验，我们这次直接将 $GOROOT/src 下面的 fmt 目录改名为 fmtbak，然后编译上面的 main.go 文件： $go build -x -v main.go WORK=/var/folders/cz/sbj5kg2d3m3c6j650z0qfm800000gn/T/go-build682636466 main.go:3:8: cannot find package \"fmt\" in any of: /Users/tonybai/.bin/go1.9.7/src/fmt (from $GOROOT) /Users/tonybai/Go/src/fmt (from $GOPATH) 我们看到 Go 编译器找不到标准库的 fmt 包了，显然和依赖第三方包一样，依赖标准库包在编译时也是需要所依赖的标准库包的源码的。那如果我们修改了标准库的源码，是否会向上面实验中那样，源码更新直接会体现在最终的可执行文件的输出中呢？这里我们将 fmt 包的部分源码做一下修改(修改前，先把 fmtbak 改回 fmt)。我们对 fmt 目录下面的 format.go 文件做些微调： // $GOROOT/src/fmt/format.go // fmt_boolean formats a boolean. func (f *fmt) fmt_boolean(v bool) &#123; if v &#123; f.padString(\"true1\") // 我们修改这一行，原代码为：f.padString(\"true\") &#125; else &#123; f.padString(\"false\") &#125; &#125; 我们构建一下main.go： $go build -x -v main.go WORK=/var/folders/cz/sbj5kg2d3m3c6j650z0qfm800000gn/T/go-build972107899 command-line-arguments mkdir -p $WORK/command-line-arguments/_obj/ mkdir -p $WORK/command-line-arguments/_obj/exe/ cd /Users/tonybai/temp /Users/tonybai/.bin/go1.9.7/pkg/tool/darwin_amd64/compile -o $WORK/command-line-arguments.a -trimpath $WORK -goversion go1.9.7 -p main -complete -buildid 374bfe52ceb5beb2748735a34836d6348e6c1e21 -D _/Users/tonybai/temp -I $WORK -pack ./main.go cd . /Users/tonybai/.bin/go1.9.7/pkg/tool/darwin_amd64/link -o $WORK/command-line-arguments/_obj/exe/a.out -L $WORK -extld=clang -buildmode=exe -buildid=374bfe52ceb5beb2748735a34836d6348e6c1e21 $WORK/command-line-arguments.a mv $WORK/command-line-arguments/_obj/exe/a.out main 从输出的详细构建日志来看，编译器并没有去重新编译 format.go，因此编译出来的可执行文件的输出为： $./main true 而不是我们期望的\"true1\"。这说明默认情况下对于标准库中的包，编译器直接链接的是$GOROOT/pkg/darwin_amd64 下的.a 文件。 那么如何让编译器能去”感知“到标准库中的最新更新呢？以 fmt.a 为例，有两种方法： 方法 1：删除$GOROOT/pkg/darwin_amd64 下面的 fmt.a，然后重新执行 go install fmt ： $go install -x -v fmt WORK=/var/folders/cz/sbj5kg2d3m3c6j650z0qfm800000gn/T/go-build519257256 fmt mkdir -p $WORK/fmt/_obj/ mkdir -p $WORK/ cd /Users/tonybai/.bin/go1.9.7/src/fmt /Users/tonybai/.bin/go1.9.7/pkg/tool/darwin_amd64/compile -o $WORK/fmt.a -trimpath $WORK -goversion go1.9.7 -p fmt -std -complete -buildid 784aa2fc38b910a35f11bcd11372fa344f46ebed -D _/Users/tonybai/.bin/go1.9.7/src/fmt -I $WORK -pack ./doc.go ./format.go ./print.go ./scan.go mkdir -p /Users/tonybai/.bin/go1.9.7/pkg/darwin_amd64/ mv $WORK/fmt.a /Users/tonybai/.bin/go1.9.7/pkg/darwin_amd64/fmt.a 方法 2：使用 go build 的-a 命令行选项： go build -a 可以让编译器将 Go 源文件（比如例子中的 main.go）的所有直接和间接的依赖包（包括标准库）都重新编译一遍，并将最新的 .a 作为链接器的输入。因此，采用 -a 选项进行构建的时间较长，这里仅摘录与 fmt 包相关的日志供参考： $go build -x -v -a main.go WORK=/var/folders/cz/sbj5kg2d3m3c6j650z0qfm800000gn/T/go-build094236425 ... ... mkdir -p $WORK/fmt/_obj/ cd /Users/tonybai/.bin/go1.9.7/src/fmt /Users/tonybai/.bin/go1.9.7/pkg/tool/darwin_amd64/compile -o $WORK/fmt.a -trimpath $WORK -goversion go1.9.7 -p fmt -std -complete -buildid 784aa2fc38b910a35f11bcd11372fa344f46ebed -D _/Users/tonybai/.bin/go1.9.7/src/fmt -I $WORK -pack ./doc.go ./format.go ./print.go ./scan.go ... ... /Users/tonybai/.bin/go1.9.7/pkg/tool/darwin_amd64/link -o $WORK/command-line-arguments/_obj/exe/a.out -L $WORK -extld=clang -buildmode=exe -buildid=374bfe52ceb5beb2748735a34836d6348e6c1e21 $WORK/command-line-arguments.a mv $WORK/command-line-arguments/_obj/exe/a.out main 2. 究竟是路径名还是包名 通过前面的实验，我们了解到编译器在编译过程中必然要使用的是编译单元（一个包）所依赖的包的源码。而编译器要找到依赖包的源码文件就需要知道依赖包的源码路径。这个路径由两部分组成：基础搜索路径和包导入路径。 基础搜索路径是一个全局的设置，下面是关于基础搜索路径的规则描述： 所有包（无论标准库包还是第三方包）的源码基础搜索路径都包括 $GOROOT/src； 在上述基础搜索路径的基础上，不同版本的 Go 包含的其他基础搜索路径有不同： Go 1.11版本之前，包的源码基础搜索路径还包括 $GOPATH/src； Go 1.11-Go 1.12 版本，包的源码基础搜索路径有三种模式： 经典 gopath 模式下(GO111MODULE=off)：$GOPATH/src ； module-aware 模式下(GO111MODULE=on)：$GOPATH/pkg/mod ； auto 模式下(GO111MODULE=auto)：在$GOPATH/src 路径下，与 gopath 模式相同；在$GOPATH/src 路径外且包含 go.mod，与 module-aware 模式相同。 Go 1.13 版本，包的源码基础搜索路径有两种模式： 经典 gopath 模式下(GO111MODULE=off)：$GOPATH/src； module-aware 模式下(GO111MODULE=on/auto)：$GOPATH/pkg/mod； 未来的 Go 版本将只有 module-aware 模式，即只在 module 缓存的目录下搜索包的源码。 而搜索路径的第二部分就是位于每个包源码文件头部的包导入路径。基础搜索路径与包导入路径结合在一起，Go 编译器便可确定一个包的所有依赖包的源码路径的集合，这个集合构成了 Go 编译器的源码搜索路径空间。我们举个例子： // p1.go package p1 import ( \"fmt\" \"time\" \"github.com/bigwhite/effective-go-book\" \"golang.org/x/text\" \"a/b/c\" \"./e/f/g\" ) ... ... 我们以 Go 1.11 版本之前的 GOPATH 模式为例，编译器在编译上述 p1 包时，会构建自己的源码搜索路径空间，该空间对应的搜索路径集合包括： - $GOROOT/src/fmt/ - $GOROOT/src/time/ - $GOROOT/src/github.com/bigwhite/effective-go-book/ - $GOROOT/src/golang.org/x/text/ - $GOROOT/src/a/b/c/ - $GOPATH/src/github.com/bigwhite/effective-go-book/ - $GOPATH/src/golang.org/x/text/ - $GOPATH/src/a/b/c/ - $CWD/e/f/g 最后一个包导入路径\"./e/f/g\"是一个本地相对路径，它的基础搜索路径是 $CWD，即执行编译命令时的当前工作目录。Go compiler 在编译源码时会使用-D 选项设置当前工作目录，该工作目录与\"./e/f/g\"的本地相对路径结合，便构成了一个源码搜索路径。 到这里，我们已经给出了前面问题的答案：源文件头部的包导入语句 import 后面的部分就是一个路径，路径的最后一个分段也不是包名。我们再通过一个例子来证明这点。我们在$GOPATH/src/github.com/bigwhite/effective-go-book/chapter3-demo1 下面再建立 cmd/app2 和 pkg/pkg2 两个目录： $tree -LF 3 chapter3-demo1 chapter3-demo1 ├── cmd/ │ └── app2/ │ └── main.go └── pkg/ └── pkg2/ └── pkg2.go app2/main.go 和 pkg2/pkg2.go 的源码如下： // pkg2/pkg2.go package mypkg2 import \"fmt\" func Func1() &#123; fmt.Println(\"mypkg2.Func1 invoked\") &#125; // app2/main.go package main import ( \"github.com/bigwhite/effective-go-book/chapter3-demo1/pkg/pkg2\" ) func main() &#123; mypkg2.Func1() &#125; 编译运行 app2： $go build github.com/bigwhite/effective-go-book/chapter3-demo1/cmd/app2 $./app2 mypkg2.Func1 invoked 我们看到这个例子与 app1 的不同之处在于 app2 的包导入语句中的路径末尾是 pkg2，而在 main 函数中使用的包名却是 mypkg2，这再次印证了包导入语句中的只是一个路径。 不过 Go 语言有一个惯用法，那就是包导入路径的最后一段目录名最好与包名一致，就像 pkg1 那样： // app1/main.go package main import ( \"github.com/bigwhite/effective-go-book/chapter3-demo1/pkg/pkg1\" ) func main() &#123; pkg1.Func1() &#125; pkg1 包导入路径的最后一段目录名为 pkg1，而包名也是 pkg1。也就是说上面代码中出现的两个 pkg1 虽然书写上时一模一样的，但代表的含义是完全不同的：包导入路径上的 pkg1 表示的是一个目录名；而 main 函数体中的 pkg1 则是包名。 关于包导入，Go 语言还有另外一个惯用法：当包名与包导入路径中的最后一个目录名不同时，最好用下面语法将包名显式放入包导入语句。以上面 app2 为例： // app2/main.go package main import ( mypkg2 \"github.com/bigwhite/effective-go-book/chapter3-demo1/pkg/pkg2\" ) func main() &#123; mypkg2.Func1() &#125; 显然，这种惯用法让代码可读性更好。 3. 同一源码文件的依赖包在同一源码搜索路径空间下包名冲突的问题 同一个包名在不同的项目、不同的仓库下可能都会存在。同一个源码文件在其包导入路径构成源码搜索路径空间下很可能存在同名包。比如：我们有另外一个 chapter3-demo2，其下也有名为 pkg1 的包，导入路径为 github.com/bigwhite/effective-go-book/chapter3-demo2/pkg/pkg1。如果 cmd/app3 同时导入了 chapter3-demo1 和 chapter3-demo2 的 pkg1 包，那么会发生什么呢？ // cmd/app3 package main import ( \"github.com/bigwhite/effective-go-book/chapter3-demo1/pkg/pkg1\" \"github.com/bigwhite/effective-go-book/chapter3-demo2/pkg/pkg1\" ) func main() &#123; pkg1.Func1() &#125; 我们编译一下 cmd/app3： $go build github.com/bigwhite/effective-go-book/chapter3-demo1/cmd/app3 # github.com/bigwhite/effective-go-book/chapter3-demo1/cmd/app3 ./main.go:5:2: pkg1 redeclared as imported package name previous declaration at ./main.go:4:2 我们看到的确出现同名包冲突的问题了！怎么解决这个问题呢？我们还是用为包导入路径下的包起别名的方法： package main import ( pkg1 \"github.com/bigwhite/effective-go-book/chapter3-demo1/pkg/pkg1\" mypkg1 \"github.com/bigwhite/effective-go-book/chapter3-demo2/pkg/pkg1\" ) func main() &#123; pkg1.Func1() mypkg1.Func1() &#125; 上面的 pkg1 指代的就是 chapter3-demo1/pkg/pkg1 下面的包；mypkg1 则指代的是 chapter3-demo1/pkg/pkg1 下面的包。就此，同名包冲突问题就轻松解决掉了。 4. 小结 在本节中，我们通过实验对 Go 语言的包导入做了进一步的理解，Gopher 们应牢记以下几点结论： Go 编译器在编译过程中必然要使用的是编译单元（一个包）所依赖的包的源码； Go 源码文件头部的包导入语句中 import 后面的部分是一个路径，路径的最后一个分段是目录名，而不是包名； Go 编译器的包源码搜索路径由基本搜索路径和包导入路径组成。两者结合在一起后，编译器便可确定一个包的所有依赖包的源码路径的集合，这个集合构成了 Go 编译器的源码搜索路径空间； 同一源码文件的依赖包在同一源码搜索路径空间下包名冲突的问题可以由包别名的方式解决。 } 15 注意：Go 字符串是原生类型 17 init 函数的妙用 扫码加入慕课前沿技术核心用户群 验证信息：2010312025386365复制 QQ讨论群号：729941811 QQ群URL：点击访问 若遇到搜索不到QQ群或加群失败，请联系客服邮箱:kf@imooc.com"},{"title":"","date":"2024-03-12T03:55:12.946Z","updated":"2024-03-12T03:55:12.946Z","comments":true,"path":"book/17init函数的妙用慕课专栏.html","permalink":"https://smartxia.github.io/blog/book/17init%E5%87%BD%E6%95%B0%E7%9A%84%E5%A6%99%E7%94%A8%E6%85%95%E8%AF%BE%E4%B8%93%E6%A0%8F.html","excerpt":"","text":"17 init 函数的妙用-慕课专栏 17 init 函数的妙用 更新时间：2020-10-23 11:45:46 只有在那崎岖的小路上不畏艰险奋勇攀登的人,才有希望达到光辉的顶点。——马克思 从程序逻辑结构角度来看，Go 包（package）是程序逻辑封装的基本单元，每个包都可以理解为一个”自治“的、封装良好的、对外部暴露有限接口的基本单元。一个 Go 程序就是由一组包组成的。 在 Go 包这一基本单元中分布着常量、包级变量、函数、类型和类型方法、接口等，我们要保证包内部的这些元素在被使用之前处于合理有效的初始状态，尤其是包级变量。在 Go 语言中，我们一般通过包的 init 函数来完成这一工作。 1. 认识 init 函数 Go 语言中有两个特殊的函数，一个是 main 包中的 main 函数，它是所有 Go 可执行程序的入口函数；另外一个就是包的 init 函数。 init 函数是一个无参数无返回值的函数： func init() &#123; ... ... &#125; 如果一个包定义了 init 函数，Go 运行时会负责在该包初始化时调用它的 init 函数。在 Go 程序中我们不能显式调用 init，否则会在编译期间报错： // call_init_in_main.go package main import \"fmt\" func init() &#123; fmt.Println(\"init invoked\") &#125; func main() &#123; init() &#125; $go run call_init_in_main.go # command-line-arguments ./call_init_in_main.go:10:2: undefined: init 一个 Go 包可以拥有多个 init 函数，每个组成 Go 包的 Go 源文件中亦可以定义多个 init 函数。在初始化该 Go 包时，Go 运行时会按照一定的次序逐一顺序地调用该包的 init 函数。Go 运行时不会并发调用 init 函数，它会等待一个 init 函数执行完毕返回后再执行下一个 init 函数，且每个 init 函数在整个 Go 程序生命周期内仅会被执行一次。因此，init 函数极其适合做一些包级数据初始化工作以及包级数据初始状态的检查工作。 一个包内的、分布在多个文件中的多个 init 函数的执行次序是什么样的呢？一般来说，先被传递给 Go 编译器的源文件中的 init 函数先被执行；同一个源文件中的多个 init 函数按声明顺序依次执行。但 Go 语言的惯例告诉我们：不要依赖 init 函数的执行次序。 2. 程序初始化顺序 init 函数为何适合做包级数据初始化工作以及包级数据初始状态的检查工作呢？除了 init 函数是顺序执行并仅被执行一次之外，Go 程序初始化顺序也给 init 函数提供了胜任该工作的前提条件。 Go 程序由一组包组合而成，程序的初始化就是这些包的初始化。每个 Go 包都会有自己的依赖包、每个包还包含有常量、变量、init 函数(其中 main 包有 main 函数)等，这些元素在程序初始化过程中的初始化顺序是什么样的呢？我们用下面的这幅图来说明一下： 图4-1-1 包初始化顺序 我们看到在上图中： main 包依赖 pkg1、pkg4 两个包； Go 运行时会根据包导入的顺序，先去初始化 main 包的第一个依赖包 pkg1； Go 运行时遵循“深度优先”原则查看到：pkg1 依赖 pkg2，于是 Go 运行时去初始化 pkg2； pkg2 依赖 pkg3，Go 运行时去初始化 pkg3； pkg3 没有依赖包，于是 Go 运行时在 pkg3 包中按照”常量 -&gt; 变量 -&gt; init 函数\"的顺序进行初始化； pkg3 初始化完毕后，Go 运行时会回到 pkg2 并对 pkg2 进行初始化；接下来再回到 pkg1 并对 pkg1 进行初始化； 在调用完 pkg1 的 init 函数后，Go 运行时完成 main 包的第一个依赖包 pkg1 的初始化； Go 运行时接下来会初始化 main 包的第二个依赖包 pkg4； pkg4 的初始化过程与 pkg1 类似，也是先初始化其依赖包 pkg5，然后再初始化自身； 当 Go 运行时初始化完 pkg4 后，也就完成了对 main 包所有依赖包的初始化，接下来初始化 main 包自身； 在 main 包中，Go 运行时会按照”常量 -&gt; 变量 -&gt; init 函数\"的顺序进行初始化，执行完这些初始化工作后才正式进入程序的入口函数 main 函数。 到这里，我们知道了 init 函数适合做包级数据初始化和初始状态检查的前提条件就是 init 函数的执行顺位排在其所在包的包级变量之后。 我们再通过代码示例来验证一下上述的程序启动初始化顺序： // 示例程序的结构如下： package-init-order ├── go.mod ├── main.go ├── pkg1 │ └── pkg1.go ├── pkg2 │ └── pkg2.go └── pkg3 └── pkg3.go 包的依赖关系如下： main 包依赖 pkg1 和 pkg3； pkg1 依赖 pkg2。 由于篇幅所限，这里仅列出 main 包的代码，pkg1、pkg2 和 pkg3 包的代码与 main 包类似： // package-init-order/main.go package main import ( \"fmt\" _ \"github.com/bigwhite/package-init-order/pkg1\" _ \"github.com/bigwhite/package-init-order/pkg3\" ) var ( _ = constInitCheck() v1 = variableInit(\"v1\") v2 = variableInit(\"v2\") ) const ( c1 = \"c1\" c2 = \"c2\" ) func constInitCheck() string &#123; if c1 != \"\" &#123; fmt.Println(\"main: const c1 init\") &#125; if c1 != \"\" &#123; fmt.Println(\"main: const c2 init\") &#125; return \"\" &#125; func variableInit(name string) string &#123; fmt.Printf(\"main: var %s init\\n\", name) return name &#125; func init() &#123; fmt.Println(\"main: init\") &#125; func main() &#123; // do nothing &#125; 我们看到 main 包并未使用 pkg1 和 pkg3 中的函数或方法，而是直接通过包的空别名方式“触发”pkg1 和 pkg3 的初始化，下面是这个程序的运行结果： $go run main.go pkg2: const c init pkg2: var v init pkg2: init pkg1: const c init pkg1: var v init pkg1: init pkg3: const c init pkg3: var v init pkg3: init main: const c1 init main: const c2 init main: var v1 init main: var v2 init main: init 正如我们预期的那样，Go 运行时按照\"pkg2 -&gt; pkg1 -&gt; pkg3 -&gt; main\"的包顺序以及在包内“常量” -&gt; “变量” -&gt; init 函数的顺序进行初始化。 3. 使用 init 函数检查包级变量的初始状态 init 函数就好比 Go 包真正投入使用之前的一个唯一的“质检员”，负责对包内部以及暴露到外部的包级数据（主要是包级变量）的初始状态进行检查。在 Go 运行时和标准库中，我们能发现很多 init 检查包级变量的初始状态的例子。 a) 重置包级变量值 我们先看看标准库 flag 包的 init 函数： // $GOROOT/src/flag/flag.go func init() &#123; // Override generic FlagSet default Usage with call to global Usage. // Note: This is not CommandLine.Usage = Usage, // because we want any eventual call to use any updated value of Usage, // not the value it has when this line is run. CommandLine.Usage = commandLineUsage &#125; CommandLine 是 flag 包的一个导出包级变量，它也是默认情况下(如果你没有新创建一个 FlagSet)代表命令行的变量，我们从其初始化表达式即可看出： var CommandLine = NewFlagSet(os.Args[0], ExitOnError) CommandLine 的 Usage 字段在 NewFlagSet 函数中被初始化为 FlagSet 实例（也就是 CommandLine)的方法值(method value)：defaultUsage。如果一直保持这样，那么使用 Flag 默认 CommandLine 的外用用户就无法自定义 usage 输出了。于是 flag 包在 init 函数中，将 ComandLine 的 Usage 字段设置为一个包内未导出函数 commandLineUsage，后者则直接使用了 flag 包的另外一个导出包变量 Usage。这样通过 init 函数将 CommandLine 与包变量 Usage 关联在一起。当用户将自定义 usage 赋值给 Usage 后，就相当于改变了 CommandLine 变量的 Usage。 另外一个例子来自标准库的 context 包： // $GOROOT/src/context/context.go // closedchan is a reusable closed channel. var closedchan = make(chan struct&#123;&#125;) func init() &#123; close(closedchan) &#125; context 包在 cancelCtx 的 cancel 方法中需要一个可复用的、处于关闭状态的 channel，于是 context 包定义了一个未导出包级变量 closedchan 并对其进行了初始化。但初始化后的 closedchan 并不满足 context 包的要求，唯一能检查和更正其状态的地方就是 context 包的 init 函数，于是我们看到上面代码在 init 函数中将 closedchan 关闭了。 b) 对包级变量进行初始化，保证其后续可用 有些包级变量需要一个较为复杂的初始化过程，简单的初始化表达式不能满足要求。而 init 函数则非常适合完成此项工作。 标准库 regexp 包的 init 函数就负责完成了对内部特殊字节数组的初始化，这个特殊字节数组被包内的 special 函数使用，用于判断某个字符是否需要转义： // $GOROOT/src/regexp/regexp.go // Bitmap used by func special to check whether a character needs to be escaped. var specialBytes [16]byte // special reports whether byte b needs to be escaped by QuoteMeta. func special(b byte) bool &#123; return b &lt; utf8.RuneSelf &amp;&amp; specialBytes[b%16]&amp;(1&lt;&lt;(b/16)) != 0 &#125; func init() &#123; for _, b := range []byte(`\\.+*?()|[]&#123;&#125;^$`) &#123; specialBytes[b%16] |= 1 &lt;&lt; (b / 16) &#125; &#125; 标准库 net 包在 init 函数中对 rfc6724policyTable 这个未导出包级变量进行反转排序： // $GOROOT/src/net/addrselect.go func init() &#123; sort.Sort(sort.Reverse(byMaskLength(rfc6724policyTable))) &#125; 标准库 http 包则在 init 函数中根据环境变量 GODEBUG 的值对一些包级开关变量进行赋值： // $GOROOT/src/net/http/h2_bundle.go var ( http2VerboseLogs bool http2logFrameWrites bool http2logFrameReads bool http2inTests bool ) func init() &#123; e := os.Getenv(\"GODEBUG\") if strings.Contains(e, \"http2debug=1\") &#123; http2VerboseLogs = true &#125; if strings.Contains(e, \"http2debug=2\") &#123; http2VerboseLogs = true http2logFrameWrites = true http2logFrameReads = true &#125; &#125; c) init 函数中的“注册模式” 下面是使用lib/pq 包访问 PostgreSQL 数据库的一段代码示例： import ( \"database/sql\" _ \"github.com/lib/pq\" ) func main() &#123; db, err := sql.Open(\"postgres\", \"user=pqgotest dbname=pqgotest sslmode=verify-full\") if err != nil &#123; log.Fatal(err) &#125; age := 21 rows, err := db.Query(\"SELECT name FROM users WHERE age = $1\", age) ... &#125; 对于初学 Go 的 gopher 来说，这是一段“神奇”的代码，因为在以空别名方式导入 lib/pq 包后，main 函数中似乎并没有使用 pq 的任何变量、函数或方法。这段代码的奥秘全在 pq 包的 init 函数中： // github.com/lib/pq/conn.go ... ... func init() &#123; sql.Register(\"postgres\", &amp;Driver&#123;&#125;) &#125; ... ... 空别名方式导入 lib/pq 的副作用就是 Go 运行时会将 lib/pq 作为 main 包的依赖包，Go 运行时会初始化 pq 包，于是 pq 包的 init 函数得以执行。我们看到在 pq 包的 init 函数中，pq 包将自己实现的 sql 驱动(driver)注册到 sql 包中。这样只要应用层代码在 Open 数据库的时候传入驱动的名字（这里是“postgres”)，那么通过 sql.Open 函数返回的数据库实例句柄对数据库进行的操作实际上调用的都是 pq 这个驱动的相应实现。 这种通过在 init 函数中注册自己的实现的模式，降低了 Go 包对外的直接暴露，尤其是包级变量的暴露，避免了外部通过包级变量对包状态的改动。从 database/sql 的角度来看，这种“注册模式”实质是一种工厂设计模式的实现，sql.Open 函数就是该模式中的工厂方法，它根据外部传入的驱动名称“生产”出不同类别的数据库实例句柄。 这种“注册模式”在标准库的其他包中亦有广泛应用，比如：使用标准库 image 包获取各种格式的图片的宽和高： // get_image_size.go package main import ( \"fmt\" \"image\" _ \"image/gif\" _ \"image/jpeg\" _ \"image/png\" \"os\" ) func main() &#123; // 支持png, jpeg, gif width, height, err := imageSize(os.Args[1]) if err != nil &#123; fmt.Println(\"get image size error:\", err) return &#125; fmt.Printf(\"image size: [%d, %d]\\n\", width, height) &#125; func imageSize(imageFile string) (int, int, error) &#123; f, _ := os.Open(imageFile) defer f.Close() img, _, err := image.Decode(f) if err != nil &#123; return 0, 0, err &#125; b := img.Bounds() return b.Max.X, b.Max.Y, nil &#125; 这个小程序支持 png、jpeg、gif 三种格式的图片，而达成这一目标正是因为 image/png、image/jpeg 和 image/gif 包在各自的 init 函数中将自己“注册”到 image 的支持格式列表中了： // $GOROOT/src/image/png/reader.go func init() &#123; image.RegisterFormat(\"png\", pngHeader, Decode, DecodeConfig) &#125; // $GOROOT/src/image/jpeg/reader.go func init() &#123; image.RegisterFormat(\"jpeg\", \"\\xff\\xd8\", Decode, DecodeConfig) &#125; // $GOROOT/src/image/gif/reader.go func init() &#123; image.RegisterFormat(\"gif\", \"GIF8?a\", Decode, DecodeConfig) &#125; d) init 函数中检查失败的处理方法 init 函数是一个无参数无返回值的函数，并且它的主要目的就是保证其所在包在被正式使用之前包的初始状态是有效的。一旦 init 函数在检查包数据初始状态时遇到失败或错误的情况(尽管极少出现），则说明对包的“质检”亮了红灯，如果让包“出厂”，那么只会导致更为严重的影响。因此，在这种情况下，快速失败是最佳选择。我们一般建议直接调用 panic。或通过 log.Fatal 等方法记录异常日志后再调用 panic 使程序退出。 4. 小结 深入理解 init 函数，记住本节的几个要点即可： init 函数的几个特点：运行时调用、顺序、仅执行一次 。 Go 程序的初始化顺序。 init 函数是包出厂前的唯一“质检员”。 } 16 理解包导入路径的含义 18 Go 函数是“一等公民” 扫码加入慕课前沿技术核心用户群 验证信息：2010312025386365复制 QQ讨论群号：729941811 QQ群URL：点击访问 若遇到搜索不到QQ群或加群失败，请联系客服邮箱:kf@imooc.com"},{"title":"","date":"2024-03-12T03:55:12.948Z","updated":"2024-03-12T03:55:12.948Z","comments":true,"path":"book/19defer让你的代码更清晰慕课专栏.html","permalink":"https://smartxia.github.io/blog/book/19defer%E8%AE%A9%E4%BD%A0%E7%9A%84%E4%BB%A3%E7%A0%81%E6%9B%B4%E6%B8%85%E6%99%B0%E6%85%95%E8%AF%BE%E4%B8%93%E6%A0%8F.html","excerpt":"","text":"19 defer 让你的代码更清晰-慕课专栏 19 defer 让你的代码更清晰 更新时间：2020-10-27 09:52:47 青年是学习智慧的时期，中年是付诸实践的时期。 —— 卢梭 日常开发中，我们经常会编写一些类似下面示例中的代码： // deferred_func_1.go func writeToFile(fname string, data []byte, mu *sync.Mutex) error &#123; mu.Lock() f, err := os.OpenFile(fname, os.O_RDWR, 0666) if err != nil &#123; mu.Unlock() return err &#125; _, err = f.Seek(0, 2) if err != nil &#123; f.Close() mu.Unlock() return err &#125; _, err = f.Write(data) if err != nil &#123; f.Close() mu.Unlock() return err &#125; err = f.Sync() if err != nil &#123; f.Close() mu.Unlock() return err &#125; err = f.Close() if err != nil &#123; mu.Unlock() return err &#125; mu.Unlock() return nil &#125; 我们看到这类代码的特点就是在函数中会申请一些资源并在函数退出前释放或关闭这些资源，比如这里的文件描述符 f 和互斥锁 mu。函数的实现需要确保这些资源在函数退出时被及时正确地释放，无论函数的执行流是按预期顺利进行还是出现错误。为此，开发人员需对函数中的错误处理尤为关注，在错误处理时不能遗漏对资源的释放，尤其是有多个资源需要释放的时候，就像上面示例那样，这大大增加了开发人员的心智负担。同时当待释放的资源个数较多时，整个代码逻辑将变得十分复杂，程序可读性、健壮性也随之下降。但即便如此，如果函数实现中的某段代码逻辑抛出 panic，传统的错误处理机制依然没有办法捕获它并尝试从 panic 恢复。 解决上述提到的这些问题正是 Go 语言引入 defer 的初衷。 1. defer 的运作机制 defer 的运作离不开函数，这里至少有两点含义： 在 Go 中，只有在函数(和方法)内部才能使用 defer； defer 关键字后面只能接函数(或方法），这些函数被称为 deferred 函数。defer 将它们注册到其所在 goroutine 用于存放 deferred 函数的栈数据结构中，这些 deferred 函数将在执行 defer 的函数退出前被按后进先出(LIFO)的顺序调度执行(如下图所示)。 图4-3-1：deferred函数的存储与调度执行 无论是执行到函数体尾部返回，还是在某个错误处理分支显式 return，亦或是出现 panic，已经存储到 deferred 函数栈中的函数都会被调度执行。因此，deferred 函数是一个可以在任何情况下都可以为函数进行收尾工作的好场合。 我们回到本节开头的例子，我们把收尾工作挪到 deferred 函数中，代码变更后如下： // deferred_func_2.go(这里仅列出writeToFile变更后的代码) func writeToFile(fname string, data []byte, mu *sync.Mutex) error &#123; mu.Lock() defer mu.Unlock() f, err := os.OpenFile(fname, os.O_RDWR, 0666) if err != nil &#123; return err &#125; defer f.Close() _, err = f.Seek(0, 2) if err != nil &#123; return err &#125; _, err = f.Write(data) if err != nil &#123; return err &#125; return f.Sync() &#125; 我们看到 defer 的使用对函数 writeToFile 的实现逻辑的简化是显而易见的，资源释放函数的 defer 注册动作紧邻着资源申请成功的动作，这样成对出现的惯例极大降低了遗漏资源释放的可能性，开发人员也因此再也不用小心翼翼地在每个错误处理分支中检查是否遗漏了某个资源的释放动作了。同时，代码的简化又意味代码可读性的提高以及健壮性的增强。 2. defer 的常见用法 除了释放资源这个最基本、最常见的用法之外，defer 的运作机制决定了它还可以在其他一些场合发挥作用，这些用法在 Go 标准库中均有体现。 1) 拦截 panic 在上一小节我们提到过，defer 的运行机制决定了无论函数是执行到函数体末尾正常返回，还是在函数体中的某个错误处理分支显式调用 return 返回，亦或是函数体内部出现 panic，已经注册了的 deferred 函数都会被调度执行。因此，defer 的第二个重要用途就是用来拦截 panic，并按需要对 panic 进行处理，可以尝试从 panic 中恢复（这也是 Go 语言中唯一一种从 panic 恢复的手段），也可以如下面标准库代码中这样，重新 panic，但为新的 panic 传一个新的 error 值： // $GOROOT/src/bytes/buffer.go func makeSlice(n int) []byte &#123; // If the make fails, give a known error. defer func() &#123; if recover() != nil &#123; panic(ErrTooLarge) &#125; &#125;() return make([]byte, n) &#125; 下面代码则是通过 deferred 函数拦截 panic 并恢复了程序的继续运行： // deferred_func_3.go package main import \"fmt\" func bar() &#123; fmt.Println(\"raise a panic\") panic(-1) &#125; func foo() &#123; defer func() &#123; if e := recover(); e != nil &#123; fmt.Println(\"recovered from a panic\") &#125; &#125;() bar() &#125; func main() &#123; foo() fmt.Println(\"main exit normally\") &#125; $ go run deferred_func_3.go raise a panic recovered from a panic main exit normally deferred 函数在 panic 的情况下依旧能够被调度执行的特性让下面两个看似行为等价的函数在 panic 的时候得到不同的执行结果： var mu sync.Mutex func f() &#123; mu.Lock() defer mu.Unlock() bizOperation() &#125; func g() &#123; mu.Lock() bizOperation() mu.Unlock() &#125; 当 bizOperation 抛出 panic 时，函数 g 无法释放 mutex，而函数 f 则可以释放 mutex，让后续函数依旧可以申请 mutex 资源。 虽然 deferred 函数可以拦截到绝大部分的 panic，但有些 runtime 之外的致命问题也是无法拦截并恢复的，比如下面代码中通过 C 代码”制造“的 crash，deferred 函数便无能为力： // deferred_func_4.go package main //#include &lt;stdio.h&gt; // void crash() &#123; // int *q = NULL; // (*q) = 15000; // printf(\"%d\\n\", *q); // &#125; import \"C\" import ( \"fmt\" ) func bar() &#123; C.crash() &#125; func foo() &#123; defer func() &#123; if e := recover(); e != nil &#123; fmt.Println(\"recovered from a panic:\", e) &#125; &#125;() bar() &#125; func main() &#123; foo() fmt.Println(\"main exit normally\") &#125; 执行这段代码我们就会看到虽然有 deferred 函数拦截，但程序仍然崩溃掉了： $ go run deferred_func_4.go SIGILL: illegal instruction PC=0x409a7f4 m=0 sigcode=1 goroutine 0 [idle]: runtime: unknown pc 0x409a7f4 ... ... 2) deferred 函数可以修改函数的具名返回值 下面是 Go 标准库中通过 deferred 函数访问函数具名返回值变量的两个例子： // $GOROOT/src/fmt/scan.go func (s *ss) Token(skipSpace bool, f func(rune) bool) (tok []byte, err error) &#123; defer func() &#123; if e := recover(); e != nil &#123; if se, ok := e.(scanError); ok &#123; err = se.err &#125; else &#123; panic(e) &#125; &#125; &#125;() ... ... &#125; // $GOROOT/SRC/net/ipsock_plan9.go func dialPlan9(ctx context.Context, net string, laddr, raddr Addr) (fd *netFD, err error) &#123; defer func() &#123; fixErr(err) &#125;() ... ... &#125; 我们也来写一个更直观的示例： // deferred_func_5.go package main import \"fmt\" func foo(a, b int) (x, y int) &#123; defer func() &#123; x = x * 5 y = y * 10 &#125;() x = a + 5 y = b + 6 return &#125; func main() &#123; x, y := foo(1, 2) fmt.Println(\"x=\", x, \"y=\", y) &#125; 运行这个程序： $ go run deferred_func_5.go x= 30 y= 80 我们看到 deferred 函数在 foo 真正将执行权返回给 main 函数之前将 foo 的两个返回值 x 和 y 分别作了 5 倍和 10 倍放大。 3) deferred 函数可以用于输出一些调试信息 deferred 函数被注册以及调度执行的时间点十分适合用来输出一些调试信息。比如下面 Go 标准库中 net 包中的 hostLookupOrder 方法就使用 deferred 函数在特定日志级别下输出一些日志便于程序调试和跟踪。 // $GOROOT/src/net/conf.go func (c *conf) hostLookupOrder(r *Resolver, hostname string) (ret hostLookupOrder) &#123; if c.dnsDebugLevel &gt; 1 &#123; defer func() &#123; print(\"go package net: hostLookupOrder(\", hostname, \") = \", ret.String(), \"\\n\") &#125;() &#125; ... ... &#125; 更为典型的莫过于在出入函数时打印留痕日志(一般在调试日志级别下)，这里摘录一下 Go 官方参考文档中提供的一个实现： func trace(s string) string &#123; fmt.Println(\"entering:\", s) return s &#125; func un(s string) &#123; fmt.Println(\"leaving:\", s) &#125; func a() &#123; defer un(trace(\"a\")) fmt.Println(\"in a\") &#125; func b() &#123; defer un(trace(\"b\")) fmt.Println(\"in b\") a() &#125; func main() &#123; b() &#125; 4) 还原变量旧值 defer 还有一种比较小众的用法，这用法依旧是来自对 Go 标准库源码的阅读。在 syscall 包下面有这样的一段代码： // $GOROOT/src/syscall/fs_nacl.go func init() &#123; // do not trigger loading of zipped file system here oldFsinit := fsinit defer func() &#123; fsinit = oldFsinit &#125;() fsinit = func() &#123;&#125; Mkdir(\"/dev\", 0555) Mkdir(\"/tmp\", 0777) mkdev(\"/dev/null\", 0666, openNull) mkdev(\"/dev/random\", 0444, openRandom) mkdev(\"/dev/urandom\", 0444, openRandom) mkdev(\"/dev/zero\", 0666, openZero) chdirEnv() &#125; 我们看到这段源码的作者利用了 deferred 函数对变量的旧值进行还原：即先将 fsinit 存储在一个局部变量 oldFsinit 中，然后在 deferred 函数中将 fsinit 的值重新置为存储在 oldFsinit 中的旧值。 3. 关于 defer 使用的几个关键问题 绝大多数 Gopher 都喜欢 defer，它让函数变得简洁且健壮。 但”工欲善其事,必先利其器“，一旦要用 defer，有几个关于 defer 使用的关键问题是需要提前了解清楚的，以避免掉进一些不必要的”坑“。 1) 明确哪些函数可以作为 deferred 函数 对于自定义的函数或方法，defer 可以给与无条件的支持，但是对于有返回值的自定义函数或方法，返回值会在 deferred 函数被调度执行的时候被自动丢弃掉。 Go 语言中除了自定义函数/方法，还有 Go 语言内置的/预定义的函数，下面是 Go 语言内置函数的完全列表： Functions: append cap close complex copy delete imag len make new panic print println real recover 内置函数是否都能作为 deferred 函数呢？我们看一下下面的示例： // deferred_func_6.go package main func bar() (int, int) &#123; return 1, 2 &#125; func foo() &#123; // builtin functions: // append cap close complex copy delete imag len // make new panic print println real recover var c chan int var sl []int var m = make(map[string]int, 10) m[\"item1\"] = 1 m[\"item2\"] = 2 var a = complex(1.0, -1.4) var sl1 []int defer bar() defer append(sl, 11) defer cap(sl) defer close(c) defer complex(2, -2) defer copy(sl1, sl) defer delete(m, \"item2\") defer imag(a) defer len(sl) defer make([]int, 10) defer new(*int) defer panic(1) defer print(\"hello, defer\\n\") defer println(\"hello, defer\") defer real(a) defer recover() &#125; func main() &#123; foo() &#125; 运行该实例： $ go run deferred_func_6.go # command-line-arguments ./deferred_func_6.go:22:2: defer discards result of append(sl, 11) ./deferred_func_6.go:23:2: defer discards result of cap(sl) ./deferred_func_6.go:25:2: defer discards result of complex(2, -2) ./deferred_func_6.go:28:2: defer discards result of imag(a) ./deferred_func_6.go:29:2: defer discards result of len(sl) ./deferred_func_6.go:30:2: defer discards result of make([]int, 10) ./deferred_func_6.go:31:2: defer discards result of new(*int) ./deferred_func_6.go:35:2: defer discards result of real(a) 我们看到 Go 编译器给出一组错误提示！从这组错误提示中我们看到：append、cap、len、make、new 等内置函数是不能直接作为 deferred 函数的，而 close、copy、delete、print、recover 等是可以直接被 defer 注册为 deferred 函数的。 对于那些不能直接作为 deferred 函数的内置函数，我们可以使用一个包裹它的匿名函数来间接满足要求，以 append 为例： defer func() &#123; _ = append(sl, 11) &#125;() 但这么做的实际意义是什么是需要开发者自己把握。 2) 把握好 defer 关键字后面表达式的求值时机 牢记一点：defer 关键字后面的表达式是在将 deferred 函数注册到 deferred 函数栈的时候进行求值的。 下面用一个典型的例子来说明一下 defer 后表达式的求值时机： // deferred_func_7.go package main import \"fmt\" func foo1() &#123; for i := 0; i &lt;= 3; i++ &#123; defer fmt.Println(i) &#125; &#125; func foo2() &#123; for i := 0; i &lt;= 3; i++ &#123; defer func(n int) &#123; fmt.Println(n) &#125;(i) &#125; &#125; func foo3() &#123; for i := 0; i &lt;= 3; i++ &#123; defer func() &#123; fmt.Println(i) &#125;() &#125; &#125; func main() &#123; fmt.Println(\"foo1 result:\") foo1() fmt.Println(\"\\nfoo2 result:\") foo2() fmt.Println(\"\\nfoo3 result:\") foo3() &#125; 我们对 foo1、foo2 和 foo3 中的 defer 后的表达式的求值时机做逐一分析： foo1 中 defer 后面直接用的是 fmt.Println 函数，每当 defer 将 fmt.Println 注册到 deferred 函数栈的时候，都会对 Println 后面的参数进行求值，根据上述代码逻辑，依次压入 deferred 函数栈的函数是： fmt.Println(0) fmt.Println(1) fmt.Println(2) fmt.Println(3) 因此，当 foo1 返回后，deferred 函数被调度执行时，上述压入栈的 deferred 函数将以 LIFO 次序出栈执行，因此输出的结果为： 3 2 1 0 foo2 中 defer 后面接的是一个带有一个参数的匿名函数。每当 defer 将匿名函数注册到 deferred 函数栈的时候，都会对该匿名函数的参数进行求值，根据上述代码逻辑，依次压入 deferred 函数栈的函数是： func(0) func(1) func(2) func(3) 因此，当 foo2 返回后，deferred 函数被调度执行时，上述压入栈的 deferred 函数将以 LIFO 次序出栈执行，因此输出的结果为： 3 2 1 0 foo3 中 defer 后面接的是一个不带参数的匿名函数。根据上述代码逻辑，依次压入 deferred 函数栈的函数是： func() func() func() func() 因此，当 foo3 返回后，deferred 函数被调度执行时，上述压入栈的 deferred 函数将以 LIFO 次序出栈执行。匿名函数以闭包的方式访问外围函数的变量 i，并通过 Println 输出 i 的值，此时 i 的值为 4，因此 foo3 的输出结果为： 4 4 4 4 鉴于 defer 表达式求值时机的重要性，我们再来看一个例子： // deferred_func_8.go package main import \"fmt\" func foo1() &#123; sl := []int&#123;1, 2, 3&#125; defer func(a []int) &#123; fmt.Println(a) &#125;(sl) sl = []int&#123;3, 2, 1&#125; _ = sl &#125; func foo2() &#123; sl := []int&#123;1, 2, 3&#125; defer func(p *[]int) &#123; fmt.Println(*p) &#125;(&amp;sl) sl = []int&#123;3, 2, 1&#125; _ = sl &#125; func main() &#123; foo1() foo2() &#125; 我们分别分析一下这个实例中的 foo1、foo2 函数： foo1 中 defer 后面的匿名函数接收一个切片类型参数，当 defer 将该匿名函数注册到 deferred 函数栈的时候，会对它的参数进行求值，此时传入的变量 sl 的值为[]int{1, 2, 3}，因此压入 deferred 函数栈的函数是： func([]int&#123;1,2,3&#125;) 之后虽然 sl 被重新赋值，但是当 foo1 返回后，deferred 函数被调度执行时，deferred 函数的参数值依然为[]int{1,2,3}，因此 foo1 输出的结果为：[1 2 3]。 foo2 中 defer 后面的匿名函数接收一个切片指针类型参数，当 defer 将该匿名函数注册到 deferred 函数栈的时候，会对它的参数进行求值，此时传入的参数为变量 sl 的地址，因此压入 deferred 函数栈的函数是： func(&amp;sl) 之后虽然 sl 被重新赋值。当 foo2 返回后，deferred 函数被调度执行时，deferred 函数的参数值依然为 sl 的地址，但此时 sl 的值已经变为[]int{3, 2, 1}，因此 foo2 输出的结果为：[3 2 1]。 3) 知晓 defer 带来的性能损耗 defer 让 Gopher 在进行资源释放(如文件描述符、锁)的过程变动优雅很多，也不易出错。但在性能敏感的应用中，defer 带来的性能负担也是 Gopher 必须要知晓和权衡的问题。 我们用一个性能基准测试(benchmark)来直观地看看 defer 究竟带来多少性能损耗。 // defer_perf_benchmark_1_test.go package defer_test import \"testing\" func sum(max int) int &#123; total := 0 for i := 0; i &lt; max; i++ &#123; total += i &#125; return total &#125; func fooWithDefer() &#123; defer func() &#123; sum(10) &#125;() &#125; func fooWithoutDefer() &#123; sum(10) &#125; func BenchmarkFooWithDefer(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; fooWithDefer() &#125; &#125; func BenchmarkFooWithoutDefer(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; fooWithoutDefer() &#125; &#125; 运行该 benchmark 测试，我们得到如下结果： $ go test -bench . defer_perf_benchmark_1_test.go goos: darwin goarch: amd64 BenchmarkFooWithDefer-8 34581608 31.6 ns/op BenchmarkFooWithoutDefer-8 248793603 4.83 ns/op PASS ok command-line-arguments 2.830s 从基准测试结果我们可以清晰的看到：使用 defer 的函数的执行时间是没有使用 defer 函数的 8 倍左右。 在 Go 1.13 中，Go 核心团队对 defer 性能做了大幅优化，官方给出了在大多数情况下，defer 性能提升 30%的说法。但笔者的实测结果是 defer 性能的确有提升，但远没有达到 30%这么大的幅度。在 Go 1.14 版本中，defer 性能据说还有大幅提升，让我们拭目以待。 4. 小结 多数情况下，我们的程序对性能并非那么敏感。在这样的情况下，笔者建议 gopher 们尽量使用 defer。defer 让资源释放变得优雅且不易出错，简化了函数实现逻辑，提高了代码可读性，让函数实现变得更加健壮。 本节要点： 理解 defer 的运作机制：deferred 函数注册与调度执行； 了解 defer 的常见用法； 了解 defer 使用的几个关键问题，避免入”坑“。 } 18 Go 函数是“一等公民” 20 Go 方法的本质 扫码加入慕课前沿技术核心用户群 验证信息：2010312025386365复制 QQ讨论群号：729941811 QQ群URL：点击访问 若遇到搜索不到QQ群或加群失败，请联系客服邮箱:kf@imooc.com"},{"title":"","date":"2024-03-12T03:55:12.948Z","updated":"2024-03-12T03:55:12.948Z","comments":true,"path":"book/20Go方法的本质慕课专栏.html","permalink":"https://smartxia.github.io/blog/book/20Go%E6%96%B9%E6%B3%95%E7%9A%84%E6%9C%AC%E8%B4%A8%E6%85%95%E8%AF%BE%E4%B8%93%E6%A0%8F.html","excerpt":"","text":"20 Go 方法的本质-慕课专栏 20 Go 方法的本质 更新时间：2020-10-28 09:38:45 我好像是一只牛，吃的是草，挤出的是牛奶。——鲁迅 Go 语言不支持经典的面向对象语法元素，比如：类、对象、继承等。但 Go 语言也有方法（method）。和函数相比，Go 语言中的方法在声明形式上仅仅多了一个参数，Go 称之为 receiver 参数。而 receiver 参数正是方法与类型之间的纽带。 Go 方法的一般声明形式如下： func (receiver T/*T) MethodName(参数列表) (返回值列表) &#123; // 方法体 &#125; 上面方法声明中的 T 称为 receiver 的基类型。通过 receiver，上述方法被绑定到类型 T 上。换句话说：上述方法是类型 T 的一个方法，我们可以通过类型 T 或*T 的实例调用该方法。 var t T t.MethodName(参数列表) var pt *T = &amp;t pt.MethodName(参数列表) Go 方法具有如下特点： 方法名的首字母是否大写决定了该方法是否是导出方法 ； 方法定义要与类型定义放在同一个包内。 由于方法定义与类型定义必须放在同一个包下面，因此我们可以推论得到：我们不能为原生类型（诸如：int、float64、map 等）添加方法, 只能为自定义类型定义方法。 错误的作法： func (i int) String() string &#123; // cannot define new methods on non-local type int return fmt.Sprintf(\"%d\", i) &#125; vs. 正确的作法： type MyInt int func (i MyInt) String() string &#123; return fmt.Sprintf(\"%d\", int(i)) &#125; 同理，我们也可以推论得出：我们也不能横跨 Go 包为其他包内的自定义类型定义方法。 每个方法只能有一个 receiver 参数，不支持多 receiver 参数列表或变长 receiver 参数。 一个方法只能绑定一个基类型，Go 语言不支持同时绑定多个类型的方法。 receiver 参数的基类型本身不能是指针类型或接口类型。 type MyInt *int func (r MyInt) String() string &#123; // invalid receiver type MyInt (MyInt is a pointer type) return fmt.Sprintf(\"%d\", *(*int)(r)) &#125; type MyReader io.Reader func (r MyReader) Read(p []byte) (int, error) &#123; // invalid receiver type MyReader (MyReader is an interface type) return r.Read(p) &#125; 和其他主流编程语言相比，Go 语言从函数到方法仅仅多出了一个 receiver，这大大降低了 Gopher 们学习方法的门槛。但即便如此，Gopher 们在把握方法本质以及如何选择 receiver 的类型时仍存在困惑，本节我就针对这些困惑做重点的说明。 1. 方法的本质 前面提到过：Go 语言没有类，方法与类型通过 receiver 联系在一起，我们可以为任何非内置原生类型定义方法，比如下面的类型 T： type T struct &#123; a int &#125; func (t T) Get() int &#123; return t.a &#125; func (t *T) Set(a int) int &#123; t.a = a return t.a &#125; C++的对象在调用方法时，编译器会自动传入指向对象自身的 this 指针作为方法的第一个参数。而对于 Go 来说，receiver 其实也是同样道理，我们将 receiver 作为第一个参数传入方法的参数列表，上面示例中的类型 T 的方法就可以等价转换为下面的普通函数： func Get(t T) int &#123; return t.a &#125; func Set(t *T, a int) int &#123; t.a = a return t.a &#125; 这种转换后的函数就是方法的原型。只不过在 Go 语言中，这种等价转换是由 Go 编译器在编译和生成代码时自动完成的。Go 语言规范中提供了方法表达式(method expression) 的概念，可以让我们更充分地理解上面的等价转换。 Go 方法的一般使用方式如下： var t T t.Get() t.Set(1) 我们可以将上面方法调用用下面的方式做等价替换： var t T T.Get(t) (*T).Set(&amp;t, 1) 这种直接以类型名 T 调用方法 M 的表达方式被称为Method Expression。类型 T 只能调用 T 的方法集合(Method Set)中的方法；同理*T 只能调用*T 的方法集合中的方法（关于方法集合，我们会在下一节中详细讲解）。我们看到：Method Expression有些类似于 C++中的 static 方法，static 方法在使用时以该 C++类的某个对象实例作为第一个参数，而 Go 语言的 Method Expression 在使用时，同样以 receiver 参数所代表的实例作为第一个参数。 这种通过 Method Expression 对方法进行调用的方式与我们之前所做的方法到函数的等价转换是如出一辙的。这就是Go 方法的本质：一个以方法所绑定类型实例为第一个参数的普通函数。 Method Expression 体现了 Go 方法的本质：其自身的类型就是一个普通函数。我们甚至可以将其作为右值赋值给一个函数类型的变量： var t T f1 := (*T).Set // f1的类型，也是T类型Set方法的原型：func (t *T, int)int f2 := T.Get // f2的类型，也是T类型Get方法的原型：func(t T)int f1(&amp;t, 3) fmt.Println(f2(t)) 2. 正确选择 receiver 类型 有了上面对 Go 方法本质的分析，我们再来理解 receiver 并在定义方法时选择正确的 receiver 类型就简单多了。我们再来看一下方法和函数的”等价变换公式“： func (t T) M1() &lt;=&gt; M1(t T) func (t *T) M2() &lt;=&gt; M2(t *T) 我们看到：M1 方法的 receiver 参数类型为 T，而 M2 方法的 receiver 参数类型为*T。 当 receiver 参数的类型为 T 时，即选择值类型的 receiver。 我们选择以 T 作为 receiver 参数类型时，T 的 M1 方法等价为 M1(t T)。我们知道 Go 函数的参数采用的是值拷贝传递，也就是说 M1 函数体中的 t 是 T 类型实例的一个副本，这样 M1 函数的实现中无论对参数 t 做任何修改都只会影响副本，而不会影响到原 T 类型实例。 当 receiver 参数的类型为 *T 时，即选择指针类型的 receiver。 我们选择以*T 作为 receiver 参数类型时，T 的 M2 方法等价为 M2(t *T)。我们传递给 M2 函数的 t 是 T 类型实例的地址，这样 M2 函数体中对参数 t 做的任何修改都会反映到原 T 类型实例。 我们以下面的例子演示一下选择不同的 receiver 类型对原类型实例的影响： // method_nature_1.go package main type T struct &#123; a int &#125; func (t T) M1() &#123; t.a = 10 &#125; func (t *T) M2() &#123; t.a = 11 &#125; func main() &#123; var t T // t.a = 0 println(t.a) t.M1() println(t.a) t.M2() println(t.a) &#125; 运行该程序： $ go run method_nature_1.go 0 0 11 在该示例中，M1 和 M2 方法体内都对字段 a 做了修改，但 M1（采用值类型 receiver）修改的只是实例的副本，对原实例并没有影响，因此 M1 调用后，输出 t.a 的值仍为 0；M2（采用指针类型 receiver）修改的是实例本身，因此 M2 调用后，t.a 的值变为了 11。 很多 Go 初学者还有这样的疑惑：是不是 T 类型实例只能调用 receiver 为 T 类型的方法，不能调用 receiver 为*T 类型的方法呢？答案是否定的。无论是 T 类型实例，还是*T 类型实例，都既可以调用 receiver 为 T 类型的方法，也可以调用 receiver 为*T 类型的方法。下面例子证明了这一点： // method_nature_2.go package main type T struct &#123; a int &#125; func (t T) M1() &#123; &#125; func (t *T) M2() &#123; t.a = 11 &#125; func main() &#123; var t T t.M1() // ok t.M2() // &lt;=&gt; (&amp;t).M2() var pt = &amp;T&#123;&#125; pt.M1() // &lt;=&gt; (*pt).M1() pt.M2() // ok &#125; 通过例子我们看到 T 类型实例 t 调用 receiver 类型为*T 的 M2 方法是没问题的，同样*T 类型实例 pt 调用 receiver 类型为 T 的 M1 方法也是可以的。实际上这都是 Go 语法甜头(syntactic sugar)，即 Go 编译器在编译和生成代码时为我们自动做的转换。 到这里，我们可以得出 receiver 类型选用的初步结论： 如果要对类型实例进行修改，那么为 receiver 选择*T 类型； 如果没有对类型实例修改的需求，那么为 receiver 选择 T 类型或*T 类型均可；但考虑到 Go 方法调用时，receiver 是以值拷贝的形式传入方法中的。如果类型 size 较大，以值形式传入会导致较大损耗，这时选择*T 作为 receiver 类型可能更好些。 对于 receiver 的类型的选择其实还有一个重要因素，那就是类型是否要实现某个 interface，这个考量因素在下一节中将有详细说明。 3. 利用对 Go 方法本质的理解巧解难题 下面的这个例子来自于笔者博客的一次真实的读者咨询，他的问题代码如下： // method_nature_3.go package main import ( \"fmt\" \"time\" ) type field struct &#123; name string &#125; func (p *field) print() &#123; fmt.Println(p.name) &#125; func main() &#123; data1 := []*field&#123;&#123;\"one\"&#125;, &#123;\"two\"&#125;, &#123;\"three\"&#125;&#125; for _, v := range data1 &#123; go v.print() &#125; data2 := []field&#123;&#123;\"four\"&#125;, &#123;\"five\"&#125;, &#123;\"six\"&#125;&#125; for _, v := range data2 &#123; go v.print() &#125; time.Sleep(3 * time.Second) &#125; 该示例在我的多核 MacOS 上运行结果如下（由于 goroutine 调度顺序不同，结果可能与下面的有差异）： $ go run method_nature_3.go one two three six six six 这位读者的问题显然是：为什么对 data2 迭代输出的结果是三个\"six\"，而不是 four、five、six？ 好了，我们来分析一下。首先，我们根据Go 方法的本质：一个以方法所绑定类型实例为第一个参数的普通函数，对这个程序做个等价变换(这里我们利用 Method Expression)，变换后的源码如下： // method_nature_4.go package main import ( \"fmt\" \"time\" ) type field struct &#123; name string &#125; func (p *field) print() &#123; fmt.Println(p.name) &#125; func main() &#123; data1 := []*field&#123;&#123;\"one\"&#125;, &#123;\"two\"&#125;, &#123;\"three\"&#125;&#125; for _, v := range data1 &#123; go (*field).print(v) &#125; data2 := []field&#123;&#123;\"four\"&#125;, &#123;\"five\"&#125;, &#123;\"six\"&#125;&#125; for _, v := range data2 &#123; go (*field).print(&amp;v) &#125; time.Sleep(3 * time.Second) &#125; 这里我们把对 field 的方法 print 的调用替换为 Method Expression 形式，替换前后的程序输出结果是一致的。但变换后，问题是不是豁然开朗了，我们可以很清楚地看到使用 go 关键字启动一个新 goroutine 时是如何绑定参数的： 迭代 data1 时，由于 data1 中的元素类型是 field 指针(*field)，因此赋值后 v 就是元素地址，每次调用 print 时传入的参数(v)实际上也是各个 field 元素的地址； 迭代 data2 时，由于 data2 中的元素类型是 field（非指针），需要将其取地址后再传入。这样每次传入的&amp;v 实际上是变量 v 的地址，而不是切片 data2 中各元素的地址； 在第 20 节 ”了解 Go 语言控制语句惯用法及使用注意事项\"一节中，我们了解过 for range 使用时应注意的几个问题，其中循环变量复用是关键的一个。这里的 v 在整个 for range 过程中只有一个，因此 data2 迭代完成之后，v 是元素\"six\"的拷贝。 这样，一旦启动的各个子 goroutine 在 main goroutine 执行到 Sleep 时才被调度执行，那么最后的三个 goroutine 在打印&amp;v 时，打印的也就都 v 中存放的值\"six\"了。而前三个子 goroutine 各自传入的是元素\"one\"、“two\"和\"three\"的地址，打印的就是\"one”、\"two\"和\"three\"了。 那么原程序如何修改一下才能让其按期望输出（“one”、“two”、“three”, “four”, “five”, “six”）呢？其实只需将 field 类型 print 方法的 receiver 类型由*field 改为 field 即可。 // method_nature_5.go ... ... type field struct &#123; name string &#125; func (p field) print() &#123; fmt.Println(p.name) &#125; ... ... 修改后的程序的输出结果为（因 goroutine 调度顺序不同，在你的机器上的结果输出顺序与这里可能会有不同）： one two three four five six 至于其中的原因，大家可以参考我的分析思路自行分析一下(可参考本节文章配套源码：method_nature_6.go。 4. 小结 本节要点： Go 方法的本质：一个以方法所绑定类型实例为第一个参数的普通函数； Go 语法甜头使得我们通过类型实例调用类型方法时无需考虑实例类型与 receiver 参数类型是否一致，编译器会为我们做自动转换； receiver 参数类型选择时要看是否要对类型实例进行修改；如有修改需求，则选择*T；如无修改需求，T 类型 receiver 传值的性能损耗也是考量因素之一。 } 19 defer 让你的代码更清晰 21 方法集合决定接口实现 扫码加入慕课前沿技术核心用户群 验证信息：2010312025386365复制 QQ讨论群号：729941811 QQ群URL：点击访问 若遇到搜索不到QQ群或加群失败，请联系客服邮箱:kf@imooc.com"},{"title":"","date":"2024-03-12T03:55:12.947Z","updated":"2024-03-12T03:55:12.947Z","comments":true,"path":"book/18Go函数是“一等公民”慕课专栏.html","permalink":"https://smartxia.github.io/blog/book/18Go%E5%87%BD%E6%95%B0%E6%98%AF%E2%80%9C%E4%B8%80%E7%AD%89%E5%85%AC%E6%B0%91%E2%80%9D%E6%85%95%E8%AF%BE%E4%B8%93%E6%A0%8F.html","excerpt":"","text":"18 Go 函数是“一等公民”-慕课专栏 18 Go 函数是“一等公民” 更新时间：2020-10-26 09:34:48 智慧，不是死的默念，而是生的沉思。——斯宾诺莎 函数（function）作为现代编程语言的基本语法元素存在于支持各种范式（paradiam）的主流编程语言当中。无论是命令式语言 C、多范式通用编程语言 C++，还是面向对象编程语言 Java、Ruby，亦或是函数式语言 Haskell、动态脚本语言 Python、PHP、JavaScript，函数这一语法元素都是当仁不让的核心。 Go 语言以“成为新一代系统级语言”为目标而诞生，但在演化过程中，逐渐演化成了面向并发、契合现代硬件发展趋势的通用编程语言。Go 语言中没有那些典型的面向对象语言的语法，比如类、继承、对象等。Go 语言中的方法（method）本质上亦是函数的一个“变种”。因此，在 Go 语言中，函数是唯一一种基于特定输入、实现特定任务并可反馈任务执行结果的代码块。本质上我们可以说 Go 程序就是一组函数的集合。 和其他编程语言中的函数相比，Go 语言的函数具有如下特点： 以“func”关键字开头； 支持多返回值； 支持具名返回值； 支持递归调用； 支持同类型的可变参数； 支持 defer，实现函数优雅返回 更为关键的是函数在 Go 语言中属于“一等公民(first-class citizen)”。众所周知，并不是在所有编程语言中函数都是“一等公民”，本节中我就和大家一起来看看成为”一等公民“的函数都有哪些特质可以帮助我们写出优雅简洁的代码。 1. 什么是“一等公民” 关于什么是编程语言的“一等公民”，业界并没有教科书给出精准的定义。这里引用一下 wiki 发明人、C2 站点作者沃德·坎宁安(Ward Cunningham)对“一等公民”的诠释： 如果一门编程语言对某种语言元素的创建和使用没有限制，我们可以像对待值(value)一样对待这种语法元素，那么我们就称这种语法元素是这门编程语言的“一等公民”。拥有“一等公民”待遇的语法元素可以存储在变量中，可以作为函数传递给函数，可以在函数内部创建并可以作为返回值从函数返回。在动态类型语言中，语言运行时还支持对“一等公民”类型的检查。 基于上面关于“一等公民”的诠释，我们来看看 Go 语言的函数是如何满足上述条件而成为“一等公民”的。 正常创建 我们可以在源码顶层正常创建一个函数，如下面的函数 newPrinter： // $GOROOT/src/fmt/print.go func newPrinter() *pp &#123; p := ppFree.Get().(*pp) p.panicking = false p.erroring = false p.wrapErrs = false p.fmt.init(&amp;p.buf) return p &#125; 在函数内创建 在 Go 语言中，我们可以在函数内定义一个新函数，如下面代码中在 hexdumpWords 函数内部定义的匿名函数（被赋值给变量 p1)。在 C/C++中我们无法实现这一点，这也是 C/C++语言中函数不是“一等公民”的原因之一。 // $GOROOT/src/runtime/print.go func hexdumpWords(p, end uintptr, mark func(uintptr) byte) &#123; p1 := func(x uintptr) &#123; var buf [2 * sys.PtrSize]byte for i := len(buf) - 1; i &gt;= 0; i-- &#123; if x&amp;0xF &lt; 10 &#123; buf[i] = byte(x&amp;0xF) + '0' &#125; else &#123; buf[i] = byte(x&amp;0xF) - 10 + 'a' &#125; x &gt;&gt;= 4 &#125; gwrite(buf[:]) &#125; ... ... &#125; 作为类型 我们可以使用函数来自定义类型，如下面代码中的 HandlerFunc、visitFunc 和 action： // $GOROOT/src/net/http/server.go type HandlerFunc func(ResponseWriter, *Request) // $GOROOT/src/sort/genzfunc.go type visitFunc func(ast.Node) ast.Visitor // codewalk: https://tip.golang.org/doc/codewalk/functions/ type action func(current score) (result score, turnIsOver bool) 存储到变量中 我们可以将定义好的函数存储到一个变量中，如下面代码中的 apply： // $GOROOT/src/runtime/vdso_linux.go func vdsoParseSymbols(info *vdsoInfo, version int32) &#123; if !info.valid &#123; return &#125; apply := func(symIndex uint32, k vdsoSymbolKey) bool &#123; sym := &amp;info.symtab[symIndex] typ := _ELF_ST_TYPE(sym.st_info) bind := _ELF_ST_BIND(sym.st_info) ... ... *k.ptr = info.loadOffset + uintptr(sym.st_value) return true &#125; ... ... &#125; 作为参数传入函数 我们可以将函数作为参数传入函数，比如下面代码中函数 AfterFunc 的参数 f： $GOROOT/src/time/sleep.go func AfterFunc(d Duration, f func()) *Timer &#123; t := &amp;Timer&#123; r: runtimeTimer&#123; when: when(d), f: goFunc, arg: f, &#125;, &#125; startTimer(&amp;t.r) return t &#125; 作为返回值从函数返回 函数还可以被作为返回值从函数返回，如下面代码中函数 makeCutsetFunc 的返回值就是一个函数： // $GOROOT/src/strings/strings.go func makeCutsetFunc(cutset string) func(rune) bool &#123; if len(cutset) == 1 &amp;&amp; cutset[0] &lt; utf8.RuneSelf &#123; return func(r rune) bool &#123; return r == rune(cutset[0]) &#125; &#125; if as, isASCII := makeASCIISet(cutset); isASCII &#123; return func(r rune) bool &#123; return r &lt; utf8.RuneSelf &amp;&amp; as.contains(byte(r)) &#125; &#125; return func(r rune) bool &#123; return IndexRune(cutset, r) &gt;= 0 &#125; &#125; 我们看到：就像沃德·坎宁安(Ward Cunningham)对“一等公民”的诠释中所说的那样，Go 中的函数可以像普通整型值那样被创建和使用。 除了上面那些例子，函数还可以被放入数组/切片/map 等结构中、可以像其他类型变量一样被赋值给 interface{}、甚至我们可以建立元素为函数的 channel，如下面例子： // function_as_first_class_citizen_1.go package main import \"fmt\" type binaryCalcFunc func(int, int) int func main() &#123; var i interface&#123;&#125; = binaryCalcFunc(func(x, y int) int &#123; return x + y &#125;) c := make(chan func(int, int) int, 10) fns := []binaryCalcFunc&#123; func(x, y int) int &#123; return x + y &#125;, func(x, y int) int &#123; return x - y &#125;, func(x, y int) int &#123; return x * y &#125;, func(x, y int) int &#123; return x / y &#125;, func(x, y int) int &#123; return x % y &#125;, &#125; c &lt;- func(x, y int) int &#123; return x * y &#125; fmt.Println(fns[0](5, 6)) f := &lt;-c fmt.Println(f(7, 10)) v, ok := i.(binaryCalcFunc) if !ok &#123; fmt.Println(\"type assertion error\") return &#125; fmt.Println(v(17, 7)) &#125; 和 C/C++这类语言相比，作为“一等公民”的 Go 函数拥有难得的\"灵活性\"。接下来我们需要考虑如何使用 Go 函数才能发挥出它作为“一等公民”的最大效用。 2. 函数作为“一等公民”的特殊运用 1). 像整型变量那样对函数进行显式转型 Go 是类型安全的语言，Go 语言不允许隐式类型转换，因此下面的代码是无法通过编译的： var a int = 5 var b int32 = 6 fmt.Println(a + b) // 违法操作: a + b (不匹配的类型int和int32) 我们必须通过对上面代码进行显式的转型才能通过编译器的检查： var a int = 5 var b int32 = 6 fmt.Println(a + int(b)) // ok。输出11 函数是“一等公民”，对整型变量进行的操作也同样可以用在函数上面，即函数也可以被显式转型，并且这样的转型在特定的领域具有奇妙的作用。一个最为典型的示例就是 http.HandlerFunc 这个类型，我们来看一下例子： // function_as_first_class_citizen_2.go package main import ( \"fmt\" \"net/http\" ) func greeting(w http.ResponseWriter, r *http.Request) &#123; fmt.Fprintf(w, \"Welcome, Gopher!\\n\") &#125; func main() &#123; http.ListenAndServe(\":8080\", http.HandlerFunc(greeting)) &#125; 上述代码是我们日常最为常见的一个用 Go 构建的 Web Server 的例子。其工作机制很简单，当用户通过浏览器或类似 curl 这样的命令行工具访问 Web server 的 8080 端口时，会收到“Welcome, Gopher!”一行文字版应答。很多 Gopher 可能并未真正深入分析过这段代码，这里用到的恰恰是函数作为“一等公民”的特性，我们来看一下。 我们先来看一下 ListenAndServe 的源码： // $GOROOT/src/net/http/server.go func ListenAndServe(addr string, handler Handler) error &#123; server := &amp;Server&#123;Addr: addr, Handler: handler&#125; return server.ListenAndServe() &#125; ListenAndServe 会将来自客户端的 http 请求交给其第二个参数 handler 处理，而这里 handler 参数的类型 http.Handler 接口： // $GOROOT/src/net/http/server.go type Handler interface &#123; ServeHTTP(ResponseWriter, *Request) &#125; 该接口仅有一个方法：ServeHTTP，其原型为：func(http.ResponseWriter, *http.Request)。这与我们自己定义的 http 请求处理函数 greeting 的原型是一致的。但是我们没法直接将 greeting 作为参数值传入，否则会报下面错误： func(http.ResponseWriter, *http.Request) does not implement http.Handler (missing ServeHTTP method) 即函数 greeting 并未实现接口 Handler 的方法，无法将其赋值给 Handler 类型的参数。 在代码中我们也并未直接将 greeting 传入 ListenAndServe，而是将 http.HandlerFunc(greeting)作为参数传给了 ListenAndServe。我们来看看 http.HandlerFunc 是什么？ // $GOROOT/src/net/http/server.go type HandlerFunc func(ResponseWriter, *Request) // ServeHTTP calls f(w, r). func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) &#123; f(w, r) &#125; HandlerFunc 其实就是一个基于函数定义的新类型，它的底层类型为 func(ResponseWriter, *Request)。该类型有一个方法 ServeHTTP，继而实现了 Handler 接口。也就是说 http.HandlerFunc(greeting)这句代码的真正含义是将函数 greeting 显式转换为 HandlerFunc 类型，后者实现了 Handler 接口，满足 ListenAndServe 函数第二个参数的要求。 另外，之所以 http.HandlerFunc(greeting)这个语句可以通过编译器检查，正是因为 HandlerFunc 的底层类型正是 func(ResponseWriter, *Request)，与 greeting 的原型是一致的。这和下面整型变量的转型原理并无二致： type MyInt int var x int = 5 y := MyInt(x) // MyInt的底层类型为int，类比 HandlerFunc的底层类型为func(ResponseWriter, *Request) 为了充分理解这种显式转型的“技巧”，我们再来看一个简化后的例子： // function_as_first_class_citizen_3.go package main import \"fmt\" type BinaryAdder interface &#123; Add(int, int) int &#125; type MyAdderFunc func(int, int) int func (f MyAdderFunc) Add(x, y int) int &#123; return f(x, y) &#125; func MyAdd(x, y int) int &#123; return x + y &#125; func main() &#123; var i BinaryAdder = MyAdderFunc(MyAdd) fmt.Println(i.Add(5, 6)) &#125; 和 Web server 那个例子一样，我们想将 MyAdd 这个函数赋值给 BinaryAdder 这个接口，直接赋值是不行的，我们需要一个底层函数类型与 MyAdd 一致的自定义类型的显式转换，这个自定义类型就是 MyAdderFunc，该类型实现了 BinaryAdder 接口，这样在经过 MyAdderFunc 的显式转型后，MyAdd 被赋值给了 BinaryAdder 的变量 i。这样通过 i 调用的 Add 方法实质上就是我们的 MyAdd 函数。 2) 函数式编程 Go 语言演进到如今，对多种编程范式或多或少都有支持。比如：对函数式编程的支持就得意于函数是“一等公民”的特质。虽然 Go 不推崇函数式编程，但有些时候应用一些函数式编程风格可以写出更加优雅、更简洁、更易维护的代码。 柯里化函数 我们先来看一种函数式编程的典型应用：柯里化函数(currying)。在计算机科学中，柯里化是把接受多个参数的函数变换成接受一个单一参数(原函数的第一个参数)的函数，并且返回接受余下的参数和返回结果的新函数的技术。这个技术以逻辑学家 Haskell Curry 命名。 定义总是拗口难懂，我们来用 Go 编写一个直观的柯里化函数的例子： // function_as_first_class_citizen_4.go package main import \"fmt\" func times(x, y int) int &#123; return x * y &#125; func partialTimes(x int) func(int) int &#123; return func(y int) int &#123; return times(x, y) &#125; &#125; func main() &#123; timesTwo := partialTimes(2) timesThree := partialTimes(3) timesFour := partialTimes(4) fmt.Println(timesTwo(5)) fmt.Println(timesThree(5)) fmt.Println(timesFour(5)) &#125; 运行这个例子： $ go run function_as_first_class_citizen_4.go 10 15 20 这里的柯里化是指将原接受两个参数的函数 times 转换为接受一个参数的 partialTimes 的过程。通过 partialTimes 函数构造的 timesTwo 将输入参数扩大为原先 2 倍、timesThree 将输入参数扩大为原先的 3 倍…。 这个例子利用了函数的几点性质： 在函数中定义，通过返回值返回 闭包 闭包是前面没有提到的 Go 函数支持的一个特性。 闭包是在函数内部定义的匿名函数，并且允许该匿名函数访问定义它的外部函数的作用域。本质上，闭包是将函数内部和函数外部连接起来的桥梁。 以上述示例来说，partialTimes 内部定义的匿名函数就是一个闭包，该匿名函数访问了其外部函数(partialTimes)的变量 x。这样当调用 partialTimes(2)时，partialTimes 实际上返回一个调用 times(2,y)的函数： timesTwo = func(y int) int &#123; return times(2, y) &#125; 函子(Functor) 函数式编程范式最让人”望而却步“的就是首先要了解一些抽象概念，比如上面的柯里化，再比如这里的函子(Functor)。什么是函子呢？具体来说，成为函子需要两个条件： 函子本身是一个容器类型，以 Go 语言为例，这个容器可以是切片、map 甚至是 channel； 光是容器还不够，该容器类型还需要实现一个方法，该方法接受一个函数类型参数，并在容器的每个元素上应用那个函数，得到一个新的函子，原函子容器内部的元素值不受到影响 我们还是用一个具体的示例来直观看一下吧： // function_as_first_class_citizen_5.go package main import ( \"fmt\" ) type IntSliceFunctor interface &#123; Fmap(fn func(int) int) IntSliceFunctor &#125; type intSliceFunctorImpl struct &#123; ints []int &#125; func (isf intSliceFunctorImpl) Fmap(fn func(int) int) IntSliceFunctor &#123; newInts := make([]int, len(isf.ints)) for i, elt := range isf.ints &#123; retInt := fn(elt) newInts[i] = retInt &#125; return intSliceFunctorImpl&#123;ints: newInts&#125; &#125; func NewIntSliceFunctor(slice []int) IntSliceFunctor &#123; return intSliceFunctorImpl&#123;ints: slice&#125; &#125; func main() &#123; // 原切片 intSlice := []int&#123;1, 2, 3, 4&#125; fmt.Printf(\"init a functor from int slice: %#v\\n\", intSlice) f := NewIntSliceFunctor(intSlice) fmt.Printf(\"original functor: %+v\\n\", f) mapperFunc1 := func(i int) int &#123; return i + 10 &#125; mapped1 := f.Fmap(mapperFunc1) fmt.Printf(\"mapped functor1: %+v\\n\", mapped1) mapperFunc2 := func(i int) int &#123; return i * 3 &#125; mapped2 := mapped1.Fmap(mapperFunc2) fmt.Printf(\"mapped functor2: %+v\\n\", mapped2) fmt.Printf(\"original functor: %+v\\n\", f) // 原functor没有改变 fmt.Printf(\"composite functor: %+v\\n\", f.Fmap(mapperFunc1).Fmap(mapperFunc2)) &#125; 运行这段代码： $ go run function_as_first_class_citizen_5.go init a functor from int slice: []int&#123;1, 2, 3, 4&#125; original functor: &#123;ints:[1 2 3 4]&#125; mapped functor1: &#123;ints:[11 12 13 14]&#125; mapped functor2: &#123;ints:[33 36 39 42]&#125; original functor: &#123;ints:[1 2 3 4]&#125; composite functor: &#123;ints:[33 36 39 42]&#125; 分析这段代码： 这里我们定义了一个 intSliceFunctorImpl 类型，用来作为 functor 的载体； 我们把 functor 要实现的方法命名为 Fmap，intSliceFunctorImpl 类型实现了该方法。同时该方法也是 IntSliceFunctor 接口的唯一方法；可以看到在这个代码中真正的 functor 其实是 IntSliceFunctor，这符合 Go 的惯用法； 我们定义了创建 IntSliceFunctor 的函数：NewIntSliceFunctor。通过该函数以及一个初始切片，我们可以实例化一个 functor； 我们在 main 中定义了两个转换函数，并将这两个函数应用到上述 functor 实例；我们看到得到的新 functor 的内部容器元素值是在原容器的元素值经由转换函数转换后得到的； 在最后，我们还可以对最初的 functor 实例连续(组合)应用转换函数，这让我们想到了数学课程中的函数组合； 无论如何应用转换函数，原 functor 中容器内的元素值不受到影响。 functor 非常适合对容器集合元素做批量同构处理，而且代码也要比每次都对容器中的元素作循环处理要优雅简洁许多。但要想在 Go 中发挥 functor 的最大效能，还需要 Go 对泛型提供支持，否则我们就需要为每一种容器类型都实现一套对应的 Functor 机制。比如上面的示例仅支持元素类型为 int 的切片，如果元素类型换为 string 或元素类型依然为 int，但容器类型换为 map，我们还需要分别为之编写新的配套代码。 延续传递式(Continuation-passing Style) 函数式编程离不开递归，以求阶乘函数为例，我们可以轻易用递归方法写出一个实现： // function_as_first_class_citizen_6.go func factorial(n int) int &#123; if n == 1 &#123; return 1 &#125; else &#123; return n * factorial(n-1) &#125; &#125; func main() &#123; fmt.Printf(\"%d\\n\", factorial(5)) &#125; 这是一个非常常规的求阶乘的实现思路，但是这种思路并未应用到函数作为”一等公民“的任何特质。函数式编程有一种被称为延续传递式(Continuation-passing Style，以下简称为 CPS）的编程风格可以充分运用函数作为”一等公民“的特质。 在 CPS 风格中，函数是不允许有返回值的。一个函数 A 应该将其想返回的值显式传给一个 continuation 函数(一般接受一个参数)，而这个 continuation 函数自身是函数 A 的一个参数。概念太过抽象，我们用一个简单的例子来说明一下： 下面得 Max 函数的功能是返回两个参数值中较大的那个值： // function_as_first_class_citizen_7.go package main import \"fmt\" func Max(n int, m int) int &#123; if n &gt; m &#123; return n &#125; else &#123; return m &#125; &#125; func main() &#123; fmt.Printf(\"%d\\n\", Max(5, 6)) &#125; 我们把 Max 函数看作是上面定义中的 A 函数在未 CPS 化之前的状态。接下来，我们来根据 CPS 的定义将其转换为 CPS 风格： 首先我们去掉 Max 函数的返回值，并为其添加一个函数类型的参数 f(这个 f 就是定义中的 continuation 函数) func Max(n int, m int, f func(int)) 将返回结果传给 continuation 函数，即把 return 语句替换为对 f 函数的调用 func Max(n int, m int, f func(int)) &#123; if n &gt; m &#123; f(n) &#125; else &#123; f(m) &#125; &#125; 完整的转换后的代码如下： // function_as_first_class_citizen_8.go package main import \"fmt\" func Max(n int, m int, f func(y int)) &#123; if n &gt; m &#123; f(n) &#125; else &#123; f(m) &#125; &#125; func main() &#123; Max(5, 6, func(y int) &#123; fmt.Printf(\"%d\\n\", y) &#125;) &#125; 接下来，我们使用同样的方法将上面的阶乘实现转换为 CPS 风格。 首先我们去掉 factorial 函数的返回值，并为其添加一个函数类型的参数 f(这个 f 也就是 CPS 定义中的 continuation 函数) func factorial(n int, f func(y int)) 接下来，将 factorial 实现中的返回结果传给 continuation 函数，即把 return 语句替换为对 f 函数的调用 func factorial(n int, f func(int)) &#123; if n == 1 &#123; f(n) &#125; else &#123; factorial(n-1, func(y int) &#123; f(n * y) &#125;) &#125; &#125; 由于原 else 分支有递归，因此我们需要把未完成的计算过程封装为一个新的函数 f’作为 factorial 递归调用的第二个参数，f’的参数 y 即为原 factorial(n-1)的计算结果，而 n * y 是要传递给 f 的，于是 f’这个函数的定义就为：func(y int) { f(n * y) }。 转换为 CPS 风格的阶乘函数的完整代码如下： // function_as_first_class_citizen_9.go package main import \"fmt\" func factorial(n int, f func(int)) &#123; if n == 1 &#123; f(1) //基本情况 &#125; else &#123; factorial(n-1, func(y int) &#123; f(n * y) &#125;) &#125; &#125; func main() &#123; factorial(5, func(y int) &#123; fmt.Printf(\"%d\\n\", y) &#125;) &#125; 我们简单解析一下上述实例代码的执行过程(下面用伪代码阐释)： f1 = func(y int) &#123; fmt.Printf(\"%v\\n\", y) factorial(5, f1) f2 = func(y int) &#123;f1(5 * y)&#125; factorial(4, f2) f3 = func(y int) &#123;f2(4 * y)&#125; factorial(3, f3) f4 = func(y int) &#123;f3(3 * y)&#125; factorial(2, f4) f5 = func(y int) &#123;f4(2 * y)&#125; factorial(1, f5) f5(1) =&gt; f5(1) = f4(2 * 1) = f3(3 * 2 * 1) = f2(4 * 3 * 2 * 1) = f1(5 * 4 * 3 * 2 * 1) = 120 读到这里很多朋友会提出心中的疑问：这种 CPS 风格虽然利用了函数作为”一等公民“的特质，但是其代码理解起来颇为困难，这种风格真的好吗？朋友们的担心是有道理的。这里对 CPS 风格的讲解其实是一个”反例“，目的就是告诉大家，尽管作为”一等公民“的函数给 Go 带来的强大的表达能力，但是如果选择了不适合的风格或者说为了函数式而进行函数式编程，那么就会出现代码难于理解，且代码执行效率不高的情况（CPS 需要语言支持尾递归优化，但 Go 目前并不支持)。 3. 小结 成为”一等公民“的函数极大增强了 Go 语言的表现力，我们可以像对待值变量那样对待函数，上述函数编程思想的运用就得益于此。 让自己习惯于函数是”一等公民“，请牢记本节要点： Go 函数可以像变量值那样被赋值给变量、作为参数传递、作为返回值返回和在函数内部创建等； 函数可以像变量那样被显式转型； 基于函数特质，了解 Go 中的几种有用的函数式编程风格：柯里化、函子； 不要为了符合特定风格而滥用函数特质。 } 17 init 函数的妙用 19 defer 让你的代码更清晰 扫码加入慕课前沿技术核心用户群 验证信息：2010312025386365复制 QQ讨论群号：729941811 QQ群URL：点击访问 若遇到搜索不到QQ群或加群失败，请联系客服邮箱:kf@imooc.com"},{"title":"","date":"2024-03-12T03:55:12.948Z","updated":"2024-03-12T03:55:12.948Z","comments":true,"path":"book/21方法集合决定接口实现慕课专栏.html","permalink":"https://smartxia.github.io/blog/book/21%E6%96%B9%E6%B3%95%E9%9B%86%E5%90%88%E5%86%B3%E5%AE%9A%E6%8E%A5%E5%8F%A3%E5%AE%9E%E7%8E%B0%E6%85%95%E8%AF%BE%E4%B8%93%E6%A0%8F.html","excerpt":"","text":"21 方法集合决定接口实现-慕课专栏 21 方法集合决定接口实现 更新时间：2020-10-29 10:58:01 机遇只偏爱那些有准备的头脑。——巴斯德 自定义类型的方法和接口（interface）都是 Go 语言中的重要概念，并且它们之间存在千丝万缕的联系。我们来看一个例子： // method_set_1.go package main type Interface interface &#123; M1() M2() &#125; type T struct&#123;&#125; func (t T) M1() &#123;&#125; func (t *T) M2() &#123;&#125; func main() &#123; var t T var pt *T var i Interface i = t i = pt &#125; 我们运行一下该示例程序： $ go run method_set_1.go # command-line-arguments ./method_set_1.go:18:4: cannot use t (type T) as type Interface in assignment: T does not implement Interface (M2 method has pointer receiver) 我们看到示例程序没有通过编译器的检查，编译器给出的错误信息是：不能使用变量 t 给接口类型变量 i 赋值，因为 t 没有实现 Interface 接口方法集合中的 M2 方法。 如果你是 Go 语言初学者，那么遇到这样的编译器错误提示信息后你一定很疑惑：我们明明为自定义类型 T 定义了 M1 和 M2 方法，为何说尚未实现 M2 方法？为何 *T 类型的 pt 就可以被正常赋值给 Interface 类型变量 i，而 T 类型的 t 就不行？ 带着这些问题，我们开启本节的内容。 1. 方法集合(Method Set) 在”理解方法本质以正确选择 receiver 类型“一节中我们曾提到过选择 receiver 类型除了考量是否需要对类型实例进行修改、类型实例值拷贝导致的性能损耗之外，还有一个重要考量因素，那就是类型是否要实现某个接口（interface）类型。 Go 语言的一个创新就是自定义类型与接口之间的实现关系是松耦合的：如果某个自定义类型 T 的方法集合是某个 interface 类型的方法集合的超集，那么就说类型 T 实现了该接口，并且类型 T 的变量可以被赋值给该接口类型的变量了，即我们说的方法集合决定接口实现。 方法集合（Method Set）是 Go 语言中一个重要的概念，在为接口类型变量赋值、使用结构体嵌入/接口嵌入、类型别名（type alias）和 method expression 等时都会用到方法集合，它像**”胶水“一样将自定义类型与接口隐式地**粘结在一起。 要判断一个自定义类型是否实现了某接口类型，我们首先要识别出自定义类型的方法集合以及接口类型的方法集合。但有些时候它们并非那么明显（比如：若存在结构体嵌入、接口嵌入、类型别名时）。这里我们实现了一个工具函数可以方便输出一个自定义类型或接口类型的方法集合。 package main import ( \"fmt\" \"reflect\" ) // method_set_utils.go func DumpMethodSet(i interface&#123;&#125;) &#123; v := reflect.TypeOf(i) elemTyp := v.Elem() n := elemTyp.NumMethod() if n == 0 &#123; fmt.Printf(\"%s's method set is empty!\\n\", elemTyp) return &#125; fmt.Printf(\"%s's method set:\\n\", elemTyp) for j := 0; j &lt; n; j++ &#123; fmt.Println(\"-\", elemTyp.Method(j).Name) &#125; fmt.Printf(\"\\n\") &#125; 接下来，我们就用该工具函数输出一下本节开头那个示例中的接口类型和自定义类型的方法集合： // method_set_2.go package main type Interface interface &#123; M1() M2() &#125; type T struct&#123;&#125; func (t T) M1() &#123;&#125; func (t *T) M2() &#123;&#125; func main() &#123; var t T var pt *T DumpMethodSet(&amp;t) DumpMethodSet(&amp;pt) DumpMethodSet((*Interface)(nil)) &#125; 运行上述代码： $ go run method_set_2.go method_set_utils.go main.T's method set: - M1 *main.T's method set: - M1 - M2 main.Interface's method set: - M1 - M2 通过上述输出结果，我们可以一目了然地看到 T、*T 和 Interface 各自的方法集合。我们看到 T 类型的方法集合中只包含 M1，无法成为与 Interface 类型的方法集合的超集，因此这就是开篇例子中编译器认为变量 t 不能赋值给 Interface 类型变量的原因。在输出的结果中，我们还看到*T 类型的方法集合为[M1, M2]。*T 类型没有直接实现 M1，但 M1 仍出现在*T 类型的方法集合中了。这符合 Go 语言规范中的说法：对于非接口类型的自定义类型 T，其方法集合为所有 receiver 为 T 类型的方法组成；而类型*T 的方法集合则包含所有 receiver 为 T 和*T 类型的方法。也正因为如此，pt 才能成功赋值给 Interface 类型变量。 到这里，我们完全明确了为 receiver 选择类型时需要考虑的第三点因素：是否支持将 T 类型实例赋值给某个接口类型变量。如果需要支持，我们就要实现 receiver 为 T 类型的接口类型方法集合中的所有方法。 2. 类型嵌入与方法集合 Go 的设计哲学之一就是偏好组合，Go 支持用组合的思想来实现一些面向对象领域经典的机制，比如：继承。而具体的方式就是利用类型嵌入（type embeding）。 Go 支持三种类型嵌入：接口类型中嵌入接口类型、结构体类型中嵌入接口类型以及结构体类型中嵌入结构体类型，下面我们分别看一下经过类型嵌入后的类型的方法集合是什么样子的。 1) 接口类型中嵌入接口类型 按 Go 语言惯例，Go 中的接口类型中仅包含少量方法，并且常常仅是一个方法。通过在接口类型中嵌入其他接口类型可以实现接口的组合，这也是 Go 语言中基于已有接口类型构建新接口类型的惯用法，比如 io 包中的 ReadWriter、ReadWriteCloser 等接口类型就是通过嵌入 Reader、Writer 或 Closer 三个基本的接口类型组合而成的： // $GOROOT/src/io/io.go type Reader interface &#123; Read(p []byte) (n int, err error) &#125; type Writer interface &#123; Write(p []byte) (n int, err error) &#125; type Closer interface &#123; Close() error &#125; // 以上为三个基本接口类型 // 下面的接口类型通过嵌入上面基本接口类型而形成 type ReadWriter interface &#123; Reader Writer &#125; type ReadCloser interface &#123; Reader Closer &#125; type WriteCloser interface &#123; Writer Closer &#125; type ReadWriteCloser interface &#123; Reader Writer Closer &#125; 我们再来看看通过嵌入接口类型后的新接口类型的方法集合是什么样的，我们就以 Go 标准库中 io 包中的几个接口类型为例： // method_set_3.go package main import \"io\" func main() &#123; DumpMethodSet((*io.Writer)(nil)) DumpMethodSet((*io.Reader)(nil)) DumpMethodSet((*io.Closer)(nil)) DumpMethodSet((*io.ReadWriter)(nil)) DumpMethodSet((*io.ReadWriteCloser)(nil)) &#125; 运行该示例得到以下结果： $ go run method_set_3.go method_set_utils.go io.Writer's method set: - Write io.Reader's method set: - Read io.Closer's method set: - Close io.ReadWriter's method set: - Read - Write io.ReadWriteCloser's method set: - Close - Read - Write 通过输出结果我们可以看出：通过嵌入其他接口类型而创建的新接口类型（比如：io.ReadWriteCloser）的方法集合包含了被嵌入接口类型（比如：io.Reader）的方法集合。 不过这种通过嵌入其他接口类型创建新接口类型的方式有一个约束，那就是被嵌入的接口类型的方法集合不能有交集(如下面例子中的 Interface1 和 Interface2 的方法集合有交集，交集是方法 M1)，同时被嵌入的接口类型的方法集合中的方法名字不能与新接口中其他方法名同名（如下面例子中的 Interface2 的 M2 与 Interface4 的 M2 重名）： // method_set_4.go package main type Interface1 interface &#123; M1() &#125; type Interface2 interface &#123; M1() M2() &#125; type Interface3 interface &#123; Interface1 Interface2 // Error: duplicate method M1 &#125; type Interface4 interface &#123; Interface2 M2() // Error: duplicate method M2 &#125; func main() &#123; DumpMethodSet((*Interface3)(nil)) &#125; 2) 结构体类型中嵌入接口类型 在结构体类型中嵌入接口类型后，该结构体类型的方法集合中将包含被嵌入的接口类型的方法集合。比如下面这个例子： // method_set_5.go package main type Interface interface &#123; M1() M2() &#125; type T struct &#123; Interface &#125; func (T) M3() &#123;&#125; func main() &#123; DumpMethodSet((*Interface)(nil)) var t T var pt *T DumpMethodSet(&amp;t) DumpMethodSet(&amp;pt) &#125; 运行该示例得到以下结果： $ go run method_set_5.go method_set_utils.go main.Interface's method set: - M1 - M2 main.T's method set: - M1 - M2 - M3 *main.T's method set: - M1 - M2 - M3 输出的结果与预期一致。 但有些时候结果并非总是这样，比如：当结果体嵌入多个接口类型且这些接口类型的方法集合存在交集时。为了方便后续说明，这里不得不提一下嵌入了其他接口类型的结构体类型的实例在调用方法时，Go 选择方法的次序： 优先选择结构体自身实现的方法; 如果结构体自身并未实现，那么将查找结构体中的嵌入接口类型的方法集中是否有该方法，如果有，则提升（promoted）为结构体的方法； 比如下面例子： // method_set_6.go package main type Interface interface &#123; M1() M2() &#125; type T struct &#123; Interface &#125; func (T) M1() &#123; println(\"T's M1\") &#125; type S struct&#123;&#125; func (S) M1() &#123; println(\"S's M1\") &#125; func (S) M2() &#123; println(\"S's M2\") &#125; func main() &#123; var t = T&#123; Interface: S&#123;&#125;, &#125; t.M1() t.M2() &#125; 当通过结构体 T 的实例变量 t 调用方法 M1 时，由于 T 自身实现了 M1 方法，因此调用的是 T.M1()；当通过变量 t 调用方法 M2 时，由于 T 自身未实现 M2 方法，于是找到结构体 T 的嵌入接口类型 Interface，发现 Interface 类型的方法集合中包含 M2 方法，于是将 Interface 类型的 M2 方法提升为结构体 T 的方法。而此时 T 类型中的匿名字段 Interface 已经赋值为 S 类型的实例，因此通过 Interface 这个嵌入字段调用的 M2 方法实质上是 S.M2()。 下面是上面程序的输出结果，与我们的分析一致： $ go run method_set_6.go T's M1 S's M2 如果结构体嵌入了多个接口类型且这些接口类型的方法集合存在交集，那么编译器将报错，除非结构体自己实现了交集中的所有方法。 我们看一下下面的例子： // method_set_7.go package main type Interface interface &#123; M1() M2() M3() &#125; type Interface1 interface &#123; M1() M2() M4() &#125; type T struct &#123; Interface Interface1 &#125; func main() &#123; t := T&#123;&#125; t.M1() t.M2() &#125; 运行该例子： $ go run method_set_7.go # command-line-arguments ./method_set_7.go:22:3: ambiguous selector t.M1 ./method_set_7.go:23:3: ambiguous selector t.M2 我们看到编译器给出错误提示：编译器在选择 t.M1 和 t.M2 时出现分歧，编译器不知道该选择哪一个。在这个例子中结构体类型 T 嵌入的两个接口类型 Interface 和 Interface1 的方法集合存在交集，都包含 M1 和 M2，而结构体类型 T 自身又没有实现 M1 和 M2，因此编译器在结构体类型内部的嵌入接口类型中寻找 M1/M2 方法时发现两个接口类型 Interface 和 Interface1 都包含 M1/M2，于是编译器因无法做出选择而报错。 为了让编译器能找到 M1/M2，我们可以为 T 增加 M1 和 M2 的实现，这样编译器便会直接选择 T 自己实现的 M1 和 M2，程序也就能顺利通过编译并运行了： // method_set_8.go ... ... type T struct &#123; Interface Interface1 &#125; func (T) M1() &#123; println(\"T's M1\") &#125; func (T) M2() &#123; println(\"T's M2\") &#125; func main() &#123; t := T&#123;&#125; t.M1() t.M2() &#125; $ go run method_set_8.go T's M1 T's M2 不过，我们还是要尽量避免在结构体类型中嵌入方法集合有交集的多个接口类型。 结构体类型在嵌入某接口类型的同时，它也实现了这个接口。这一特性在单元测试时尤为有用，尤其是应对在下面的场景中： // method_set_9.go package employee type Result struct &#123; Count int &#125; func (r Result) Int() int &#123; return r.Count &#125; type Rows []struct&#123;&#125; type Stmt interface &#123; Close() error NumInput() int Exec(stmt string, args ...string) (Result, error) Query(args []string) (Rows, error) &#125; // 返回男性员工总数 func MaleCount(s Stmt) (int, error) &#123; result, err := s.Exec(\"select count(*) from employee_tab where gender=?\", \"1\") if err != nil &#123; return 0, err &#125; return result.Int(), nil &#125; 在这个例子中，我们有一个 employee 包，该包中的方法 MaleCount 方法通过传入的 Stmt 接口的实现从数据库获取男性员工的数量。 现在我们要对 MaleCount 方法编写单元测试代码。对于这种依赖外部数据库操作的方法，我们的惯例是使用“伪对象(fake object)”来冒充真实的 Stmt 接口实现。不过现在有一个问题，那就是 Stmt 接口类型的方法集合中有四个方法，如果我们针对每个测试用例所用的伪对象都实现这四个方法，那么这个工作量有些大，我们需要的仅仅是 Exec 这一个方法。如何快速建立伪对象呢？结构体类型嵌入接口类型便可以帮助我们： // method_set_9_test.go package employee import \"testing\" type fakeStmtForMaleCount struct &#123; Stmt &#125; func (fakeStmtForMaleCount) Exec(stmt string, args ...string) (Result, error) &#123; return Result&#123;Count: 5&#125;, nil &#125; func TestEmployeeMaleCount(t *testing.T) &#123; f := fakeStmtForMaleCount&#123;&#125; c, _ := MaleCount(f) if c != 5 &#123; t.Errorf(\"want: %d, actual: %d\", 5, c) return &#125; &#125; 我们为 TestEmployeeMaleCount 测试用例建立了一个 fakeStmtForMaleCount 的伪对象，在该结构体类型时嵌入 Stmt 接口类型，这样 fakeStmtForMaleCount 就实现了 Stmt 接口，我们实现了快速建立伪对象的目的。然后我们仅需为 fakeStmtForMaleCount 实现 MaleCount 所需的 Exec 方法即可。 3) 结构体类型中嵌入结构体类型 在结构体类型中嵌入结构体类型为 Gopher 提供了一种“实现继承”的手段，外部的结构体类型 T 可以“继承”嵌入的结构体类型的所有方法的实现，并且无论是 T 类型的变量实例还是*T 类型变量实例，都可以调用所有“继承”的方法。 // method_set_10.go package main type T1 struct&#123;&#125; func (T1) T1M1() &#123; println(\"T1's M1\") &#125; func (T1) T1M2() &#123; println(\"T1's M2\") &#125; func (*T1) PT1M3() &#123; println(\"PT1's M3\") &#125; type T2 struct&#123;&#125; func (T2) T2M1() &#123; println(\"T2's M1\") &#125; func (T2) T2M2() &#123; println(\"T2's M2\") &#125; func (*T2) PT2M3() &#123; println(\"PT2's M3\") &#125; type T struct &#123; T1 *T2 &#125; func main() &#123; t := T&#123; T1: T1&#123;&#125;, T2: &amp;T2&#123;&#125;, &#125; println(\"call method through t:\") t.T1M1() t.T1M2() t.PT1M3() t.T2M1() t.T2M2() t.PT2M3() println(\"\\ncall method through pt:\") pt := &amp;t pt.T1M1() pt.T1M2() pt.PT1M3() pt.T2M1() pt.T2M2() pt.PT2M3() println(\"\") var t1 T1 var pt1 *T1 DumpMethodSet(&amp;t1) DumpMethodSet(&amp;pt1) var t2 T2 var pt2 *T2 DumpMethodSet(&amp;t2) DumpMethodSet(&amp;pt2) DumpMethodSet(&amp;t) DumpMethodSet(&amp;pt) &#125; 示例运行结果如下： $ go run method_set_10.go method_set_utils.go call method through t: T1's M1 T1's M2 PT1's M3 T2's M1 T2's M2 PT2's M3 call method through pt: T1's M1 T1's M2 PT1's M3 T2's M1 T2's M2 PT2's M3 main.T1's method set: - T1M1 - T1M2 *main.T1's method set: - PT1M3 - T1M1 - T1M2 main.T2's method set: - T2M1 - T2M2 *main.T2's method set: - PT2M3 - T2M1 - T2M2 main.T's method set: - PT2M3 - T1M1 - T1M2 - T2M1 - T2M2 *main.T's method set: - PT1M3 - PT2M3 - T1M1 - T1M2 - T2M1 - T2M2 通过输出结果可以看出：虽然通过 T 还是*T 变量实例，都可以调用所有“继承”的方法(这也是 Go 语法甜头)，但是 T 和*T 类型的方法集合是有差别的： 类型 T 的方法集合 = T1 的方法集合 + *T2 的方法集合； 类型*T 的方法集合 = *T1 的方法集合 + *T2 的方法集合； 3. 类型别名的方法集合 Go 在 1.9 版本中引入了类型别名（type alias），支持为已有类型定义别名，如： type MyInterface I type Mystruct T 类型别名与原类型几乎可以理解为是完全等价的。Go 预定义标识符 rune、byte 就是通过 type alias 语法定义的： // $GOROOT/src/builtin/builtin.go // byte is an alias for uint8 and is equivalent to uint8 in all ways. It is // used, by convention, to distinguish byte values from 8-bit unsigned // integer values. type byte = uint8 // rune is an alias for int32 and is equivalent to int32 in all ways. It is // used, by convention, to distinguish character values from integer values. type rune = int32 但是在方法集合上面，类型别名与原类型是有差别的。我们看一个例子： // method_set_11.go package main type T struct&#123;&#125; func (T) M1() &#123;&#125; func (*T) M2() &#123;&#125; type Interface interface &#123; M1() M2() &#125; type T1 T type Interface1 Interface func main() &#123; var t T var pt *T var t1 T1 var pt1 *T1 DumpMethodSet(&amp;t) DumpMethodSet(&amp;t1) DumpMethodSet(&amp;pt) DumpMethodSet(&amp;pt1) DumpMethodSet((*Interface)(nil)) DumpMethodSet((*Interface1)(nil)) &#125; 运行该示例程序得到如下结果： $ go run method_set_11.go method_set_utils.go main.T's method set: - M1 main.T1's method set is empty! *main.T's method set: - M1 - M2 *main.T1's method set is empty! main.Interface's method set: - M1 - M2 main.Interface1's method set: - M1 - M2 从例子的输出结果上来看，Go 对于接口类型和自定义类型的类型别名给出了“不一致”的结果： 接口类型的别名类型与原接口类型的方法集合是一致的，如上面的 Interface 和 Interface1； 自定义类型的别名类型则并没有“继承”原类型的方法集合，别名类型的方法集合是空的。 方法集合决定接口实现：自定义类型的别名类型的方法集合为空的事实也决定了即便原类型实现了某些接口，其别名类型也没有“继承”这一隐式关联。别名类型要想实现那些接口，仍需重新实现接口的所有方法。 4. 小结 本节要点： 方法集合是类型与接口间“隐式”关系的纽带，只有类型的方法集合是某接口类型的超集时，我们才说该类型实现了某接口； 类型 T 的方法集合为以 T 为 receiver 类型的所有方法的集合；类型*T 的方法集合为以*T 为 receiver 类型的所有方法的集合与类型 T 的方法集合的并集； 了解类型嵌入对接口类型和自定义结构体类型的方法集合的影响； 接口类型的别名类型与原类型具有相同的方法集合；自定义类型的别名类型的方法集合为空。 } 20 Go 方法的本质 22 变长参数函数的妙用 扫码加入慕课前沿技术核心用户群 验证信息：2010312025386365复制 QQ讨论群号：729941811 QQ群URL：点击访问 若遇到搜索不到QQ群或加群失败，请联系客服邮箱:kf@imooc.com"},{"title":"友情链接","date":"2019-12-25T07:28:57.000Z","updated":"2024-03-12T03:55:12.973Z","comments":true,"path":"link/index.html","permalink":"https://smartxia.github.io/blog/link/index.html","excerpt":"","text":""},{"title":"","date":"2024-03-12T03:55:12.949Z","updated":"2024-03-12T03:55:12.949Z","comments":true,"path":"book/22变长参数函数的妙用慕课专栏.html","permalink":"https://smartxia.github.io/blog/book/22%E5%8F%98%E9%95%BF%E5%8F%82%E6%95%B0%E5%87%BD%E6%95%B0%E7%9A%84%E5%A6%99%E7%94%A8%E6%85%95%E8%AF%BE%E4%B8%93%E6%A0%8F.html","excerpt":"","text":"22 变长参数函数的妙用-慕课专栏 22 变长参数函数的妙用 更新时间：2020-10-30 09:42:34 完成工作的方法，是爱惜每一分钟。——达尔文 在 Go 语言中，我们日常使用最多但又经常被”忽视“的一类函数就是变长参数函数。 说变长参数函数被使用得最多是因为最常用的 fmt 包、log 包中的几个导出函数都是变长参数函数： // $GOROOT/src/fmt/print.go func Println(a ...interface&#123;&#125;) (n int, err error) func Printf(format string, a ...interface&#123;&#125;) (n int, err error) func Fprintf(w io.Writer, format string, a ...interface&#123;&#125;) (n int, err error) func Fprint(w io.Writer, a ...interface&#123;&#125;) (n int, err error) func Sprintf(format string, a ...interface&#123;&#125;) string func Sprintln(a ...interface&#123;&#125;) string // $GOROOT/src/log/log.go func Printf(format string, v ...interface&#123;&#125;) func Println(v ...interface&#123;&#125;) func Fatal(v ...interface&#123;&#125;) func Fatalf(format string, v ...interface&#123;&#125;) func Fatalln(v ...interface&#123;&#125;) func Panic(v ...interface&#123;&#125;) func Panicf(format string, v ...interface&#123;&#125;) func Panicln(v ...interface&#123;&#125;) 并且 Go 内置的常用于切片类型操作的 append 函数也是变长参数函数： // $GOROOT/src/builtin/builtin.go func append(slice []Type, elems ...Type) []Type 但日常我们却很少基于变长参数设计和实现自己的函数或方法。究其原因，笔者认为除了对变长参数函数的理解可能不足之外，更主要的原因是没有找到很好的变长参数函数应用模式。 但有些时候使用变长参数函数可以简化代码逻辑，使代码更易阅读和理解。在这一节中，我就和大家一起来了解一下变长参数函数以及它的几个典型应用模式。 1. 什么是变长参数函数 顾名思义，变长参数函数就是指函数调用时可以接受零个、一个或多个实际参数，就像下面对 fmt.Println 的调用那样： fmt.Println() // ok fmt.Println(\"Tony\", \"Bai\") // ok fmt.Println(\"Tony\", \"Bai\", \"is\", \"a\", \"gopher\") // ok 对照下面 fmt.Println 函数的原型： func Println(a ...interface&#123;&#125;) (n int, err error) 我们看到：无论传入零个、两个还是多个实际参数，这些实参都传给了 Println 的形式参数 a。形参 a 的类型是一个比较”奇特“的组合：… interface{}，这种接受**”…T“类型形式参数的函数就被称为变长参数函数**。 一个变长参数函数只能有一个**”…T“**类型形式参数，并且该形式参数应该为函数参数列表中的最后一个形式参数，否则 Go 编译器就会给出如下错误提示： func foo(args ...int, s string) int // syntax error: cannot use ... with non-final parameter args func bar(args1 ...int, args2 ...string) int // syntax error: cannot use ... with non-final parameter args1 变长参数函数的**”…T“**类型形式参数在函数体内呈现为[]T 类型的变量，我们可以将其理解为一个 Go 语法甜头： // variadic_function_1.go func sum(args ...int) int &#123; var total int // 下面的args的类型为[]int for _, v := range args &#123; total += v &#125; return total &#125; 但在函数外部，”…T“ 类型形式参数可匹配和接受的实参类型有两种： 多个 T 类型变量； t…（t 为 []T 类型变量）； // variadic_function_1.go func main() &#123; a, b, c := 1, 2, 3 println(sum(a, b, c)) // 传入多个int类型的变量 nums := []int&#123;4, 5, 6&#125; println(sum(nums...)) // 传入\"nums...\"，num为[]int型变量 &#125; 但我们只能选择上述两种实参类型中的一种：要么是多个 T 类型变量，要么是t…（t 为[]T 类型变量）。如果两种放在一起混用，则会得到类似下面的编译错误： println(sum(a, b, c, nums...)) // too many arguments in call to sum have (int, int, int, []int...) want (...int) 这里将变长参数函数的形参和实参类型总结为下面的示意图： 图4-6-1: 变长参数函数的形参和实参 使用变长参数函数时最容易出现的一个问题就是实参与形参的不匹配，比如下面这个例子： // variadic_function_2.go package main import \"fmt\" func dump(args ...interface&#123;&#125;) &#123; for _, v := range args &#123; fmt.Println(v) &#125; &#125; func main() &#123; s := []string&#123;\"Tony\", \"John\", \"Jim\"&#125; dump(s...) &#125; 运行这段代码： $ go run variadic_function_2.go # command-line-arguments ./variadic_function_2.go:14:6: cannot use s (type []string) as type []interface &#123;&#125; in argument to dump 我们看到：编译器给出了”类型不匹配“的错误。 dump 函数的变长参数类型为”…interface{}“，因此匹配该形参的要么是 interface{} 类型的变量，要么为t…(t 类型为[]interface{})。在例子中给 dump 传入的实参为s…，但 s 的类型为[]string，并非[]interface{}，导致不匹配。这里要注意的是虽然 string 类型变量可以直接赋值给 interface{} 类型变量，但是 []string 类型变量并不能直接赋值给 []interface{} 类型变量。 要消除编译错误，我们仅需将变量 s 的类型换为 []interface{}： // variadic_function_2.go ... ... func main() &#123; s := []interface&#123;&#125;&#123;\"Tony\", \"John\", \"Jim\"&#125; dump(s...) &#125; $ go run variadic_function_2.go Tony John Jim 不过有个例外，那就是 Go 内置的 append 函数，它支持通过下面的方式将字符串附加到一个字节切片后面： // variadic_function_3.go package main import \"fmt\" func main() &#123; b := []byte&#123;&#125; b = append(b, \"hello\"...) fmt.Println(string(b)) &#125; $ go run variadic_function_3.go hello string 类型本是不满足类型要求的（append 本需要[]byte…)， 这算是 Go 编译器的一个优化，编译器自动将 string 隐式转换为了 []byte。如果是我们自定义的函数，那么是无论如何都不能支持这样的用法的： // variadic_function_3.go package main import \"fmt\" func foo(b ...byte) &#123; fmt.Println(string(b)) &#125; func main() &#123; b := []byte&#123;&#125; b = append(b, \"hello\"...) fmt.Println(string(b)) foo(\"hello\"...) &#125; $ go run variadic_function_3.go # command-line-arguments ./variadic_function_3.go:14:6: cannot use \"hello\" (type string) as type []byte in argument to foo 2. 模拟函数重载 Go 语言不允许在同一个作用域下定义名字相同但函数原型不同的函数，如果定义这样的函数，Go 编译器会提示下面错误信息： // variadic_function_4.go package main import ( \"fmt\" \"strings\" ) func concat(a, b int) string &#123; return fmt.Printf(\"%d %d\", a, b) &#125; func concat(x, y string) string &#123; return x + \" \" + y &#125; func concat(s []string) string &#123; return strings.Join(s, \" \") &#125; func main() &#123; println(concat(1, 2)) println(concat(\"hello\", \"gopher\")) println(concat([]string&#123;\"hello\", \"gopher\", \"!\"&#125;)) &#125; $ go run variadic_function_4.go # command-line-arguments ./variadic_function_4.go:9:2: too many arguments to return have (int, error) want (string) ./variadic_function_4.go:12:6: concat redeclared in this block previous declaration at ./variadic_function_4.go:8:23 ./variadic_function_4.go:16:6: concat redeclared in this block previous declaration at ./variadic_function_4.go:12:26 ./variadic_function_4.go:21:16: too many arguments in call to concat have (number, number) want ([]string) ./variadic_function_4.go:22:16: too many arguments in call to concat have (string, string) want ([]string) 如果要修复上面的例子程序，我们需要将三个”concat“函数作分别命名，比如： concatTwoInt concatTwoString concatStrings 在其他一些主流编程语言中（比如:C++），这种在同一声明域中的名字相同但参数列表不同的函数被称为重载函数(overloaded function)，编译器根据实际的参数传递来判断究竟该使用哪个函数。通过重载函数，你可以根据参数的类型和数量为同名函数提供不同的语义。 但 Go 语言并不支持函数重载，Go 语言官方常见问答(即：FAQ)中给出的不支持的理由如下: 其他语言的经验告诉我们，使用具有相同名称但函数签名不同的多种方法有时会很有用，但在实践中也可能会造成混淆和脆弱性。 在 Go 的类型系统中，仅按名称进行匹配并要求类型一致是一个主要的简化决策。 不可否认重载函数会增加语言的复杂性，笔者在早期使用 C++ 语言开发时已经深刻体会到了这一点。Go 语言的设计哲学也让最初的设计者们倾向于简化而放弃了对函数重载的支持，但他们也承认了有些时候函数重载是很有用的。那么我们在 Go 语言中怎么模拟重载函数呢？变长参数函数显然是最好的选择。 如果要重载的函数的参数都是相同类型的，仅参数的个数是变化的，那么变长参数函数可以轻松对应；如果参数类型不同且个数可变，那么我们还要结合 interface{}类型的特性。我们来看一个例子： // variadic_function_5.go package main import ( \"fmt\" \"strings\" ) func concat(sep string, args ...interface&#123;&#125;) string &#123; var result string for i, v := range args &#123; if i != 0 &#123; result += sep &#125; switch v.(type) &#123; case int, int8, int16, int32, int64, uint, uint8, uint16, uint32, uint64: result += fmt.Sprintf(\"%d\", v) case string: result += fmt.Sprintf(\"%s\", v) case []int: ints := v.([]int) for i, v := range ints &#123; if i != 0 &#123; result += sep &#125; result += fmt.Sprintf(\"%d\", v) &#125; case []string: strs := v.([]string) result += strings.Join(strs, sep) default: fmt.Printf(\"the argument type [%T] is not supported\", v) return \"\" &#125; &#125; return result &#125; func main() &#123; println(concat(\"-\", 1, 2)) println(concat(\"-\", \"hello\", \"gopher\")) println(concat(\"-\", \"hello\", 1, uint32(2), []int&#123;11, 12, 13&#125;, 17, []string&#123;\"robot\", \"ai\", \"ml\"&#125;, \"hacker\", 33)) &#125; 在上面这个例子中，我们定义了一个 concat 函数，该函数支持接受任意数量的整型、字符串、整型切片、字符串切片参数，并将输入的参数通过分隔符（sep）连接在一起。看 main 函数中对 concat 的调用，是不是有一种调用重载函数的味道儿！我们运行一下该例子： $ go run variadic_function_5.go 1-2 hello-gopher hello-1-2-11-12-13-17-robot-ai-ml-hacker-33 3. 模拟实现函数的可选参数与默认参数 如果参数在传入时有隐式要求的固定顺序(这点由调用者保证)，我们还可以利用变长参数函数模拟实现函数的可选参数和默认参数。 我们来看下面例子： // variadic_function_6.go package main import \"fmt\" type record struct &#123; name string gender string age uint16 city string country string &#125; func enroll(args ...interface&#123;&#125; /* name, gender, age, city = \"Beijing\", country = \"China\" */) (*record, error) &#123; if len(args) &gt; 5 || len(args) &lt; 3 &#123; return nil, fmt.Errorf(\"the number of arguments passed is wrong\") &#125; r := &amp;record&#123; city: \"Beijing\", // 默认值：Beijing country: \"China\", // 默认值：China &#125; for i, v := range args &#123; switch i &#123; case 0: // name name, ok := v.(string) if !ok &#123; return nil, fmt.Errorf(\"name is not passed as string\") &#125; r.name = name case 1: // gender gender, ok := v.(string) if !ok &#123; return nil, fmt.Errorf(\"gender is not passed as string\") &#125; r.gender = gender case 2: // age age, ok := v.(int) if !ok &#123; return nil, fmt.Errorf(\"age is not passed as int\") &#125; r.age = uint16(age) case 3: // city city, ok := v.(string) if !ok &#123; return nil, fmt.Errorf(\"city is not passed as string\") &#125; r.city = city case 4: // country country, ok := v.(string) if !ok &#123; return nil, fmt.Errorf(\"country is not passed as string\") &#125; r.country = country default: return nil, fmt.Errorf(\"unknown argument passed\") &#125; &#125; return r, nil &#125; func main() &#123; r, _ := enroll(\"小明\", \"male\", 23) fmt.Printf(\"%+v\\n\", *r) r, _ = enroll(\"小红\", \"female\", 13, \"Hangzhou\") fmt.Printf(\"%+v\\n\", *r) r, _ = enroll(\"Leo Messi\", \"male\", 33, \"Barcelona\", \"Spain\") fmt.Printf(\"%+v\\n\", *r) r, err := enroll(\"小吴\", 21, \"Suzhou\") if err != nil &#123; fmt.Println(err) return &#125; &#125; 在该例子中，我们要实现一个 enroll 函数，用于登记一些人员信息。人员信息包括：姓名（name）、性别（gender）、年龄（age）、城市（city）和国家（country）。其中城市（city)和国家（country）这两个字段是可选字段并且具有默认值。我们结合变长参数函数和 interface{} 类型的特点来实现这个函数，city 和 country 的默认值是在 record 类型实例创建时赋予的初值。实现这样的一个 enroll 函数的前提就是其调用方要负责按正确的顺序传入参数并保证参数类型满足函数要求。 我们运行一下上面的例子： $ go run variadic_function_6.go &#123;name:小明 gender:male age:23 city:Beijing country:China&#125; &#123;name:小红 gender:female age:13 city:Hangzhou country:China&#125; &#123;name:Leo Messi gender:male age:33 city:Barcelona country:Spain&#125; gender is not passed as string 我们看到： 在第一次 enroll 函数调用时，我们省略了 city 和 country 的传参，因此得到了记录中 city 和 country 都是默认值； 在第二次 enroll 函数调用时，我们省略了 country 的传参，因此得到的记录中，country 是默认值； 第三次 enroll 函数调用，我们传递了 city 和 country，因此得到的记录中，city 和 country 没有使用默认值，使用的是传入的参数值； 第四次 enroll 函数调用时，调用者没有按照约定传入 gender 参数，因此，enroll 函数返回一个错误。 我们看到基于上述前提而用 Go 实现的可选参数和默认参数是有局限的：调用者只能从右侧的参数开始逐一做省略传递的处理，比如：可以省略 country，可以省略 country、city，但不能省略 city 而不省略 country 的传递。 4. 实现”功能选项“模式 日常 Go 编程时，我们经常会去实现一些带有设置选项的创建型函数，比如：我们要创建一个网络通信的客户端，创建客户端实例的函数需要提供某种方式可以让调用者设置客户端的一些行为属性，比如：超时时间、重试次数等。对于一些复杂的 Go 包中的创建型函数，它要提供的可设置选项有时多达数十种，甚至后续还会增加。因此，设计和实现这样的创建型函数时要尤为考虑使用者的体验：不能因选项较多而提供过多的 API，并且要保证选项持续增加后，函数的对外接口依旧保持稳定。 接下来就让我们用一个简单的示例来看看变长参数函数在这里究竟能发挥什么样的作用。我们先从一个简单的版本开始并对其进行持续优化，直到实现令我们满意的最终版本。 我们来设计和实现一个 NewFinishedHouse 函数，该函数返回一个”FinishedHouse(精装房)“实例。生活中精装房是由不同装修选项的，比如： 装修风格：美式/中式/欧式； 是否安装中央空调系统； 地面材料：瓷砖/实木地板； 墙面材料：乳胶漆/壁纸/硅藻泥。 可能还有很多装修配置选项，但这里使用上述这几个就足以满足示例的需要了。 1) 版本 1：通过参数暴露配置选项 一个最简单直接的实现方法就是通过函数参数暴露配置选项，让调用者可以自行设置自己所需要的精装房风格和使用的材料： // variadic_function_7.go package main import \"fmt\" type FinishedHouse struct &#123; style int // 0: Chinese, 1: American, 2: European centralAirConditioning bool // true or false floorMaterial string // \"ground-tile\" or ”wood\" wallMaterial string // \"latex\" or \"paper\" or \"diatom-mud\" &#125; func NewFinishedHouse(style int, centralAirConditioning bool, floorMaterial, wallMaterial string) *FinishedHouse &#123; // here: you should do some check to the arguments passed h := &amp;FinishedHouse&#123; style: style, centralAirConditioning: centralAirConditioning, floorMaterial: floorMaterial, wallMaterial: wallMaterial, &#125; return h &#125; func main() &#123; fmt.Printf(\"%+v\\n\", NewFinishedHouse(0, true, \"wood\", \"paper\")) &#125; 运行该例子： $ go run variadic_function_7.go &amp;&#123;style:0 centralAirConditioning:true floorMaterial:wood wallMaterial:paper&#125; 上述这个设计的唯一优点就是能够快速实现，但不足之处却有很多，最致命的是该接口没法扩展。如果我们此时应用户要求增加一个室内门型设置的选项（可选实木门/板材套装门），那么该接口无法满足。考虑兼容性原则，该接口一但发布就成为了 API 的一部分，我们不能随意变更。于是我们唯一能做的就是新增一个创建函数，比如：NewFinishedHouseWithDoorOption。如果后续要增加其他设置选项，API 中很大可能会充斥着 NewFinishedHouseWithXxxOption1、NewFinishedHouseWithYyyOpiton、… NewFinishedHouseWithZzzOption 等新接口。 2) 版本 2：使用结构体封装配置选项 软件设计中的一个比较重要的原则就是“封装变化”，既然我们无法控制将来要加入的配置选项的个数和内容，但还要尽可能保持提供单一接口，我们就把“配置选项”这个变量抽取出来封装到一个结构体中，这也是目前比较常见的作法。 下面是我们的第二个版本： // variadic_function_8.go package main import \"fmt\" type FinishedHouse struct &#123; style int // 0: Chinese, 1: American, 2: European centralAirConditioning bool // true or false floorMaterial string // \"ground-tile\" or ”wood\" wallMaterial string // \"latex\" or \"paper\" or \"diatom-mud\" &#125; type Options struct &#123; Style int // 0: Chinese, 1: American, 2: European CentralAirConditioning bool // true or false FloorMaterial string // \"ground-tile\" or ”wood\" WallMaterial string // \"latex\" or \"paper\" or \"diatom-mud\" &#125; func NewFinishedHouse(options *Options) *FinishedHouse &#123; // use default style and materials if option is nil var style int = 0 var centralAirConditioning = true var floorMaterial = \"wood\" var wallMaterial = \"paper\" if options != nil &#123; // here: you should do some check to the options passed style = options.Style centralAirConditioning = options.CentralAirConditioning floorMaterial = options.FloorMaterial wallMaterial = options.WallMaterial &#125; h := &amp;FinishedHouse&#123; style: style, centralAirConditioning: centralAirConditioning, floorMaterial: floorMaterial, wallMaterial: wallMaterial, &#125; return h &#125; func main() &#123; fmt.Printf(\"%+v\\n\", NewFinishedHouse(nil)) // use default options fmt.Printf(\"%+v\\n\", NewFinishedHouse(&amp;Options&#123; Style: 1, CentralAirConditioning: false, FloorMaterial: \"ground-tile\", WallMaterial: \"paper\", &#125;)) &#125; 我们运行一下这个例子： $ go run variadic_function_8.go &amp;&#123;style:0 centralAirConditioning:true floorMaterial:wood wallMaterial:paper&#125; &amp;&#123;style:1 centralAirConditioning:false floorMaterial:ground-tile wallMaterial:paper&#125; 我们看到： 使用这种方法，即便后续添加新配置选项，Options 结构体可以随着时间变迁而增长，但 FinishedHouse 创建函数本身的 API 签名是保持不变的； 这种方法还使得调用者可以使用 nil 来表示他们希望使用默认配置选项来创建 FinishedHouse； 这种方法还带来了额外收获：更好的文档记录（文档重点从对 NewFinishedHouse 函数的大段注释描述转移到了对 Options 结构体各字段的说明）。 当然这种方法也有其不足的地方： 调用者可能会有如此疑问：传递 nil 和传递&amp;Options{}之间有区别吗？ 每次传递 Options 都要将 Options 中的所有字段做正确显式的赋值，即便调用者想使用某个配置项的默认值，赋值动作 1 依然不可少； 调用者还可能有如此疑问：如果传递给 NewFinishedHourse 的 options 中的字段值在函数调用后发生了变化会发生什么情况？ 带着这些疑问，我们进入 NewFinishedHouse 的下一个版本。 3) 版本 3：使用“功能选项”模式 Go 语言之父 Rob Pike 早在 2014 年就在其一篇博文“自引用函数与选项设计”中论述了一种被后人称为“功能选项(functional option)”的模式，这种模式应该是目前进行功能选项设计的最佳实践方案。 接下来我们就来看看使用“功能选项”模式实现的 NewFinishedHouse 是什么样的： // variadic_function_9.go package main import \"fmt\" type FinishedHouse struct &#123; style int // 0: Chinese, 1: American, 2: European centralAirConditioning bool // true or false floorMaterial string // \"ground-tile\" or ”wood\" wallMaterial string // \"latex\" or \"paper\" or \"diatom-mud\" &#125; type Option func(*FinishedHouse) func NewFinishedHouse(options ...Option) *FinishedHouse &#123; h := &amp;FinishedHouse&#123; // default options style: 0, centralAirConditioning: true, floorMaterial: \"wood\", wallMaterial: \"paper\", &#125; for _, option := range options &#123; option(h) &#125; return h &#125; func WithStyle(style int) Option &#123; return func(h *FinishedHouse) &#123; h.style = style &#125; &#125; func WithFloorMaterial(material string) Option &#123; return func(h *FinishedHouse) &#123; h.floorMaterial = material &#125; &#125; func WithWallMaterial(material string) Option &#123; return func(h *FinishedHouse) &#123; h.wallMaterial = material &#125; &#125; func WithCentralAirConditioning(centralAirConditioning bool) Option &#123; return func(h *FinishedHouse) &#123; h.centralAirConditioning = centralAirConditioning &#125; &#125; func main() &#123; fmt.Printf(\"%+v\\n\", NewFinishedHouse()) // use default options fmt.Printf(\"%+v\\n\", NewFinishedHouse(WithStyle(1), WithFloorMaterial(\"ground-tile\"), WithCentralAirConditioning(false))) &#125; 运行一下该新版例子： $ go run variadic_function_9.go &amp;&#123;style:0 centralAirConditioning:true floorMaterial:wood wallMaterial:paper&#125; &amp;&#123;style:1 centralAirConditioning:false floorMaterial:ground-tile wallMaterial:paper&#125; 我们看到在该方案中，FinishedHouse 的配置选项不是通过存储在结构体中的配置参数传入的，而是通过对 FinishedHouse 值本身进行操作的函数调用（利用函数的“一等公民“特质）实现的，并且通过使用变长参数函数，我们可以随意扩展传入的配置选项的个数。 功能选项模式使得我们在设计和实现类似 NewFinishedHouse 这样带有配置选项的函数或方法时可以收获如下好处： 更漂亮的、不随时间变化的公共 API 参数可读性更好 配置选项高度可扩展 提供使用默认选项的最简单方式 使用更安全（不会像版本 2 那样在创建函数被调用后，调用者仍然可以修改 options） 5. 小结 本节要点： 了解变长参数函数的特点和约束； 变长参数函数可以在有限情况下模拟函数重载、可选参数和默认参数，但要谨慎使用，不要造成混淆； 利用变长参数函数实现”功能选项（Functional Options)“模式。 } 21 方法集合决定接口实现 23 定义小接口是 Go 的惯例 扫码加入慕课前沿技术核心用户群 验证信息：2010312025386365复制 QQ讨论群号：729941811 QQ群URL：点击访问 若遇到搜索不到QQ群或加群失败，请联系客服邮箱:kf@imooc.com"},{"title":"留言板","date":"2019-12-25T07:28:57.000Z","updated":"2024-03-12T03:55:12.973Z","comments":true,"path":"messageboard/index.html","permalink":"https://smartxia.github.io/blog/messageboard/index.html","excerpt":"","text":"有什麽想説的？ 有什麽想問的？ 有什麽想吐槽的？ 可以在下面留言..."},{"title":"music","date":"2019-12-19T11:18:41.000Z","updated":"2024-03-12T03:55:12.992Z","comments":false,"path":"music/index.html","permalink":"https://smartxia.github.io/blog/music/index.html","excerpt":"","text":"聆听这个世界 OH MY GIRL"},{"title":"记录这个世界","date":"2019-12-25T07:29:38.000Z","updated":"2024-03-12T03:55:12.992Z","comments":false,"path":"photos/index.html","permalink":"https://smartxia.github.io/blog/photos/index.html","excerpt":"","text":"IMG_0556.jpg67580923_163885094733558_2732488031818814501_n.jpgIMG_0472.jpgIMG_0453.jpgIMG_0931.jpgIMG_0523.jpgIMG_0264.jpgIMG_0337.jpgIMG_0515.jpgIMG_0393.jpgIMG_0501.jpgIMG_0328.jpgIMG_0262.jpgIMG_0338.jpgIMG_0915.jpgIMG_0414.jpgIMG_0911.jpgIMG_0906.jpgIMG_0354.jpgIMG_0251.jpgIMG_0925.jpgIMG_0406.jpgIMG_0908.jpgIMG_0415.jpgIMG_0521.jpgIMG_0910.jpgIMG_0060.jpgIMG_0054.jpgIMG_0491.jpgIMG_0913.jpgIMG_0164.jpgIMG_9924.jpgIMG_0398.jpgIMG_0920.jpgIMG_0409.jpgIMG_0451.jpgIMG_9919.jpgIMG_0052.jpgIMG_0191.JPGIMG_9911.jpgIMG_9909.jpgIMG_0937.jpgIMG_9915.jpgIMG_0159.jpgIMG_9912.jpgIMG_0156.jpgIMG_0043.jpgIMG_0917.jpgIMG_0048.jpgIMG_0916.jpg"},{"title":"sitemap","date":"2019-12-17T09:12:43.000Z","updated":"2024-03-12T03:55:12.994Z","comments":true,"path":"sitemap/index.html","permalink":"https://smartxia.github.io/blog/sitemap/index.html","excerpt":"","text":""},{"title":"schedule","date":"2019-12-17T09:13:54.000Z","updated":"2024-03-12T03:55:12.992Z","comments":true,"path":"schedule/index.html","permalink":"https://smartxia.github.io/blog/schedule/index.html","excerpt":"","text":"http://help.bj.cn/这个网站用于生成站点地图"},{"title":"tags","date":"2019-12-17T08:05:10.000Z","updated":"2024-03-12T03:55:12.994Z","comments":false,"path":"tags/index.html","permalink":"https://smartxia.github.io/blog/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"GOLANG-笔记7-error.group用法","slug":"GOLANG/GOLANG-笔记7-error-group用法","date":"2024-03-26T06:18:21.000Z","updated":"2024-03-26T07:02:26.582Z","comments":true,"path":"2024/03/26/GOLANG/GOLANG-笔记7-error-group用法/","permalink":"https://smartxia.github.io/blog/2024/03/26/GOLANG/GOLANG-%E7%AC%94%E8%AE%B07-error-group%E7%94%A8%E6%B3%95/","excerpt":"","text":"1 .先看下数据结构12345678910type Group struct &#123; cancel func() wg sync.WaitGroup sem chan token errOnce sync.Once err error&#125; 2.在并发编程里 sync.WaitGroup并发原语的使用频率非常高，它经常用于协同等待的场景 gorouting 都完成后才能继续执行。 如果在woker goroutine的执行过程中遇到错误并想要处理该怎么办？ WaitGroup并没有提供传播错误的功能，遇到这种场景我们该怎么办？Go语言在扩展库提供了ErrorGroup并发原语正好适合在这种场景下使用，它在WaitGroup的基础上还提供了，错误传播以及上下文取消的功能。 扩展库通过errorgroup.Group提供ErrorGroup原语的功能，它有三个方法可调用 123func WithContext(ctx context.Context) (*Group, context.Context)func (g *Group) Go(f func() error)func (g *Group) Wait() error 1//ErrorGroup有一个特点是会返回所以执行任务的goroutine遇到的第一个错误 3.想让程序遇到错误就终止其他子任务最早执行遇到错误的goroutine输出了Error: 98但是所有未执行完的其他任务并没有停止执行，那么想让程序遇到错误就终止其他子任务该怎么办呢？我们可以用errgroup.Group提供的WithContext方法创建一个带可取消上下文功能的ErrorGroup。 1234567891011121314151617181920212223242526272829303132/**使用errorgroup.Group时注意它的两个特点：- errgroup.Group在出现错误或者等待结束后都会调用 Context对象 的 cancel 方法同步取消信号。- 只有第一个出现的错误才会被返回，剩余的错误都会被直接抛弃。*/func main() &#123; eg, ctx := errgroup.WithContext(context.Background()) for i := 0; i &lt; 100; i++ &#123; i := i eg.Go(func() error &#123; time.Sleep(2 * time.Second) select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;Canceled:&quot;, i) return nil default: if i &gt; 90 &#123; fmt.Println(&quot;Error:&quot;, i) return fmt.Errorf(&quot;Error: %d&quot;, i) &#125; fmt.Println(&quot;End:&quot;, i) return nil &#125; &#125;) &#125; if err := eg.Wait(); err != nil &#123; log.Fatal(err) &#125;&#125; 4.cancle到其他的子任务在上面的例子中，子goroutine出现错误后，会cancle到其他的子任务，但是我们并没有看到调用ctx的cancel方法，下面我们看下源码，看看内部是怎么处理的。 errgroup 的设计非常精练，全部代码如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package errgroupimport ( &quot;context&quot; &quot;sync&quot;)// A Group is a collection of goroutines working on subtasks that are part of// the same overall task.//// A zero Group is valid and does not cancel on error.type Group struct &#123; cancel func() wg sync.WaitGroup errOnce sync.Once err error&#125;// WithContext returns a new Group and an associated Context derived from ctx.//// The derived Context is canceled the first time a function passed to Go// returns a non-nil error or the first time Wait returns, whichever occurs// first.func WithContext(ctx context.Context) (*Group, context.Context) &#123; ctx, cancel := context.WithCancel(ctx) return &amp;Group&#123;cancel: cancel&#125;, ctx&#125;// Wait blocks until all function calls from the Go method have returned, then// returns the first non-nil error (if any) from them.func (g *Group) Wait() error &#123; g.wg.Wait() if g.cancel != nil &#123; g.cancel() &#125; return g.err&#125;// Go calls the given function in a new goroutine.//// The first call to return a non-nil error cancels the group; its error will be// returned by Wait.func (g *Group) Go(f func() error) &#123; g.wg.Add(1) go func() &#123; defer g.wg.Done() if err := f(); err != nil &#123; g.errOnce.Do(func() &#123; g.err = err if g.cancel != nil &#123; g.cancel() &#125; &#125;) &#125; &#125;()&#125; 可以看到，errgroup 的实现依靠于结构体 Group，它通过封装 sync.WaitGroup，继承了 WaitGroup 的特性，在 Go() 方法中新起一个子任务 goroutine，并在 Wait() 方法中通过 sync.WaitGroup 的 Wait 进行阻塞等待。 同时 Group 利用 sync.Once 保证了它有且仅会保留第一个子 goroutine 错误。 Group 通过嵌入 context.WithCancel 方法产生的 cancel 函数（对于 Context 不熟悉的读者，推荐阅读 理解Context机制 一文），能够在子 goroutine 发生错误时，及时通过调用 cancle 函数，将 Context 的取消信号及时传播出去。 5.总结:使用errorgroup.Group时注意它的特点： 继承了 WaitGroup 的功能 errgroup.Group在出现错误或者等待结束后都会调用Context对象 的 cancel 方法同步取消信号。 只有第一个出现的错误才会被返回，剩余的错误都会被直接抛弃。 context 信号传播：如果子任务 goroutine 中有循环逻辑，则可以添加 ctx.Done 逻辑，此时通过 context 的取消信号，提前结束子任务执行。 .","categories":[{"name":"GOLANG","slug":"GOLANG","permalink":"https://smartxia.github.io/blog/categories/GOLANG/"}],"tags":[{"name":"error.group","slug":"error-group","permalink":"https://smartxia.github.io/blog/tags/error-group/"}]},{"title":"k8s-kubeadmin安装","slug":"K8s/k8s-kubeadmin安装","date":"2024-03-18T03:30:15.000Z","updated":"2024-03-18T06:05:58.361Z","comments":true,"path":"2024/03/18/K8s/k8s-kubeadmin安装/","permalink":"https://smartxia.github.io/blog/2024/03/18/K8s/k8s-kubeadmin%E5%AE%89%E8%A3%85/","excerpt":"","text":"通过kubeadm工具，部署k8s集群。操作步骤如下： 准备工作： 配置yum源，repo(防被墙) 安装常用工具，同步时间 关闭防火墙，将SELinux配置为Permissive模式，关闭swap 加载ipvs模块，优化内核 在所有机器上安装docker 在所有机器上安装kubeadm, kubelet, kubectl 部署集群Master节点 部署集群工作节点 安装CNI网络插件 一个Kubernetes集群Master节点。k8s官网现在将master节点称为control plane node(控制平面节点) 一个Kubernetes集群Slave节点。k8s官网叫worker node(工作节点)。下文中Slave节点和工作节点含义含义相同。 hostname ip 备注 master master.k8s 192.168.246.133 k8s主节点(control plane node) slave slave.k8s 192.168.246.132 k8s 工作节点(worker node) 0. 系统要求安装之前，请确保操作系统满足如下要求： Linux内核操作系统，如CentOS，Ubuntu等 至少2 CPU， 2GB 集群中所有机器之间的网络必须是通的(公共或私有网络都可以)。 每个节点都有唯一的主机名、MAC地址和product_uuid 部署时要保证能连外网 12345678910## 查看操作系统cat /proc/versionhostnamectl## 查看IP和MAC命令ip linkifconfig -a## 查看product_uuidsudo cat /sys/class/dmi/id/product_uuid 1. 准备工作在所有节点上运行 1.1 配置yum源，repo由于众所周知的原因，为防止在安装时出现资源下载失败的问题，在所有节点上配置yum源，repo。shell如下 1234567891011121314151617# yum源curl -o /etc/yum.repos.d/Centos-7.repo http://mirrors.aliyun.com/repo/Centos-7.repo# docker repocurl -o /etc/yum.repos.d/docker-ce.repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# kubernetes repocat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=0repo_gpgcheck=0gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF# 缓存yum clean all &amp;&amp; yum makecache 1.2 安装常用的工具，同步时间123456yum -y install tree vim wget bash-completion bash-completion-extras lrzsz net-tools sysstat iotop iftop htop unzip nc nmap telnet bc psmisc httpd-tools ntpdate# 时区修改,如果/etc/localtime有软连接,不是Shanghai,可以直接删除,在软链接ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtimentpdate ntp2.aliyun.com # 同步阿里云服务器上的时间./sbin/hwclock --systohc # 写入到bios系统 1.3 检查防火墙是否关闭，将SELinux配置为Permissive模式，关闭swap123456789101112131415161718## 查看防火墙状态sudo firewall-cmd --state## 如果防火墙是running，关闭防火墙sudo systemctl disable firewalld &amp;&amp; systemctl stop firewalld## Set SELinux to permissive mode.将SELinux配置为Permissive模式sudo setenforce 0sudo sed -i &#x27;s/^SELINUX=enforcing$/SELINUX=permissive/&#x27; /etc/selinux/config## 也可以直接关闭SELinux #sudo setenforce 0#sudo sed -ri &#x27;s#(SELINUX=).*#\\1disabled#&#x27; /etc/selinux/config# 临时关闭swap。如果不关闭，kubelet会启动失败sudo swapoff -a# 永久防止开机自动挂载swapsudo sed -i &#x27;/ swap / s/^\\(.*\\)$/#\\1/g&#x27; /etc/fstab 1.4 加载ipvs模块，优化内核如下参数不修改，会导致kubeadm init运行失败。 123456789101112131415161718192021222324252627# 加载ipvs模块modprobe br_netfiltermodprobe -- ip_vsmodprobe -- ip_vs_shmodprobe -- ip_vs_rrmodprobe -- ip_vs_wrrmodprobe -- nf_conntrack_ipv4# 验证ip_vs模块lsmod |grep ip_vsip_vs_wrr 12697 0 ip_vs_rr 12600 0 ip_vs_sh 12688 0 ip_vs 145458 6 ip_vs_rr,ip_vs_sh,ip_vs_wrrnf_conntrack 139264 2 ip_vs,nf_conntrack_ipv4libcrc32c 12644 3 xfs,ip_vs,nf_conntrack# 内核文件 cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_forward=1vm.max_map_count=262144EOF# 生效并验证内核优化sysctl -p /etc/sysctl.d/k8s.conf 2. 安装docker在所有节点上运行 2.1 安装启动docker注意：安装docker需要root权限。 123456789101112131415161718## 1. yum 安装## 运行sudo yum install docker-ce 也是可以的，docker-ce依赖了docker-ce-cli, containerd.io, docker-buildx-plugin, docker-compose-plugin。这些依赖会同步installyum install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin## 2. 配置dockercat &lt;&lt;EOF &gt; /etc/docker/daemon.json&#123; &quot;registry-mirrors&quot;: [ &quot;https://registry.hub.docker.com&quot;, &quot;http://hub-mirror.c.163.com&quot;, &quot;https://docker.mirrors.ustc.edu.cn&quot;, &quot;https://registry.docker-cn.com&quot; ]&#125; EOF ## 3. 启动dockersystemctl start docker 验证是否安装正确 123456789101112131415161718192021222324## 4. docker运行正常[shirley@master k8s_install]$ systemctl status docker● docker.service - Docker Application Container Engine Loaded: loaded (/usr/lib/systemd/system/docker.service; disabled; vendor preset: disabled) Active: active (running) since Tue 2023-10-10 09:23:41 CST; 19s ago Docs: https://docs.docker.com Main PID: 16381 (dockerd) Tasks: 8 Memory: 27.4M CGroup: /system.slice/docker.service └─16381 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/con...[shirley@master k8s_install]$## 运行docker命令，验证镜像下载正常，容器运行正常[shirley@slave k8s_install]$ sudo docker run hello-worldUnable to find image &#x27;hello-world:latest&#x27; locallylatest: Pulling from library/hello-world719385e32844: Pull completeDigest: sha256:4f53e2564790c8e7856ec08e384732aa38dc43c52f02952483e3f003afbf23dbStatus: Downloaded newer image for hello-world:latestHello from Docker!This message shows that your installation appears to be working correctly.... ... 2.2 配置containerd中pause镜像地址为了防止安装过程中出现pause镜像下载失败的问题，建议运行containerd config dump &gt; /etc/containerd/config.toml 命令，将当前配置导出到文件，并修改sandbox_image配置。 12345678910111213## 如果没有/etc/containerd/config.toml文件，将默认配置导出到/etc/containerd/config.toml。containerd config default &gt; /etc/containerd/config.toml## 修改配置文件/etc/containerd/config.toml， 更改sandbox_image配置[plugins] [plugins.&quot;io.containerd.grpc.v1.cri&quot;] sandbox_image = &quot;registry.aliyuncs.com/google_containers/pause:3.9&quot;## PS: 如果生成的/etc/containerd/config.toml中没有如上配置项，可以运行如下命令导出当前所有配置项后再修改文件/etc/containerd/config.toml# containerd config dump &gt; /etc/containerd/config.toml## 重启containerdsystemctl restart containerd 3. 部署kubeadm, kubelet, kubectlkubeadm：启动k8s集群的工具 kubelet: 该组件在集群中的所有机器上运行，并执行启动pod和容器之类的任务。 kubectl: 与集群通信的工具。可以只在master节点上安装。 1234sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes## 开机启动kubeletsudo systemctl enable --now kubelet 验证 123# 查看kubeadm版本[root@master ~]# sudo kubeadm versionkubeadm version: &amp;version.Info&#123;Major:&quot;1&quot;, Minor:&quot;28&quot;, GitVersion:&quot;v1.28.2&quot;, GitCommit:&quot;89a4ea3e1e4ddd7f7572286090359983e0387b2f&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2023-09-13T09:34:32Z&quot;, GoVersion:&quot;go1.20.8&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;&#125; 4. 初始化Master节点（kubeadm init）在Master节点运行 4.1. 更改配置文件kubeadm init命令用于初始化master节点。kubeadm init 的参数可以通过命令行或yaml文件进行配置。本文介绍如何通过yaml文件进行配置。可以通过kubeadm config print init-defaults命令得到一份默认配置，然后对其进行修改。 1kubeadm config print init-defaults &gt; kubeadm.yaml 对kubeadm.yaml进行编辑，修改内容如下： 修改advertiseAddress为master IP地址 imageRepository修改为registry.aliyuncs.com/google_containers，防止镜像拉不下来 建议将networking.podSubnet修改为10.244.0.0/16， 和后续安装的flannel CNI 插件的默认配置保持一致。 12345678910111213141516171819202122232425262728293031323334353637apiVersion: kubeadm.k8s.io/v1beta3bootstrapTokens:- groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authenticationkind: InitConfigurationlocalAPIEndpoint: advertiseAddress: 192.168.246.133 ## change the IP of apiserver. bindPort: 6443nodeRegistration: criSocket: unix:///var/run/containerd/containerd.sock imagePullPolicy: IfNotPresent name: node taints: null---apiServer: timeoutForControlPlane: 4m0sapiVersion: kubeadm.k8s.io/v1beta3certificatesDir: /etc/kubernetes/pkiclusterName: kubernetescontrollerManager: &#123;&#125;dns: &#123;&#125;etcd: local: dataDir: /var/lib/etcdimageRepository: registry.aliyuncs.com/google_containers ## change imageRepository to aliyun.kind: ClusterConfigurationkubernetesVersion: 1.28.0networking: dnsDomain: cluster.local podSubnet: 10.244.0.0/16 ## add this line to config POD network. Same with CNI config. serviceSubnet: 10.96.0.0/12scheduler: &#123;&#125; 如上配置文件等价于命令行： 123456kubeadm init \\ --apiserver-advertise-address=192.168.246.133 \\ --image-repository registry.aliyuncs.com/google_containers \\ --kubernetes-version v1.28.0 \\ --service-cidr=10.96.0.0/12 \\ --pod-network-cidr=10.244.0.0/16 –apiserver-advertise-address 集群通告地址 –image-repository 由于默认拉取镜像地址http://k8s.gcr.io国内无法访问，这里指定阿里云镜像仓库地址 –kubernetes-version K8s版本，与上面安装的一致 –service-cidr 集群内部虚拟网络，Pod统一访问入口 –pod-network-cidr Pod网络，与下面部署的CNI网络组件yaml中保持一致 4.2 提前pull镜像（可选）为了使后续安装更快，建议先把安装需要的镜像pull下来。 12345678910111213141516171819202122232425## 验证配置文件格式是否正确[shirley@master k8s_install]$ kubeadm config validate --config kubeadm.yamlok## 查看需要下载哪些镜像。需要关注下载的repository地址是否正确。## 如上在kubeadm.yaml文件配置了imageRepository：registry.aliyuncs.com/google_containers，因此images会从aliyun的repo下载。[shirley@master k8s_install]$ kubeadm config images list --config kubeadm.yamlregistry.aliyuncs.com/google_containers/kube-apiserver:v1.28.0registry.aliyuncs.com/google_containers/kube-controller-manager:v1.28.0registry.aliyuncs.com/google_containers/kube-scheduler:v1.28.0registry.aliyuncs.com/google_containers/kube-proxy:v1.28.0registry.aliyuncs.com/google_containers/pause:3.9registry.aliyuncs.com/google_containers/etcd:3.5.9-0registry.aliyuncs.com/google_containers/coredns:v1.10.1 ## pull镜像。pull镜像有点慢，第一个镜像pull成功后才有日志输出。命令运行后发现没有日志不要着急，多等一会。[shirley@master k8s_install]$ sudo kubeadm config images pull --config kubeadm.yaml[config/images] Pulled registry.aliyuncs.com/google_containers/kube-apiserver:v1.28.0[config/images] Pulled registry.aliyuncs.com/google_containers/kube-controller-manager:v1.28.0[config/images] Pulled registry.aliyuncs.com/google_containers/kube-scheduler:v1.28.0[config/images] Pulled registry.aliyuncs.com/google_containers/kube-proxy:v1.28.0[config/images] Pulled registry.aliyuncs.com/google_containers/pause:3.9[config/images] Pulled registry.aliyuncs.com/google_containers/etcd:3.5.9-0[config/images] Pulled registry.aliyuncs.com/google_containers/coredns:v1.10.1 4.3 kubeadm init初始化运行kubeadm init --config kubeadm.yaml， 当看到Your Kubernetes control-plane has initialized successfully!时表示安装成功。 12345678910111213141516171819202122[root@master k8s_install]# kubeadm init --config kubeadm.yaml... ...Your Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configAlternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.confYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:kubeadm join 192.168.246.133:6443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:9f7d37c768e658119242dfb49675eaeb3cbdbb7d191526bfa197dd92373b40ab PS：最好将最后一行log需要记下来，worker节点安装会用到。 根据提示，退出root账户后运行命令 123mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config 4.4 验证验证master节点是否部署成功。 12345678910111213## kubectl 运行正常. STATUS=NotReady是因为CNI插件还没装。[shirley@master k8s_install]$ kubectl get nodeNAME STATUS ROLES AGE VERSIONnode NotReady control-plane 20m v1.28.2## 通过crictl命令可以查看到运行的container[shirley@master k8s_install]$ sudo crictl ps -aCONTAINER IMAGE CREATED STATE NAME ATTEMPT POD ID POD955b0c87ad621 ea1030da44aa1 26 minutes ago Running kube-proxy 0 78efbee65dfac kube-proxy-kp9kwf69d8c3246904 73deb9a3f7025 26 minutes ago Running etcd 0 77180bc7ff0a8 etcd-node3efba65f263d3 f6f496300a2ae 26 minutes ago Running kube-scheduler 0 f89fb4bb60e2e kube-scheduler-node5dfb28390f30b 4be79c38a4bab 26 minutes ago Running kube-controller-manager 0 b716cb4652e1c kube-controller-manager-nodeb8cfce31fa842 bb5e0dde9054c 26 minutes ago Running kube-apiserver 0 006db1ce43cfe kube-apiserver-node 这里有大家可能有个疑惑，为什么docker ps看不到运行的容器 123## 运行docker命令，发现没有container[shirley@master k8s_install]$ sudo docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 这是因为kubernetes使用的containerd作为容器运行时，而不是Docker engine. kubernetes支持4中容器运行时： Runtime Path to Unix domain socket（CRI socket） containerd unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;containerd&#x2F;containerd.sock CRI-O unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;crio&#x2F;crio.sock Docker Engine (using cri-dockerd) unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;cri-dockerd.sock Mirantis Container Runtime (MCR)(using cri-dockerd) unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;cri-dockerd.sock By default, Kubernetes uses the Container Runtime Interface (CRI) to interface with your chosen container runtime. 默认情况下，kubernetes会用CRI找到选择的容器运行时。在我们安装docker时，安装了containerd，因此k8s找到了containerd作为容器运行时。在kubeadm.yam文件中也能看到相应的配置 12nodeRegistration: criSocket: unix:///var/run/containerd/containerd.sock 为什么k8s不选用docker engine作为容器运行时？因为如果使用docker engine, 还需要安装cri-dockerd，才能作为容器时被k8s识别。而如上操作并未安装。 此外，k8s推荐直接使用containerd作为容器运行时。 5. 初始化工作节点5.1 运行kubeadm join将工作节点加入集群在master节点kubeadm init安装完成后，会有如下类似log 12345.. ... Then you can join any number of worker nodes by running the following on each as root:kubeadm join 192.168.246.133:6443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:9f7d37c768e658119242dfb49675eaeb3cbdbb7d191526bfa197dd92373b40ab 将上述命令粘贴到工作节点，将工作节点添加到集群 1234567891011121314151617[root@slave ~]# kubeadm join 192.168.246.133:6443 --token abcdef.0123456789abcdef \\&gt; --discovery-token-ca-cert-hash sha256:9f7d37c768e658119242dfb49675eaeb3cbdbb7d191526bfa197dd92373b40ab[preflight] Running pre-flight checks [WARNING Hostname]: hostname &quot;slave.k8s&quot; could not be reached [WARNING Hostname]: hostname &quot;slave.k8s&quot;: lookup slave.k8s on 192.168.246.2:53: no such host[preflight] Reading configuration from the cluster...[preflight] FYI: You can look at this config file with &#x27;kubectl -n kube-system get cm kubeadm-config -o yaml&#x27;[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;[kubelet-start] Starting the kubelet[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...This node has joined the cluster:* Certificate signing request was sent to apiserver and a response was received.* The Kubelet was informed of the new secure connection details.Run &#x27;kubectl get nodes&#x27; on the control-plane to see this node join the cluster. 5.2 验证到master节点运行kubelet get node,可以看到加进来的node 1234[shirley@master k8s_install]$ kubectl get nodesNAME STATUS ROLES AGE VERSIONnode NotReady control-plane 121m v1.28.2slave.k8s NotReady &lt;none&gt; 28s v1.28.2 当前STATUS都是NotReady，这是因为还没有安装网络插件CNI 5.3 忘记token怎么办如果master节点安装时，没有记录下token，或token超时(默认24小时)，可以运行如下命令重新生成 12[shirley@master k8s_install]$ kubeadm token create --print-join-commandkubeadm join 192.168.246.133:6443 --token by8q23.65btteq9iud7ypso --discovery-token-ca-cert-hash sha256:9f7d37c768e658119242dfb49675eaeb3cbdbb7d191526bfa197dd92373b40ab 6. 安装CNI网络插件Kubernetes 它需要网络插件来提供集群内部和集群外部的网络通信。以下是一些常用的 k8s 网络插件： Flannel：Flannel 是最常用的 k8s 网络插件之一，它使用了虚拟网络技术来实现容器之间的通信，支持多种网络后端，如 VXLAN、UDP 和 Host-GW。 Calico：Calico 是一种基于 BGP 的网络插件，它使用路由表来路由容器之间的流量，支持多种网络拓扑结构，并提供了安全性和网络策略功能。 Canal：Canal 是一个组合了 Flannel 和 Calico 的网络插件，它使用 Flannel 来提供容器之间的通信，同时使用 Calico 来提供网络策略和安全性功能。 Weave Net：Weave Net 是一种轻量级的网络插件，它使用虚拟网络技术来为容器提供 IP 地址，并支持多种网络后端，如 VXLAN、UDP 和 TCP&#x2F;IP，同时还提供了网络策略和安全性功能。 Cilium：Cilium 是一种基于 eBPF (Extended Berkeley Packet Filter) 技术的网络插件，它使用 Linux 内核的动态插件来提供网络功能，如路由、负载均衡、安全性和网络策略等。 Contiv：Contiv 是一种基于 SDN 技术的网络插件，它提供了多种网络功能，如虚拟网络、网络隔离、负载均衡和安全策略等。 Antrea：Antrea 是一种基于 OVS (Open vSwitch) 技术的网络插件，它提供了容器之间的通信、网络策略和安全性等功能，还支持多种网络拓扑结构。 提供商 网络模型 路线分发 网络策略 网格 外部数据存储 加密 Ingress&#x2F;Egress 策略 Canal 封装 (VXLAN) 否 是 否 K8s API 是 是 Flannel 封装 (VXLAN) 否 否 否 K8s API 是 否 Calico 封装（VXLAN，IPIP）或未封装 是 是 是 Etcd 和 K8s API 是 是 Weave 封装 是 是 是 否 是 是 Cilium 封装 (VXLAN) 是 是 是 Etcd 和 K8s API 是 是 Calico 和 Flannel都是常用的CNI，如下介绍如何安装flannel网络插件 6.1 安装flannel网络插件 下载kube-flannel.yml 12## 1. 下载kube-flannel.ymlwget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml kube-flannel.yaml文件中，需要注意，net-conf.json里的network要和kubeadm.yaml里配置的networking.podSubnet相同 12345678910... ... net-conf.json: | &#123; ### 这里的network和kubeadm.yaml里配置的networking.podSubnet相同 &quot;Network&quot;: &quot;10.244.0.0/16&quot;, &quot;Backend&quot;: &#123; &quot;Type&quot;: &quot;vxlan&quot; &#125; &#125;... ... 容器部署flannel 1234567[shirley@master k8s_install]$ kubectl apply -f kube-flannel.ymlnamespace/kube-flannel createdclusterrole.rbac.authorization.k8s.io/flannel createdclusterrolebinding.rbac.authorization.k8s.io/flannel createdserviceaccount/flannel createdconfigmap/kube-flannel-cfg createddaemonset.apps/kube-flannel-ds created 6.2 验证CNI安装后，运行kubectl -n kube-system get pod -o wide， 可以看到在master节点和slave节点分别运行了一个kube-proxy 123456789101112131415161718## 每个节点上都运行了kube-proxy[shirley@master k8s_install]$ kubectl -n kube-system get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEScoredns-66f779496c-d8rws 1/1 Running 0 4h40m 10.244.0.3 node &lt;none&gt; &lt;none&gt;coredns-66f779496c-fzmjm 1/1 Running 0 4h40m 10.244.0.2 node &lt;none&gt; &lt;none&gt;etcd-node 1/1 Running 0 4h41m 192.168.246.133 node &lt;none&gt; &lt;none&gt;kube-apiserver-node 1/1 Running 0 4h41m 192.168.246.133 node &lt;none&gt; &lt;none&gt;kube-controller-manager-node 1/1 Running 0 4h41m 192.168.246.133 node &lt;none&gt; &lt;none&gt;kube-proxy-bpv8d 1/1 Running 0 160m 192.168.246.132 slave.k8s &lt;none&gt; &lt;none&gt;kube-proxy-kp9kw 1/1 Running 0 4h40m 192.168.246.133 node &lt;none&gt; &lt;none&gt;kube-scheduler-node 1/1 Running 0 4h41m 192.168.246.133 node &lt;none&gt; &lt;none&gt;## node状态显示为Ready[shirley@master k8s_install]$ kubectl get nodeNAME STATUS ROLES AGE VERSIONnode Ready control-plane 4h38m v1.28.2slave.k8s Ready &lt;none&gt; 158m v1.28.2 自此，集群搭建完成。 其他说明另外，在初始安装的Master节点上也启动了kubelet和kube-proxy，在默认情况下并不参与工作负载的调度。如果希望Master节点也作为Node角色，则可以运行下面的命令（删除Master节点的：node-role.kubernetes.io/control-plane:NoSchedule），让Master节点也成为一个Node： 1kubectl taint nodes --all node-role.kubernetes.io/control-plane-","categories":[{"name":"K8S","slug":"K8S","permalink":"https://smartxia.github.io/blog/categories/K8S/"}],"tags":[{"name":"K8S","slug":"K8S","permalink":"https://smartxia.github.io/blog/tags/K8S/"}]},{"title":"K8s-IPVS概念原理以及应用","slug":"K8s/K8s-IPVS概念原理以及应用","date":"2024-03-18T03:24:31.000Z","updated":"2024-03-18T06:05:22.047Z","comments":true,"path":"2024/03/18/K8s/K8s-IPVS概念原理以及应用/","permalink":"https://smartxia.github.io/blog/2024/03/18/K8s/K8s-IPVS%E6%A6%82%E5%BF%B5%E5%8E%9F%E7%90%86%E4%BB%A5%E5%8F%8A%E5%BA%94%E7%94%A8/","excerpt":"","text":"IPVS的概念、原理及应用一、什么是IPVSLVS（Linux 虚拟服务器）和 IPVS（IP 虚拟服务器）是 Linux 中用于构建可扩展和高性能网络服务的两种相关技术。 LVS 是 Linux 系统的内核级负载均衡解决方案。 它允许您在多个服务器之间分配传入的网络流量，创建一个服务器集群，在客户端看来就像一个虚拟服务器。 LVS 中的负载均衡算法可以根据各种因素（例如循环法、最少连接数和源 IP 哈希）来分配流量。 二、IPVS的工作原理IPVS的工作原理基于网络地址转换（Network Address Translation，NAT）和端口转换（Port Translation）。 当一个网络请求到达IPVS，IPVS会根据预设的调度算法选择一个后端服务器，然后修改网络请求的目标IP地址和端口，使其指向选择的后端服务器。 当后端服务器处理完请求后，IPVS会将服务器的响应转发回原始请求的客户端。 在这个过程中，客户端并不知道实际上是哪个后端服务器处理了它的请求。 三、IPVS的主要特性丰富的调度算法：IPVS支持多种调度算法，包括最小连接（Least-Connection）、轮询（Round-Robin）和加权轮询（Weighted Round-Robin）等，满足不同应用场景的需求。健康检查：IPVS能够定期对后端服务器进行健康检查，当检测到某个服务器故障时，可以将其从服务列表中移除，防止向故障服务器发送请求。高性能：由于IPVS是Linux内核的一部分，因此处理网络请求的效率非常高。IPVS支持大规模并发连接，能够处理每秒数以万计的网络请求。易于集成：IPVS可以与其他Linux内核模块和用户空间工具一起使用，如iptables和keepalived等，提供更加强大和灵活的网络服务。 四、IPVS的应用场景IPVS广泛应用于大规模的互联网服务，如网站、在线视频和游戏等，提供高可用性和高性能的网络服务。 此外，IPVS也在云计算、大数据和容器技术等领域有广泛的应用，例如在Kubernetes中，IPVS作为服务代理的一种模式，为集群内的服务提供负载均衡。 综上所述，LVS 是 Linux 系统的综合负载均衡解决方案，而 IPVS 是 LVS 中专门处理 IP 负载均衡的组件。 LVS 利用 IPVS 在多个真实服务器之间分发流量，并为各种网络服务提供可扩展性和容错性","categories":[{"name":"K8S","slug":"K8S","permalink":"https://smartxia.github.io/blog/categories/K8S/"}],"tags":[{"name":"K8S","slug":"K8S","permalink":"https://smartxia.github.io/blog/tags/K8S/"}]},{"title":"PHP-析构函数-destruct","slug":"PHP/PHP-析构函数-destruct","date":"2024-03-12T03:55:12.845Z","updated":"2024-03-12T03:55:12.845Z","comments":true,"path":"2024/03/12/PHP/PHP-析构函数-destruct/","permalink":"https://smartxia.github.io/blog/2024/03/12/PHP/PHP-%E6%9E%90%E6%9E%84%E5%87%BD%E6%95%B0-destruct/","excerpt":"","text":"phpStrom 里alt+insert 会出现的一些函数 析构函数destruct 简单理解：构造函数的对立面构造函数：__construct()在初始化对象的时候默认执行的析构函数：__destruct()在对象销毁回收时候默认执行的，类似于web框架里面的钩子函数 触发条件 当对象或者变量 消失时候 关键词：unset或者对象生命周期结束 phpStrom 里alt+insert 会出现的一些函数 1234567891011121314151617181920212223242526calss A&#123; protected $data = [];public function insert($data) &#123; $data[&#x27;appkey&#x27;] = getAppkey(); $data[&#x27;channel&#x27;] = getChannel(); $this-&gt;data[] = $data; //这个[]意思在多个多次调用的时候插入整个数组很关键，可以看下面内容 请求中 php 如何分配phpfpm &#125; public function __destruct() &#123; if ($this-&gt;data) &#123; $this-&gt;getDB()-&gt;insert_batch($this-&gt;table, $this-&gt;data); $id = $this-&gt;getDB()-&gt;insert_id(); Ioc()-&gt;CallRecordModel-&gt;_delete([ &#x27;id &lt;&#x27; =&gt; $id - 50000 ], &#x27;&#x27;, 1000); &#125; &#125;&#125;$zend=new A();$zend-&gt;insert([&quot;aaaaa&quot;]);","categories":[{"name":"PHP","slug":"PHP","permalink":"https://smartxia.github.io/blog/categories/PHP/"}],"tags":[{"name":"php","slug":"php","permalink":"https://smartxia.github.io/blog/tags/php/"}]},{"title":"GOLANG-笔记-ArrayMapSlice","slug":"GOLANG/GOLANG-笔记3-nil-slice-map","date":"2024-03-12T03:55:12.820Z","updated":"2024-03-12T03:55:12.820Z","comments":true,"path":"2024/03/12/GOLANG/GOLANG-笔记3-nil-slice-map/","permalink":"https://smartxia.github.io/blog/2024/03/12/GOLANG/GOLANG-%E7%AC%94%E8%AE%B03-nil-slice-map/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253### 1. := = ==:= 给某变量的第一次赋值，初始化= 变量的非第一次赋值== 等于操作符### 2. go中nil的使用指针、切片、映射、通道、函数和接口的零值则是 nil。- nil 标识符是不能比较的- nil 不是关键字或保留字- nil 没有默认类型- 不同类型 nil 的指针是一样的- 不同类型的 nil 是不能比较的- 两个相同类型的 nil 值也可能无法比较- nil 是 map、slice、pointer、channel、func、interface 的零值- 不同类型的 nil 值占用的内存大小可能是不一样的### 3.切片 slice类似于py或Java的list ,是数组的抽象,支持数组扩容 定义:slice1 := make([]type, len)len 获取长度 cap 获取容量 append(slice1 ,v1,...) copy(new_slice,slice1)### 4.集合 mapmap 无序k-v ,快速根据k 找到v,类似于索引,在做循环打印的时候，无法固定返回顺序，因为map 用hash表来实现的- 声明变量，默认 map 是 nil var map_val map[key_data_type]value_data_type- 使用 make 函数 map_val := make(map[key_data_type]value_data_type)### 并发goroutine go sync()### 通道 channel既然已经有了线程的概念，那么就会存在线程间的同步和通讯问题，Go 使用通道（channel）来实现。通道可用于两个 goroutine 之间通过传递一个指定类型的值来同步运行和通讯。使用操作符 &lt;-，符号左边是接收者，右边是发送者。使用 make 创建 channel，如下：​```ch := make(chan int, 100) // make 第二个参数 100 是该通道的缓冲区，是一个可选参数，如果不指定，那么就是无缓冲的通道ch &lt;- v // 把 v 发送到通道 chv := &lt;-ch // 从 ch 接收数据// 并把值赋给 v​```通道与消息队列是等效的，如果通道缓冲区满，那么再往通道里塞数据，就会阻塞该 goroutine；同样，如果通道缓冲区没有数据了，再次接收通道数据，也会阻塞该 goroutine。","categories":[{"name":"GOLANG","slug":"GOLANG","permalink":"https://smartxia.github.io/blog/categories/GOLANG/"}],"tags":[{"name":"Slice","slug":"Slice","permalink":"https://smartxia.github.io/blog/tags/Slice/"}]},{"title":"darp Docs","slug":"darp-Docs","date":"2022-03-16T06:59:18.000Z","updated":"2024-03-12T03:55:12.897Z","comments":true,"path":"2022/03/16/darp-Docs/","permalink":"https://smartxia.github.io/blog/2022/03/16/darp-Docs/","excerpt":"","text":"dapr 文档贡献dapr 文档贡献规则：https://docs.dapr.io/zh-hans/contributing/contributing-docs/ dapr 文档网站使用hugo 开发工具： Windows：安装流程安装scoopepowerSheel ：执行命令： 123456789101112set-executionpolicy remotesigned -scope currentuseriex (new-object net.webclient).downloadstring(&#x27;https://get.scoop.sh&#x27;)执行scoope help 查看是否安装正常执行 scoop install hugo scoop install hugo-extended这两部即可 完成对其安装文档：https://gohugo.io/getting-started/installing/ 1.执行doc仓库下载和安装依赖仓库： 1234567891011121314https://github.com.cnpmjs.org/dapr/docs.git执行：git submodule update --init --recursive这步可能遇到下载不下来情况，可以按照此步骤进行操作1.执行 git submodule update --init2.去.gitmodules文件 进行编辑将所有的https://github.com 后缀加上 cnpmjs.org(这个原理可以参考:谷歌插件---GitHub加速1.3.5)3.然后利用git submodule sync更新子项目对应的url4.git submodule update --init --recursive，最后执行//s2-cdn.oneitfarm.com/6d3518411d074f9eae604f77da39da83.png 错误1. 解决方案： 1234使用git代理：git config *--global https.proxy*执行命令后取消代理git config --global --unset https.proxy 错误2： 解决方案： 1这个是因为没有执行git module的 下载 2.安装依赖此项目使用的还是npm 1npm install （很慢）","categories":[{"name":"dapr","slug":"dapr","permalink":"https://smartxia.github.io/blog/categories/dapr/"}],"tags":[]},{"title":"GOLANG-grpc-2","slug":"GOLANG/GOLANG-grpc-2","date":"2021-12-09T07:05:54.000Z","updated":"2024-03-12T03:55:12.807Z","comments":true,"path":"2021/12/09/GOLANG/GOLANG-grpc-2/","permalink":"https://smartxia.github.io/blog/2021/12/09/GOLANG/GOLANG-grpc-2/","excerpt":"","text":"脑图： https://naotu.baidu.com/file/c80e753e20e8ab18a80cb573ac08e912?token=e89e127e95b325d5 服务端的操作： 取出server 挂载方法 注册服务 创建监听 客户端： 创建链接 new 一个client 调用client方法 获取返回值","categories":[],"tags":[]},{"title":"x86和arm架构区别","slug":"建站/x86和arm架构区别","date":"2021-12-02T08:22:44.000Z","updated":"2024-03-12T03:55:12.898Z","comments":true,"path":"2021/12/02/建站/x86和arm架构区别/","permalink":"https://smartxia.github.io/blog/2021/12/02/%E5%BB%BA%E7%AB%99/x86%E5%92%8Carm%E6%9E%B6%E6%9E%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"什么是arm架构ARM架构过去称之为进阶精简指令集机器，是一个32位的精简指令集（RISC）处理器架构，其广泛的使用在嵌入式系统设计，由于节能的特点，ARM非常适合处理移动通讯领域，符合其设计目标低消耗 电量的特性，在今日，ARM家族占了所有32位嵌入式处理器75%的比例，使它成为占全世界最多数的32位架构之一。ARM处理器可以在很多消费性电子产品上看到，从可携式装置（PDA、移动电话、多媒体播放器、掌上型电子游戏，和计算机）到电脑外设（硬盘、桌上型路由器）甚至在导弹的弹载计算机等军用设施中都有他的存在。在此还有一些基于ARM设计的派生产品，重要产品还包括Marvell的XScale架构和德州仪器的OMAP系列. arm架构图 下图所示的是ARM构架图。它由32位ALU、若干个32位通用寄存器以及状态寄存器、32&TImes;8位乘法器、32&TImes;32位桶形移位寄存器、指令译码以及控制逻辑、指令流水线和数据&#x2F;地址寄存器组成. 1、ALU：它有两个操作数锁存器、加法器、逻辑功能、结果以及零检测逻辑构成。 2、桶形移位寄存器：ARM采用了32&TImes;32位的桶形移位寄存器，这样可以使在左移&#x2F;右移n位、环移n位和算术右移n位等都可以一次完成。 3、高速乘法器：乘法器一般采用“加一移位”的方法来实现乘法。ARM为了提高运算速度，则采用两位乘法的方法，根据乘数的2位来实现“加一移位”运算;ARM高速乘法器采用32&TImes;8位的结构，这样，可以降低集成度（其相应芯片面积不到并行乘法器的1&#x2F;3）。 4、浮点部件：浮点部件是作为选件供ARM构架使用。FPA10浮点加速器是作为协处理方式与ARM相连，并通过协处理指令的解释来执行。 5、控制器：ARM的控制器采用的是硬接线的可编程逻辑阵列PLA。 6、寄存器 x86架构 当然，这个架构图并不是所有的都是如此，根据不同的主板，平台，架构是略有差别的比如说，目前很多主板已经将北桥集成到CPU当中，将南桥集成为PCH，但大致的框架还是如此的。下面对这个架构图上的各个内容分别进行一些简介: 1：CPU，大家都不陌生的名词，中央处理器，计算机的核心大脑。 2： 北桥（North Bridge Chipset）：北桥是电脑主板上的一块芯片，位于CPU插座边，起连接作用。 3：南桥芯片（South Bridge）是主板芯片组的重要组成部分，一般位于主板上离CPU插槽较远的下方，PCI插槽的附近，这种布局是考虑到它所连接的I&#x2F;O总线较多，离处理器远一点有利于布线。 4： 内存是计算机中重要的部件之一，它是与CPU进行沟通的桥梁。计算机中所有程序的运行都是在内存中进行的，因此内存的性能对计算机的影响非常大。 5：显卡（Video card，Graphics card）全称显示接口卡，又称显示适配器，是计算机最基本配置、最重要的配件之一。 6：显示j接口 7：网卡是工作在链路层的网络组件，是局域网中连接计算机和传输介质的接口，不仅能实现与局域网传输介质之间的物理连接和电信号匹配，还涉及帧的发送与接收、帧的封装与拆封、介质访问控制、数据的编码与解码以及数据缓存的功能等。 8：声卡的基本功能是把来自话筒、磁带、光盘的原始声音信号加以转换，输出到耳机、扬声器、扩音机、录音机等声响设备，或通过音乐设备数字接口（MIDI）使乐器发出美妙的声音。 9：SATA（Serial Advanced Technology Attachment，串行高级技术附件）是一种基于行业标准的串行硬件驱动器接口，是由Intel、IBM、Dell、APT、Maxtor和Seagate公司共同提出的硬盘接口规范。 10：硬盘是电脑主要的存储媒介之一，由一个或者多个铝制或者玻璃制的碟片组成。碟片外覆盖有铁磁性材料。 11：总线 arm架构和x86架构有什么区别一、性能 ​ X86结构的电脑无论如何都比ARM结构的系统在性能方面要快得多、强得多。X86的CPU随便就是1G以上、双核、四核大行其道，通常使用45nm（甚至更高级）制程的工艺进行生产；而ARM方面：CPU通常是几百兆，最近才出现1G左右的CPU，制程通常使用不到65nm制程的工艺，可以说在性能和生产工艺方面ARM根本不是X86结构系统的对手。 但ARM的优势不在于性能强大而在于效率，ARM采用RISC流水线指令集，在完成综合性工作方面根本就处于劣势，而在一些任务相对固定的应用场合其优势就能发挥得淋漓尽致. 二、扩展能力 ​ X86结构的电脑采用“桥”的方式与扩展设备（如：硬盘、内存等）进行连接，而且x86结构的电脑出现了近30年，其配套扩展的设备种类多、价格也比较便宜，所以x86结构的电脑能很容易进行性能扩展，如增加内存、硬盘等. ARM结构的电脑是通过专用的数据接口使CPU与数据存储设备进行连接，所以ARM的存储、内存等性能扩展难以进行（一般在产品设计时已经定好其内存及数据存储的容量），所以采用ARM结构的系统，一般不考虑扩展。基本奉行“够用就好”的原则. 三、操作系统的兼容性 ​ X86系统由微软及Intel构建的Wintel联盟一统天下，垄断了个人电脑操作系统近30年，形成巨大的用户群，也深深固化了众多用户的使用习惯，同时x86系统在硬件和软件开发方面已经形成统一的标准，几乎所有x86硬件平台都可以直接使用微软的视窗系统及现在流行的几乎所有工具软件，所以x86系统在兼容性方面具有无可比拟的优势。 ARM系统几乎都采用Linux的操作系统，而且几乎所有的硬件系统都要单独构建自己的系统，与其他系统不能兼容，这也导致其应用软件不能方便移植，这一点一直严重制约了ARM系统的发展和应用。GOOGLE开发了开放式的Android系统后，统一了ARM结构电脑的操作系统，使新推出基于ARM结构的电脑系统有了统一的、开放式的、免费的操作系统，为ARM的发展提供了强大的支持和动力. 四、软件开发的方便性及可使用工具的多样性 ​ X86结构的系统推出已经近30年，在此期间，x86电脑经过飞速发展的黄金时期，用户的应用、软件配套、软件开发工具的配套及兼容等工作，已经到达非常成熟甚至可以说是完美的境界。所以使用X86电脑系统不仅有大量的第三方软件可供选择，也有大量的软件编程工具可以帮助您完成您所希望完成的工作。 Arm结构的电脑系统因为硬件性能的制约、操作系统的精简、以及系统兼容等问题的制约，造成Arm结构的电脑系统不可能像X86电脑系统那样有众多的编程工具和第三方软件可供选择及使用，ARM的编程语言大多采用C和JAVA。 对这一点的比较，更直接的结论是：基于x86结构电脑系统平台开发软件比arm结构系统更容易、更简单、实际成本也更低，同时更容易找到第三方软件（免去自己开发的时间和成本），而且软件移植更容易。 从以上对比分析，给了我们的一个很清晰的感觉，ARM和X86结构的电脑根本就无法对比，ARM根本就不是X86电脑的的对手。是的，如果只考虑上述几个方面的要数，ARM确实无法与X86电脑竞争，甚至连比较的资格都没有。但是近1、2年，ARM的产品在终端应用特别是手持终端应用飞速发展（如：智能手机、平板电脑等），其销售数量已经远远超出x86结构的电脑销售数量，可见ARM是具有其与X86结构电脑不可对比的优势。该优势就是：功耗. 五、功耗 X86电脑因考虑要适应各种应用的需求，其发展思路是：性能+速度。20多年来x86电脑的速度从原来8088的几M发展到现在随便就是几G，而且还是几核，其速度和性能已经提升了千、万倍，技术进步使x86电脑成为大众生活中不可缺少的一部分。但是x86电脑发展的方向和模式，使其功耗一直居高不下，一台电脑随便就是几百瓦，即使是号称低功耗节能的手提电脑或上网本，也有十几、二十多瓦的功耗，这与ARM结构的电脑就无法相比.","categories":[],"tags":[]},{"title":"HTTP 请求方法之CONNECT method","slug":"HTTP/HTTP-请求方法之CONNECT-method","date":"2021-11-25T01:36:06.000Z","updated":"2024-03-12T03:55:12.824Z","comments":true,"path":"2021/11/25/HTTP/HTTP-请求方法之CONNECT-method/","permalink":"https://smartxia.github.io/blog/2021/11/25/HTTP/HTTP-%E8%AF%B7%E6%B1%82%E6%96%B9%E6%B3%95%E4%B9%8BCONNECT-method/","excerpt":"","text":"HTTP1.1 中的connect1.http请求代理就是connect这个方法，connect网页开发中不会使用2.connect的作用将服务器作为代理，让服务器提用户访问其他网页（翻墙），之后将数据返回用户3.connect是将通过TCP代理链接服务器的，假如我想让代理服务器访问，https://baidu.com网站，首先要简历一条客户端到代理服务器的tcp的链接然后给代理服务器发送一个http报文 12345CONNECT https://www.jianshu.com/u/f67233ce6c0c:80 HTTP/1.1Host: www.web-tinker.com:80Proxy-Connection: Keep-AliveProxy-Authorization: Basic *Content-Length: 0 在发送完这个请求之后，代理服务器会响应请求，返回一个200的信息，但这个200并不同于我们平时见到的OK，而是Connection Established","categories":[{"name":"HTTP","slug":"HTTP","permalink":"https://smartxia.github.io/blog/categories/HTTP/"}],"tags":[]},{"title":"弱势文化","slug":"我的日记/弱势文化","date":"2021-11-22T05:37:08.000Z","updated":"2024-03-12T03:55:12.916Z","comments":true,"path":"2021/11/22/我的日记/弱势文化/","permalink":"https://smartxia.github.io/blog/2021/11/22/%E6%88%91%E7%9A%84%E6%97%A5%E8%AE%B0/%E5%BC%B1%E5%8A%BF%E6%96%87%E5%8C%96/","excerpt":"","text":"知识的快餐：我们为什么要懂点哲学什么是哲学，哲学可不可以理解成为人的认知的差异，哲学里的文化属性到底代表着什么 闲暇产生思辨，思辨消解教条主义和陈腐习俗，发展出敏锐的感知，让人丧失行动的决断。 思想，在分析迷宫冒险前行，发现社会背后的个体，玻璃其正常的社会功能，转向内在，发现自我 共同的利益，和共同体的意识衰退，如今没有公民只有个人 个体通过思索意识到自己本身就是生存的目的，他要求国际从此以往加强而不是利用他的能力，以此为代价，个人将维持国家的持续 社会经济的发展带来的我们物质和生活的增长，被冠以着数十年来通过个体努力的结果，于是国家造就了弱势文化的典型思想:误以为将自己的生活水平的提高，是通过自己勤劳获取的，殊不知这是吃着国家的红利，而并非自己真的可以通过真正的努力获取的温饱","categories":[{"name":"diary","slug":"diary","permalink":"https://smartxia.github.io/blog/categories/diary/"}],"tags":[]},{"title":"GOLANG-GPM的深入理解","slug":"GOLANG/GOLANG-GPM的深入理解","date":"2021-11-18T02:08:03.000Z","updated":"2024-03-12T03:55:12.806Z","comments":true,"path":"2021/11/18/GOLANG/GOLANG-GPM的深入理解/","permalink":"https://smartxia.github.io/blog/2021/11/18/GOLANG/GOLANG-GPM%E7%9A%84%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/","excerpt":"","text":"深入golang runtime的调度 理解调度器的启动runtime： scheduler: TLS: spinning: systemstack,mcall,asmcgocall 主要源码文件: 调度基本组件： **G(goroutine)**：调度器的基本单位，存储的goroutine的执行stack信息，状态以及任务函数 在g的眼中只有p,p就是运行的G的“CPU” 相当于两级线程 g的任务函数 每个g的实例都有任务函数，如下代码 12userFun:=func()&#123;fmt.Println(&quot;111&quot;)&#125;go userFunc(); go的关键词创建了一个goroutine,此时gouroutine的任务函数userFun P（processor） p表示逻辑processor，代表M执行的上下文 p的最大作用是拥有各种G的对象队列，链表，cache,和状态 p的数量也代表go的执行并发度，即多少个goroutine可以同时执行 这里的p虽然表示逻辑处理器，但是p并不代表任何执行代码，对于g来说，p相当于cpu的核，g只有绑定p才能调度。对于M来说，p提供了执行环境（Context），如分配内存状态（mcache）,任务队列G等 M(machine) M代表真正的执行计算资源，可以任务他就是os thread(系统线程) M是真正的执行者，每个M就像一个勤劳的工作者，总是从各种队列找到可运行的G,而且这样的M的可以同时存在多个 M在绑定有效P，可以进行调度循环，而且M并不保留G状态，这个是g可以跨M调度的基础","categories":[{"name":"GOLANG","slug":"GOLANG","permalink":"https://smartxia.github.io/blog/categories/GOLANG/"}],"tags":[{"name":"golang","slug":"golang","permalink":"https://smartxia.github.io/blog/tags/golang/"}]},{"title":"GOLANG-纯纯的语法仔的没落","slug":"GOLANG/GOLANG-纯纯的语法仔的没落","date":"2021-11-17T03:57:39.000Z","updated":"2024-03-12T03:55:12.821Z","comments":true,"path":"2021/11/17/GOLANG/GOLANG-纯纯的语法仔的没落/","permalink":"https://smartxia.github.io/blog/2021/11/17/GOLANG/GOLANG-%E7%BA%AF%E7%BA%AF%E7%9A%84%E8%AF%AD%E6%B3%95%E4%BB%94%E7%9A%84%E6%B2%A1%E8%90%BD/","excerpt":"","text":"基础1. 对于已经关闭的channel的处理读已经关闭的channel，一直能读到东西，但是读到的东西根据通道内关闭前是否有元素而不同， 关闭前，buffer有还未读取的，会读取到chan内的值，且返回是否读取成功的bool值为true 关闭前，buffer的值读完，channel元素值为0，bool值为false 写入：直接panic 2. Make和new区别make：返回特定类型channel，slice,map new: 开辟新内存和指针，泛化类型 3. nil 切片和空切片一不一样指向的地址不一样。nill引用指针地址为0，空切片执行数组指针地址，且为一个固定值 数据结构：data,len,cap 4. 字符串转byte数组，会发生内存拷贝吗严格来说，只要发生类型强转，都会发生内存拷贝。 那么go有个很强的包叫 unsafe 。先获取变量地址，字符串转成底层结构，通过unsafe包，转为切片数组,再通过指针指向实际内容 string 数据结构 {data,len} 5. json包变量不加tag会怎么样和key的大小写有关 6. GPM指向另一篇详细（） 7.Docker 的网络通信模式。四种： 1.host模式：和宿主机公用一个network NameSpace 。容器不会配置任何自己网卡，而是使用自己宿主机的IP和端口 2.container模式：指定和其他容器共享network nameSpace,而不是和宿主机共享 3.none模式：告诉容器放到自己网站堆里，但是不要配置他的网络 4.brideg模式：docker默认的网络模式，此模式会将主机docker链接到虚拟网桥上 8.访问私有成员 调用其他包共有结构的私有成员变量 绕过小写不公开 用unsafe包中的unsafe.Pointer获取到结构体对象的首地址，然后加上想访问的私有变量的偏移地址就是私有变量的地址 9、数组和切片的区别长度，容量，数组指针 切片是指针类型，数组是是值类型 数据长度固定，切片不固定 切片比数组多个属性（cap）,切片底层是数组 扩容：小于1024 每次cap翻倍，超过变成1.25 扩容后没触及原数组容量，那么切片指针指向的位置，还是原数组，扩容后，超过原数组容量，会开辟一块新内存，原来的值拷贝过来，也不会影响原来数组 append: 10.介绍 rune 类型123456789101112package mainimport &quot;fmt&quot;func main() &#123; var str = &quot;hello 你好&quot; fmt.Println(&quot;len(str):&quot;, len(str)) //12个 //中文字符在unicode下占2个字节，在utf-8编码下占3个字节 go默认utf-8 5+1+3*2 //通过rune类型处理unicode字符 fmt.Println(&quot;rune:&quot;, len([]rune(str))) //8个 fmt.Println(&quot;RuneCountInString:&quot;, utf8.RuneCountInString(str))&#125; byte等同于uint8，而不是int8 rune 等同于int32,常用来处理unicode或utf-8字符 11 panic defer recoverpanic() 函数 函数中遇到panic语句，会立即终止当前函数的执行，在panic所在函数内如果存在要执行的defer函数列表，按照defer的逆序执行 recover() 函数 recover函数的返回值报告协程是否正在遭遇panic 有异常时，recover()只能调用一次，后面再次调用则捕获不到任何异常 通常办法：go中可以抛出一个panic的异常，然后在defer中通过recover捕获这个异常，然后正常处理，从而恢复正常代码的执行 12 读写锁和互斥锁总结： 1.在单纯的只是获取锁和释放锁时，互斥锁的用时要少一些，这主要是因为多个线程同时获取读写锁的情况比较少出现。 golang底层实现上，互斥锁确实要比读写锁的性能要好一些，这主要是因为读写锁的底层实现其实是互斥锁加上计数器 在 增 强 协 程 互 相 冲 突 的 效 果 后 ， 读 写 锁 的 性 能 要 明 显 高 于 互 斥 锁 13.结构体是否可以比较回到上面的划重点部分，在总结中我们可以知道，golang中 Slice，Map，Function 这三种数据类型是不可以直接比较的。我们再看看S结构体，该结构体并没有包含不可比较的成员变量，所以该结构体是可以直接比较的。 reflect.DeepEqual 函数 来对两个变量进行比较。 14.golang channel是线程安全的吗如果把线程安全定义为允许多个goroutine同时去读写，那么golang 的channel 是线程安全的。不需要在并发读写同一个channe时加锁。 15.channel数据结构12345678910111213141516171819202122232425type hchan struct &#123; qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element type sendx uint // send index recvx uint // receive index recvq waitq // list of recv waiters sendq waitq // list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G&#x27;s status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex&#125;type waitq struct &#123; first *sudog last *sudog&#125;","categories":[{"name":"GOLANG","slug":"GOLANG","permalink":"https://smartxia.github.io/blog/categories/GOLANG/"}],"tags":[{"name":"golang","slug":"golang","permalink":"https://smartxia.github.io/blog/tags/golang/"}]},{"title":"GOLANG-grpc","slug":"GOLANG/GOLANG-grpc","date":"2021-11-17T02:28:40.000Z","updated":"2024-03-12T03:55:12.807Z","comments":true,"path":"2021/11/17/GOLANG/GOLANG-grpc/","permalink":"https://smartxia.github.io/blog/2021/11/17/GOLANG/GOLANG-grpc/","excerpt":"","text":"grpc 官网：https://grpc.io/docs/languages/go/basics/ 中文翻译版本：http://doc.oschina.net/grpc?t=56831 1、下载protobuf的编译器protoc 地址： 1、https://github.com/google/protobuf/releases 123456789window： 下载: protoc-3.3.0-win32.zip 解压，把bin目录下的protoc.exe复制到GOPATH/bin下，GOPATH/bin加入环境变量。当然也可放在其他目录，需加入环境变量，能让系统找到protoc.exelinux： 下载：protoc-3.3.0-linux-x86_64.zip 或 protoc-3.3.0-linux-x86_32.zip解压，把bin目录下的protoc复制到GOPATH/bin下，GOPATH/bin加入环境变量。如果喜欢编译安装的，也可下载源码自行安装，最后将可执行文件加入环境变量。 2、获取protobuf的编译器插件protoc-gen-go 1234 进入GOPATH目录 运行&gt; go get -u github.com/golang/protobuf/protoc-gen-go 如果成功，会在GOPATH/bin下生成protoc-gen-go.exe文件 3、创建一个test.proto文件 12345678910111213141516171819202122232425262728293031323334//指定版本//注意proto3与proto2的写法有些不同syntax = &quot;proto3&quot;; //包名，通过protoc生成时go文件时package test; //手机类型//枚举类型第一个字段必须为0enum PhoneType &#123; HOME = 0; WORK = 1;&#125; //手机message Phone &#123; PhoneType type = 1; string number = 2;&#125; //人message Person &#123; //后面的数字表示标识号 int32 id = 1; string name = 2; //repeated表示可重复 //可以有多个手机 repeated Phone phones = 3;&#125; //联系簿message ContactBook &#123; repeated Person persons = 1;&#125; 4、运行如下命令 12&gt; protoc --go_out=. *.proto会生成一个test.pb.go的文件，具体的文件内容我就不截图了。 5、在go语言中使用protobuf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package main; import ( &quot;github.com/golang/protobuf/proto&quot; &quot;protobuf/test&quot; &quot;io/ioutil&quot; &quot;os&quot; &quot;fmt&quot;) func write() &#123; p1 := &amp;test.Person&#123; Id: 1, Name: &quot;小张&quot;, Phones: []*test.Phone&#123; &#123;test.PhoneType_HOME, &quot;111111111&quot;&#125;, &#123;test.PhoneType_WORK, &quot;222222222&quot;&#125;, &#125;, &#125;; p2 := &amp;test.Person&#123; Id: 2, Name: &quot;小王&quot;, Phones: []*test.Phone&#123; &#123;test.PhoneType_HOME, &quot;333333333&quot;&#125;, &#123;test.PhoneType_WORK, &quot;444444444&quot;&#125;, &#125;, &#125;; //创建地址簿 book := &amp;test.ContactBook&#123;&#125;; book.Persons = append(book.Persons, p1); book.Persons = append(book.Persons, p2); //编码数据 data, _ := proto.Marshal(book); //把数据写入文件 ioutil.WriteFile(&quot;./test.txt&quot;, data, os.ModePerm);&#125; func read() &#123; //读取文件数据 data, _ := ioutil.ReadFile(&quot;./test.txt&quot;); book := &amp;test.ContactBook&#123;&#125;; //解码数据 proto.Unmarshal(data, book); for _, v := range book.Persons &#123; fmt.Println(v.Id, v.Name); for _, vv := range v.Phones &#123; fmt.Println(vv.Type, vv.Number); &#125; &#125;&#125; func main() &#123; write(); read();&#125; image.png 1//go:generate protoc -I ../routeguide --go_out=plugins=grpc:../routeguide ../routeguide/route_guide.proto protoc -I 参数：指定import路径，可以指定多个-I参数，编译时按顺序查找，不指定时默认查找当前目录 --go_out ：golang编译支持，支持以下参数plugins&#x3D;plugin1+plugin2 - 指定插件，目前只支持grpc，即：plugins&#x3D;grpc","categories":[{"name":"GOLANG","slug":"GOLANG","permalink":"https://smartxia.github.io/blog/categories/GOLANG/"}],"tags":[{"name":"golang","slug":"golang","permalink":"https://smartxia.github.io/blog/tags/golang/"}]},{"title":"golang Context上下文","slug":"GOLANG/GOLANG-Context上下文","date":"2021-11-15T10:56:27.000Z","updated":"2024-03-12T03:55:12.806Z","comments":true,"path":"2021/11/15/GOLANG/GOLANG-Context上下文/","permalink":"https://smartxia.github.io/blog/2021/11/15/GOLANG/GOLANG-Context%E4%B8%8A%E4%B8%8B%E6%96%87/","excerpt":"","text":"","categories":[{"name":"GOLANG","slug":"GOLANG","permalink":"https://smartxia.github.io/blog/categories/GOLANG/"}],"tags":[{"name":"golang","slug":"golang","permalink":"https://smartxia.github.io/blog/tags/golang/"}]},{"title":"数据四层七层","slug":"REDIS/数据四层七层","date":"2021-11-10T07:08:25.000Z","updated":"2024-03-12T03:55:12.870Z","comments":true,"path":"2021/11/10/REDIS/数据四层七层/","permalink":"https://smartxia.github.io/blog/2021/11/10/REDIS/%E6%95%B0%E6%8D%AE%E5%9B%9B%E5%B1%82%E4%B8%83%E5%B1%82/","excerpt":"","text":"","categories":[{"name":"reids","slug":"reids","permalink":"https://smartxia.github.io/blog/categories/reids/"}],"tags":[]},{"title":"golang里的进程线程携程的调度方式","slug":"GOLANG/golang里的进程线程携程的调度方式","date":"2021-10-10T10:56:27.000Z","updated":"2024-03-12T03:55:12.824Z","comments":true,"path":"2021/10/10/GOLANG/golang里的进程线程携程的调度方式/","permalink":"https://smartxia.github.io/blog/2021/10/10/GOLANG/golang%E9%87%8C%E7%9A%84%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E6%90%BA%E7%A8%8B%E7%9A%84%E8%B0%83%E5%BA%A6%E6%96%B9%E5%BC%8F/","excerpt":"","text":"找工作本来想靠实力和经验，奈何仍需背面试题，刷算法，可以说是可恶了作者：腾讯技术工程链接：https://www.zhihu.com/question/20862617/answer/921061289来源：知乎 goroutine 实现: 我们去看调度的一个进化, 从进程到线程再到协程, 其实是一个不断共享, 不断减少切换成本的过程. go 实现的协程为有栈协程, go 协程的用法和线程的用法基本类似. 很多人会疑问, 协程到底是个什么东西? 用户态的调度感觉很陌生, 很抽象, 到底是个什么东西? 我觉得要理解调度, 要理解两个概念: 运行和阻塞. 特别是在协程中, 这两个概念不容易被正确理解. 我们理解概念时往往会代入自身感受, 觉得线程或协程运行就是像我们吭哧吭哧的处理事情, 线程或协程阻塞就是做事情时我们需要等待其他人. 然后就在这等着了. 要是其他人搞好了, 那我们就继续做当前的事. 其实主体对象搞错了.正确的理解应该是我们处理事情时就像 CPU, 而不是像线程或者协程. 假如我当前在写某个服务, 发现依赖别人的函数还没有 ready, 那就把写服务这件事放一边. 点开企业微信, 我去和产品沟通一些问题了. 我和产品沟通了一会后, 检查一下, 发现别人已经把依赖的函数提交了, 然后我就最小化企业微信, 切到 IDE, 继续写服务 A 了. 对操作系统有过一些了解, 知道 linux 下的线程其实是 task_struct 结构, 线程其实并不是真正运行的实体, 线程只是代表一个执行流和其状态.真正运行驱动流程往前的其实是 CPU. CPU 在时钟的驱动下, 根据 PC 寄存器从程序中取指令和操作数, 从 RAM 中取数据, 进行计算, 处理, 跳转, 驱动执行流往前. CPU 并不关注处理的是线程还是协程, 只需要设置 PC 寄存器, 设置栈指针等(这些称为上下文), 那么 CPU 就可以欢快的运行这个线程或者这个协程了. 线程的运行, 其实是被运行.其阻塞, 其实是切换出调度队列, 不再去调度执行这个执行流. 其他执行流满足其条件, 便会把被移出调度队列的执行流重新放回调度队列.协程同理, 协程其实也是一个数据结构, 记录了要运行什么函数, 运行到哪里了.go 在用户态实现调度, 所以 go 要有代表协程这种执行流的结构体, 也要有保存和恢复上下文的函数, 运行队列. 理解了阻塞的真正含义, 也就知道能够比较容易理解, 为什么 go 的锁, channel 这些不阻塞线程. 对于实现的同步执行流效果, 又不阻塞线程的网络, 接下来也会介绍. 协程结构体和切换函数 我们 go 一个 func 时一般这样写 1go func1(arg1 type1,arg2 type2)&#123;....&#125;(a1,a2) 一个协程代表了一个执行流, 执行流有需要执行的函数(对应上面的 func1), 有函数的入参(a1, a2), 有当前执行流的状态和进度(对应 CPU 的 PC 寄存器和 SP 寄存器), 当然也需要有保存状态的地方, 用于执行流恢复. 真正代表协程的是 runtime.g 结构体. 每个 go func 都会编译成 runtime.newproc 函数, 最终有一个 runtime.g 对象放入调度队列. 上面的 func1 函数的指针设置在 runtime.g 的 startfunc 字段, 参数会在 newproc 函数里拷贝到 stack 中, sched 用于保存协程切换时的 pc 位置和栈位置. 协程切换出去和恢复回来需要保存上下文, 恢复上下文, 这些由以下两个汇编函数实现. 以上就能实现协程这种执行流, 并能进行切换和恢复.(下图中的 struct 和函数都做了精简) GM 模型及 GPM 模型 有了协程的这种执行流形式, 那待运行的协程放在哪呢?在 Go1.0 的时候: 调度队列 schedt 是全局的, 对该队列的操作均需要竞争同一把锁, 导致伸缩性不好. 新生成的协程也会放入全局的队列, 大概率是被其他 m(可以理解为底层线程的一个表示)运行了, 内存亲和性不好. 当前协程 A 新生成了协程 B, 然后协程 A 比较大概率会结束或者阻塞, 这样 m 直接去执行协程 B, 内存的亲和性也会好很多. 因为 mcache 与 m 绑定, 在一些应用中(比如文件操作或其他可能会阻塞线程的系统调用比较多), m 的个数可能会远超过活跃的 m 个数, 导致比较大的内存浪费. 那是不是可以给 m 分配一个队列, 把阻塞的 m 的 mcache 给执行 go 代码的 m 使用? Go 1.1 及以后就是这样做的. 再 1.1 中调度模型更改为 GPM 模型, 引入逻辑 Process 的概念, 表示执行 Go 代码所需要的资源, 同时也是执行 Go 代码的最大的并行度. 这个概念可能很多人不知道怎么理解. P 涉及到几点, 队列和 mcache, 还有 P 的个数的选取. 首先为什么把全局队列打散, 以及 mcache 为什么跟随 P, 这个在 GM 模型那一页就讲的比较清楚了.然后为什么 P 的个数默认是 CPU 核数: Go 尽量提升性能, 那么在一个 n 核机器上, 如何能够最大利用 CPU 性能呢? 当然是同时有 n 个线程在并行运行中, 把 CPU 喂饱, 即所有核上一直都有代码在运行. 在 go 里面, 一个协程运行到阻塞系统调用, 那么这个协程和运行它的线程 m, 自然是不再需要 CPU 的, 也不需要分配 go 层面的内存. 只有一直在并行运行的 go 代码才需要这些资源, 即同时有 n 个 go 协程在并行执行, 那么就能最大的利用 CPU, 这个时候需要的 P 的个数就是 CPU 核数. (注意并行和并发的区别) 协程状态及流转 协程的状态其实和线程状态类似,状态转换和发生状态转换的时机如图所示. 还是需要注意: 协程只是一个执行流, 并不是运行实体. 调度 并没有一个一直在运行调度的调度器实体. 当一个协程切换出去或新生成的 m, go 的运行时从 stw 中恢复等情况时, 那么接下来就需要发生调度. go 的调度是通过线程(m)执行 runtime.schedule 函数来完成的. sysmon 协程 在 linux 内核中有一些执行定时任务的线程, 比如定时写回脏页的 pdflush, 定期回收内存的 kswapd0, 以及每个 cpu 上都有一个负责负载均衡的 migration 线程等.在 go 运行时中也有类似的协程, sysmon.功能比较多: 定时从 netpoll 中获取 ready 的协程, 进行抢占, 定时 GC,打印调度信息,归还内存等定时任务. 协作式抢占 go 目前(1.12)还没有实现非协作的抢占. 基本流程是 sysmon 协程标记某个协程运行过久, 需要切换出去, 该协程在运行函数时会检查栈标记, 然后进行切换. 同步执行流不阻塞线程的网络的实现 go 写后台最舒服的就是能够以同步写代码的方式操作网络, 但是网络操作不阻塞线程.主要是结合了非阻塞的 fd, epoll 以及协程的切换和恢复.linux 提供了网络 fd 的非阻塞模式, 对于没有 ready 的非阻塞 fd 执行网络操作时, linux 内核不阻塞线程, 会直接返回 EAGAIN, 这个时候将协程状态设置为 wait, 然后 m 去调度其他协程. go 在初始化一个网络 fd 的时候, 就会把这个 fd 使用 epollctl 加入到全局的 epoll 节点中. 同时放入 epoll 中的还有 polldesc 的指针. 123456func netpollopen(fd uintptr, pd *pollDesc) int32 &#123; var ev epollevent ev.events = _EPOLLIN | _EPOLLOUT | _EPOLLRDHUP | _EPOLLET *(**pollDesc)(unsafe.Pointer(&amp;ev.data)) = pd return -epollctl(epfd, _EPOLL_CTL_ADD, int32(fd), &amp;ev)&#125; 在 sysmon 中, schedule 函数中, start the world 中等情况下, 会执行 netpoll 调用 epollwait 系统调用, 把 ready 的网络事件从 epoll 中取出来, 每个网络事件可以通过前面传入的 polldesc 获取到阻塞在其上的协程, 以此恢复协程为 runnable. 调度相关结构体 调度综述 内存分配内存分配简介 Go 的分配采用了类似 tcmalloc 的结构.特点: 使用一小块一小块的连续内存页, 进行分配某个范围大小的内存需求. 比如某个连续 8KB 专门用于分配 17-24 字节,以此减少内存碎片. 线程拥有一定的 cache, 可用于无锁分配. 同时 Go 对于 GC 后回收的内存页, 并不是马上归还给操作系统, 而是会延迟归还, 用于满足未来的内存需求. 内存空间结构 在 1.10 以前 go 的堆地址空间是线性连续扩展的, 比如在 1.10(linux amd64)中, 最大可扩展到 512GB. 因为 go 在 gc 的时候会根据拿到的指针地址来判断是否位于 go 的 heap 的, 以及找到其对应的 span, 其判断机制需要 gc heap 是连续的. 但是连续扩展有个问题, cgo 中的代码(尤其是 32 位系统上)可能会占用未来会用于 go heap 的内存. 这样在扩展 go heap 时, mmap 出现不连续的地址, 导致运行时 throw. 在 1.11 中, 改用了稀疏索引的方式来管理整体的内存. 可以超过 512G 内存, 也可以允许内存空间扩展时不连续.在全局的 mheap struct 中有个 arenas 二阶数组, 在 linux amd64 上,一阶只有一个 slot, 二阶有 4M 个 slot, 每个 slot 指向一个 heapArena 结构, 每个 heapArena 结构可以管理 64M 内存, 所以在新的版本中, go 可以管理 4M*64M&#x3D;256TB 内存, 即目前 64 位机器中 48bit 的寻址总线全部 256TB 内存. span 机制 前面提到了 go 的内存分配类似于 tcmalloc, 采用了 span 机制来减少内存碎片. 每个 span 管理 8KB 整数倍的内存, 用于分配一定范围的内存需求. 内存分配全景 多层次的分配 Cache, 每个 P 上有一个 mcache, mcache 会为每个 size 最多缓存一个 span, 用于无锁分配. 全局每个 size 的 span 都有一个 mcentral, 锁的粒度相对于全局的 heap 小很多, 每个 mcentral 可以看成是每个 size 的 span 的一个全局后备 cache. 在 gc 完成后, 会把 P 中的 span 都 flush 到 mcentral 中, 用于清扫后再分配. P 有需要 span 时, 从对应 size 的 mcentral 获取. 获取不到再上升到全局的 heap. 几种特殊的分配器 对于很小的对象分配, go 做了个优化, 把小对象合并, 以移动指针的方式分配.对于栈内存有 stackcache 分配, 也有多个层次的分配, 同时 stack 也有多个不同 size. 用于分配 stack 的内存也是位于 go gc heap, 用 mspan 管理, 不过这个 span 的状态和用于分配对象的 mspan 状态不太一样, 为 mSpanManual. 我们可以思考一个问题, go 的对象是分配在 go gc heap 中, 并由 mcache, mspan, mcentral 这些结构管理, 那么 mcache, mspan, mcentral 这些结构又是哪里管理和分配的呢? 肯定不是自己管理自己. 这些都是由特殊的分配 fixalloc 分配的, 每种类型有一个 fixalloc, 大致原理就是通过 mmap 从进程空间获取一小块内存(百 KB 的样子), 然后用来分配这个固定大小的结构. 内存分配综合 GCGolang GC 简述 GC 简介 GC 并不是个新事物, 使得 GC 大放光彩的是 Java 语言. Golang GC 发展 上面是几个比较重要的版本.左图是根据 twitter 工程师的数据绘制的(堆比较大), 从 1.4 的百 ms 级别的停顿到 1.8 以后的小于 1ms.右图是我对线上服务(Go 1.11 编译)测试的一个结果, 是一个批量拉取数据的服务, 大概 3000qps, 服务中发起的 rpc 调用大概在 2w&#x2F;s. 可以看到大部分情况下 GC 停顿小于 1ms, 偶尔超过一点点. 整体来说 golang gc 用起来是很舒心的, 几乎不用你关心. 三色标记 go 采用的是并发三色标记清除法. 图展示的是一个简单的原理.有几个问题可以思考一下: 并发情况下, 会不会漏标记对象? 对象的三色状态存放在哪? 如何根据一个对象来找到它引用的对象? 写屏障 GC 最基本的就是正确性: 不漏标记对象, 程序还在用的对象都被清除了, 那程序就错误了. 有一点浮动垃圾是允许的.在并发情况下, 如果没有一些措施来保障, 那可能会有什么问题呢? 看左边的代码和图示, 第 2 步标记完 A 对象, A 又没有引用对象, 那 A 变成黑色对象. 在第 3 步的时候, muator(程序)运行, 把对象 C 从 B 转到了 A, 第 4 步, GC 继续标记, 扫描 B, 此时 B 没有引用对象, 变成了黑色对象. 我们会发现 C 对象被漏标记了. 如何解决这个问题? go 使用了写屏障, 这里的写屏障是指由编译器生成的一小段代码. 在 gc 时对指针操作前执行的一小段代码, 和 CPU 中维护内存一致性的写屏障不太一样哈.所以有了写屏障后, 第 3 步, A.obj&#x3D;C 时, 会把 C 加入写屏障 buf. 最终还是会被扫描的. 这里感受一下写屏障具体生成的代码. 我们可以看到在写入指针 slot 时, 对写屏障是否开启做了判断, 如果开启了, 会跳转到写屏障函数, 执行加入写屏障 buf 的逻辑. 1.8 中写屏障由 Dijkstra 写屏障改成了混合式写屏障, 使得 GC 停顿达到了 1ms 以下. 三色状态 并没有这样一个集合把不同状态对象放到对应集合中. 只是一个逻辑上的意义. 扫描和元信息 gc 拿到一个指针, 如何把这个指针指向的对象其引用的子对象都加到扫描队列呢? 而且 go 还允许内部指针, 似乎更麻烦了. 我们分析一下, 要知道对象引用的子对象, 从对象开始到对象结尾, 把对象那一块内存上是指针的放到扫描队列就好了. 那我们是不是得知道对象有多大, 从哪开始到哪结束, 同时要知道内存上的 8 个字节, 哪里是指针, 哪里是普通的数据. 首先 go 的对象是 mspan 管理的, 我们如果能知道对象属于哪个 mspan, 就知道对象多大, 从哪开始, 到哪结束了. 前面我们讲到了 areans 结构, 可以通过指针加上一定得偏移量, 就知道属于哪个 heap arean 64M 块. 再通过对 64M 求余, 结合 spans 数组, 即可知道属于哪个 mspan 了. 结合 heapArean 的 bitmap 和每 8 个字节在 heapArean 中的偏移, 就可知道对象每 8 个字节是指针还是普通数据(这里的 bitmap 是在分配对象时根据 type 信息就设置了, type 信息来源于编译器生成) GC 流程 1.5 和 1.12 的 GC 大致流程相同. 上图是 golang 官方的 ppt 里的图, 下图是我根据 1.12 源码绘制的.从最坏可能会有百 ms 的 gc 停顿到能够稳定在 1ms 以下, 这之间 GC 做了很多改进. 右边是我根据官方 issues 整理的一些比较重要的改进. 1.6 的分布式检测, 1.7 将栈收缩放到了并发扫描阶段, 1.8 的混合写屏障, 1.12 更改了 mark termination 检测算法, mcache flush 移除出 mark termination 等等. Golang GC Pacer 大家对并发 GC 除了怎么保证不漏指针有疑问外, 可能还会疑问, 并发 GC 如何保证能够跟得上应用程序的分配速度? 会不会分配太快了, GC 完全跟不上, 然后 OOM? 这个就是 Golang GC Pacer 的作用. Go 的 GC 是一种比例 GC, 下一次 GC 结束时的堆大小和上一次 GC 存活堆大小成比例. 由 GOGC 控制, 默认 100, 即 2 倍的关系, 200 就是 3 倍, 以此类推. 假如上一次 GC 完成时, 存活对象 1000M, 默认 GOGC 100, 那么下次 GC 会在比较接近但小于 2000M 的时候(比如 1900M)开始, 争取在堆大小达到 2000M 的时候结束. 这之间留有一定的裕度, 会计算待扫描对象大小(根据历史数据计算)与可分配的裕度的比例, 应用程序分配内存根据该比例进行辅助 GC, 如果应用程序分配太快了, 导致 credit 不够, 那么会被阻塞, 直到后台的 mark 跟上来了,该比例会随着 GC 进行不断调整. GC 结束后, 会根据这一次 GC 的情况来进行负反馈计算, 计算下一次 GC 开始的阈值. 如何保证按时完成 GC 呢? GC 完了后, 所有的 mspan 都需要 sweep, 类似于 GC 的比例, 从 GC 结束到下一次 GC 开始之间有一定的堆分配裕度, 会根据还有多少的内存需要清扫, 来计算分配内存时需要清扫的 span 数这样的一个比例. 实践与总结观察调度 观察一下调度, 加一些请求. 我们可以看到虽然有 1000 个连接, 但是 go 只用了几个线程就能处理了, 表明 go 的网络的确是由 epoll 管理的. runqueue 表示的是全局队列待运行协程数量, 后面的数字表示每个 P 上的待运行协程数. 可以看到待处理的任务并没有增加, 表示虽然请求很多, 但完全能 hold 住. 同时可以看到, 不同 P 上有的时候可能任务不均衡, 但是一会后, 任务又均衡了, 表示 go 的 work stealing 是有效的. 观察 GC 其中一些数据的含义, 在分享的时候没有怎么解释, 不过网上的解释几乎没有能完全解释正确. 我这里敲一下.其实一般关注堆大小和两个 stw 的 wall time 即可. gc 8913(第 8913 次 gc) @2163.341s(在程序运行的第 2163s) 1%(gc 所有 work 消耗的历史累计 CPU 比例, 所以其实这个数据没太大意义) 0.13(第一个 stw 的 wall time)+14(并发 mark 的 wall time)+0.20(第二个 stw 的 wall time) ms clock, 1.1(第一个 stw 消耗的 CPU 时间)+21(用户程序辅助扫描消耗的 cpu 时间)&#x2F;22(分配用于 mark 的 P 消耗的 cpu 时间)&#x2F;0(空闲的 P 用于 mark 的 cpu 时间)+1.6ms(第 2 个 stw 的 cpu 时间) cpu, 147(gc 开始时的堆大小)-&gt;149(gc 结束的堆大小)-&gt;75MB(gc 结束时的存活堆大小), 151 MB goal(本次 gc 预计结束的堆大小), 8P(8 个 P). 优化 个人建议, 没事不要总想着优化, 好好 curd 就好. 当然还是有一些优化方法的. 一点实践 我们将 pprof 的开启集成到模板中, 并自动选择端口, 并集成了 gops 工具, 方便查询 runtime 信息, 同时在浏览器上可直接点击生成火焰图, pprof 图, 非常的方便, 也不需要使用者关心. 问题排查的一点思路 一次有意思的问题排查 负载, 依赖服务都很正常, CPU 利用率也不高, 请求也不多, 就是有很多超时. 该服务在线上打印了 debug 日志, 因为早期的服务模板开启了 gctrace, 框架把 stdout 重定向到一个文件了. 而输出 gctrace 时本来是到 console 的, 输出到文件了, 而磁盘跟不上, 导致 gctrace 日志被阻塞了. 这里更正一下 ppt 中的内容, 并不是因为 gc 没完成而导致其他协程不能运行, 而是后续 gc 无法开启, 导致实质上的 stw.打印 gc trace 日志时, 已经 start the world 了, 其他协程可以开始运行了. 但是在打印 gctrace 日志时, 还保持着开启 gc 需要的锁, 所以, 打印 gc trace 日志一直没完成, 而 gc 又比较频繁, 比如 0.1s 一次, 这样会导致下一次 gc 开始时无法获取锁, 每一个进入 gc 检查的 p 阻塞, 实际上就造成了 stw. Runtime 的一点个人总结 并行, 纵向多层次, 横向多个 class, 缓存, 缓冲, 均衡. 参考文档 本文完整 PPT 可点击下方图片获得。","categories":[{"name":"GOLANG","slug":"GOLANG","permalink":"https://smartxia.github.io/blog/categories/GOLANG/"}],"tags":[{"name":"golang","slug":"golang","permalink":"https://smartxia.github.io/blog/tags/golang/"}]},{"title":"开发空间使用文档","slug":"Wiki/开发空间使用文档","date":"2021-09-01T07:44:30.000Z","updated":"2024-03-12T03:55:12.872Z","comments":true,"path":"2021/09/01/Wiki/开发空间使用文档/","permalink":"https://smartxia.github.io/blog/2021/09/01/Wiki/%E5%BC%80%E5%8F%91%E7%A9%BA%E9%97%B4%E4%BD%BF%E7%94%A8%E6%96%87%E6%A1%A3/","excerpt":"","text":"开发空间使用文档项目设置项目主页项目名称：默认创建的时候的名称，可以在这里修改 封面：项目的封面，可以用来发布，图片尺寸符合页面提示内容 简介：项目的一些简单介绍 代码仓库代码仓库默认分为语言类型的git仓库，所带有的框架默认支持打包，和支持中台的基本框架 前端仓库：vue idg等 后端仓库：golang java php node 等 ios,android,中台小程序，微信小程序，h5，浏览器插件，pc，跨段应用， 勤务仓库，和区块链专用仓库，并支持复制其他仓库 仓库使用：默认开发者为主master分支管理员 分支: 合并请求：可以合并其他用户提交的合并请求 标签：利用此标签可以用来打包集成各类型的资产包和镜像 成员：可以添加成员 镜像管理可以分为两大类：镜像（可以直接放在服务器运行的）包管理（可以支持其他服务引入的） 镜像根据仓库类型里的tag然后进行打包： 包括：php(5-*7)类型，golang(13-15)java 和其他类型打包 vue类型镜像 包根据仓库里的tag进行打包： 包括:npm android ios composer h5等类型dab 成员管理此处用来添加用户，其中项目成员基本权限要有：项目负责人或者项目参与者。支持批量添加用户角色 部署设置b部署设置放在此处比较早，需要后端或者项目负责人添加。 其中包括：对项目所需要的容器资源类型进行配置，和资源模板配置，cpu membery port 等 产品定义 模块列表：默认有主模块。主模块权限属于第一个使用产品定义的人，并非创建者。 可以选择新增模块，填写模块名称和描述，模块标签 模块之间支持的功能：利用密钥来实现复制（内容复制）和分享（通道分享） 模块之间可以添加用户，给用户赋予模块负责人、模块参与者（只有浏览权限） 任务列表： 包括产品、后端、设计使用的基本工具和文档 需求定义：产品需要写的一些基本功能提供。项目创立之初的一些信息收集，和基本的作图，设计用例，数据模型等功能的支持 设计文档：一些基本的设计图片文稿，竞品分析，设计用的图片且支持图片拖动执行 技术定义：后端的一些基本api文档填写 数据定义：数据库相关的基本使用 每个分类下分为各种的类型使用，种类繁多，满足项目创立之初所有的使用 多语言管理项目多语言支撑项目内关键词，各个国家语言的翻译使用 会议记录记录项目成员每次开会使用的基本任务 接入管理中台核心内容：支持开发者创建开发容器，支持实例数据填写ACL权限管控，支持用户购买 资源管理容器云所需的资源购买和资源配置 部署空间中台核心内容：支持开发者创建开发容器，支持实例数据填写ACL权限管控，支持用户购买 项目管理项目issue配置 CICD项目自动化测试 发布管理项目发布到市场 GUI管理gui前端界面自动化添加 WIKI项目Wiki记录","categories":[],"tags":[]},{"title":"GOLGANG-笔记6-学习日志位运算符","slug":"GOLANG/GOLANG-笔记6-学习日志","date":"2021-08-27T01:55:06.000Z","updated":"2024-03-12T03:55:12.821Z","comments":true,"path":"2021/08/27/GOLANG/GOLANG-笔记6-学习日志/","permalink":"https://smartxia.github.io/blog/2021/08/27/GOLANG/GOLANG-%E7%AC%94%E8%AE%B06-%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/","excerpt":"","text":"位运算：位运算符对整数在内存中的二进制位进行操作。 &amp;, |, 和 ^ 》》》 《《《 数组 var a 【5】string a:&#x3D;[5]string[“2”,”3”,”4”,”2”,”3”] a:&#x3D;[….]string[“2”,”3”,”4”,”2”,”3”] 空指针：指针定义后没有分配到任何变量就会错 旧的： uh49y8vwmxp5rsiqthfjm62ynxbajofc edc8af2cfdaf438e9e1dc301234e13b9 747 opygwmeutz6kt15umavlwyrcjqqok0ni topocpzejlq4huin6cmhieqxxn8fep7n 263 新的： uh49y8vwmxp5rsiqthfjm62ynxbajofc edc8af2cfdaf438e9e1dc301234e13b9 747 opygwmeutz6kt15umavlwyrcjqqok0ni 8191a23b9783477599b9f01f53f5bab7 37","categories":[{"name":"GOLANG","slug":"GOLANG","permalink":"https://smartxia.github.io/blog/categories/GOLANG/"}],"tags":[]},{"title":"计算机基础-转义字符","slug":"Wiki/计算机基础-转义字符","date":"2021-06-22T02:54:33.000Z","updated":"2024-03-12T03:55:12.895Z","comments":true,"path":"2021/06/22/Wiki/计算机基础-转义字符/","permalink":"https://smartxia.github.io/blog/2021/06/22/Wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80-%E8%BD%AC%E4%B9%89%E5%AD%97%E7%AC%A6/","excerpt":"","text":"什么是转义字符？有什么用？转义字符是一种特殊的字符常量","categories":[{"name":"计算机基础知识","slug":"计算机基础知识","permalink":"https://smartxia.github.io/blog/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"转义字符","slug":"转义字符","permalink":"https://smartxia.github.io/blog/tags/%E8%BD%AC%E4%B9%89%E5%AD%97%E7%AC%A6/"},{"name":"wiki","slug":"wiki","permalink":"https://smartxia.github.io/blog/tags/wiki/"}]},{"title":"正则表达式-修饰符","slug":"正则表达式/正则表达式-修饰符","date":"2021-06-07T08:09:29.000Z","updated":"2024-03-12T03:55:12.917Z","comments":true,"path":"2021/06/07/正则表达式/正则表达式-修饰符/","permalink":"https://smartxia.github.io/blog/2021/06/07/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F-%E4%BF%AE%E9%A5%B0%E7%AC%A6/","excerpt":"","text":"标记也称为修饰符，正则表达式的标记用于指定额外的匹配策略。 标记不写在正则表达式里，标记位于表达式之外 1/pattern/flags 修饰符 含义 描述 i ignore - 不区分大小写 将匹配设置为不区分大小写，搜索时不区分大小写: A 和 a 没有区别。 g global - 全局匹配 查找所有的匹配项。 m multi line - 多行匹配 使边界字符 ^ 和 $ 匹配每一行的开头和结尾，记住是多行，而不是整个字符串的开头和结尾。 s 特殊字符圆点 . 中包含换行符 \\n 默认情况下的圆点 . 是 匹配除换行符 \\n 之外的任何字符，加上 s 修饰符之后, . 中包含换行符 \\n。 元字符运算符优先级正则表达式从左到右进行计算，并遵循优先级顺序，这与算术表达式非常类似。 相同优先级的从左到右进行运算，不同优先级的运算先高后低。下表从最高到最低说明了各种正则表达式运算符的优先级顺序： 运算符 描述 \\ 转义符 (), (?:), (?&#x3D;), [] 圆括号和方括号 *, +, ?, {n}, {n,}, {n,m} 限定符 ^, $, \\任何元字符、任何字符 定位点和序列（即：位置和顺序） | 替换，”或”操作 字符具有高于替换运算符的优先级，使得”m|food”匹配”m”或”food”。若要匹配”mood”或”food”，请使用括号创建子表达式，从而产生”(m|f)ood”。","categories":[{"name":"regex","slug":"regex","permalink":"https://smartxia.github.io/blog/categories/regex/"}],"tags":[{"name":"regex","slug":"regex","permalink":"https://smartxia.github.io/blog/tags/regex/"}]},{"title":"正则表达式-语法","slug":"正则表达式/正则表达式-语法","date":"2021-06-07T05:40:59.000Z","updated":"2024-03-12T03:55:12.917Z","comments":true,"path":"2021/06/07/正则表达式/正则表达式-语法/","permalink":"https://smartxia.github.io/blog/2021/06/07/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F-%E8%AF%AD%E6%B3%95/","excerpt":"","text":"https://github.com/ziishaned/learn-regex/blob/master/translations/README-cn.md 1.普通字符：1-9 a-z A-Z 标点符号和一些其他符号。 key val desc exp &#x2F;*&#x2F; 基础语法区隔，转义符号 ^ 开始位置 $ 结束位置 [0-9] 匹配数字 [a-z] 小写字母 [A-Z] 大写字母 + runoo+b 匹配一个或多个 - 连接字符 {} {3,5} 字符长度3-5 ^[a-z0-9_-]{3,15}$ ？ colou?r 匹配 color 或者 colour … […] 匹配所有字符 ( ) ( ) 子表达式的开始和结束位置 2.非打印字符","categories":[{"name":"regex","slug":"regex","permalink":"https://smartxia.github.io/blog/categories/regex/"}],"tags":[{"name":"regex","slug":"regex","permalink":"https://smartxia.github.io/blog/tags/regex/"}]},{"title":"网络协议","slug":"HTTP/网络协议","date":"2021-06-07T01:49:48.000Z","updated":"2024-03-12T03:55:12.825Z","comments":true,"path":"2021/06/07/HTTP/网络协议/","permalink":"https://smartxia.github.io/blog/2021/06/07/HTTP/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"1.0 网络协议（TCP Trancemission Control Protocol） 1.1 请求头 1.2 三次握手四次挥手 1.3 报文抓取工具 2.0 HTTP (HyperText Transfer protocol) 2.1 请求报文 2.2 响应报文 2.3 HTTP 抓取工具 2.4 Session Cookie 3.0 总结 1.0 网络协议（TCP Trancemission Control Protocol） TCP 七层网络模型主机层：媒介层： 1.1 请求头1.2 三次握手四次挥手1.3 报文抓取工具2.0 HTTP (HyperText Transfer protocol) 2.1 请求报文2.2 响应报文2.3 HTTP 抓取工具2.4 Session Cookie3.0 总结","categories":[{"name":"HTTP","slug":"HTTP","permalink":"https://smartxia.github.io/blog/categories/HTTP/"}],"tags":[]},{"title":"The MIT License","slug":"Wiki/其他-MIT 许可协议","date":"2021-05-27T01:25:29.000Z","updated":"2024-03-12T03:55:12.871Z","comments":true,"path":"2021/05/27/Wiki/其他-MIT 许可协议/","permalink":"https://smartxia.github.io/blog/2021/05/27/Wiki/%E5%85%B6%E4%BB%96-MIT%20%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"MIT许可证（The MIT License）是许多软件授权条款中，被广泛使用的其中一种。与其他常见的软件授权条款（如GPL、LGPL、BSD）相比，MIT是相对宽松的软件授权条款。 1.条款内容1234Copyright (C) &lt;year&gt; &lt;copyright holders&gt;Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the &quot;Software&quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. 2.MIT与其他开源许可证的区别","categories":[{"name":"其他","slug":"其他","permalink":"https://smartxia.github.io/blog/categories/%E5%85%B6%E4%BB%96/"}],"tags":[]},{"title":"孔乙己和阿Q","slug":"我的日记/孔乙己和阿Q","date":"2021-05-26T02:23:14.000Z","updated":"2024-03-18T03:22:23.787Z","comments":true,"path":"2021/05/26/我的日记/孔乙己和阿Q/","permalink":"https://smartxia.github.io/blog/2021/05/26/%E6%88%91%E7%9A%84%E6%97%A5%E8%AE%B0/%E5%AD%94%E4%B9%99%E5%B7%B1%E5%92%8C%E9%98%BFQ/","excerpt":"","text":"孔乙己原为鲁迅笔下的一个旧时代的人物，我们可以简单理解为一个臭读书的阿Q我们听到的最多的是阿Q精神：自恋不自知的小人物这些都是鲁迅笔下的小人物，之前不大明白鲁迅为何喜欢写这些我们现在看起来抨击小人物的短片小说，包括对闰土 阿Q 孔乙己 祥林嫂 范爱农等等这些现在看起来很离谱的事情，这要是放到现在不得不说是一股奇葩的力量在微博贡献，因为本人也是个冲浪的键盘侠。但了解过鲁迅大大说过一句很经典的话：学医救不了中国人当时是民国 想想这句话到底有几个味道大家便知道了现在提起来中国人，你走到哪里都是自豪的，除了蜜汁自信呢的美帝，最起码在国外是没问题的，对于一个长时间被中央人民广播电台熏陶的年青人是这样的 当时中国是被侵略，被十几个人打，想想那画面，不敢还手，对于国家至此，何况老百姓。其实鲁迅笔下任务用的最多为小小的底层任务对社会，谈不上社会，而是对自己的生活圈子里造成的影响，可有可无的那种。","categories":[{"name":"diary","slug":"diary","permalink":"https://smartxia.github.io/blog/categories/diary/"}],"tags":[]},{"title":"从正则表达式的iUs说说模式修正符","slug":"PHP/PHP-从正则表达式的iUs说说模式修正符","date":"2021-05-25T11:06:09.000Z","updated":"2024-03-12T03:55:12.844Z","comments":true,"path":"2021/05/25/PHP/PHP-从正则表达式的iUs说说模式修正符/","permalink":"https://smartxia.github.io/blog/2021/05/25/PHP/PHP-%E4%BB%8E%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%9A%84iUs%E8%AF%B4%E8%AF%B4%E6%A8%A1%E5%BC%8F%E4%BF%AE%E6%AD%A3%E7%AC%A6/","excerpt":"","text":"本想做个简单的采集程序，发现被抓页面代码的规律后发现抓下来的内容没有放到一个数组中，而是放在一个元素中，无奈找遍资料发现在正则表达式后加上”&#x2F;iUs”后竟然可以了。hexo网上关于iUs的说明多数都是抄袭的，没有做过多的解释，对于一个小学毕业证是买来的人来说是在是不好理解。不过幸亏Google让我找到答案。 “iUs” 在这里叫“模式修正符”。模式修正符其实就是几个字母，可以一次使用一个也可以一次使用多个，每一个都具有一定的意义，模式修正符是对正则表达式的扩展；“&#x2F;模式修正符”，其中正斜线“&#x2F;”为边界符。下表列出来有那些模式修正符： 模式修正符 说明i 表示在和模式进行匹配进不区分大小写m 将模式视为多行，使用^和$表示任何一行都可以以正则表达式开始或结束s 如果没有使用这个模式修正符号，元字符中的”.”默认不能表示换行符号,将字符串视为单行x 表示模式中的空白忽略不计e 正则表达式必须使用在preg_replace替换字符串的函数中时才可以使用(讲这个函数时再说)A 以模式字符串开头，相当于元字符^Z 以模式字符串结尾，相当于元字符$U 正则表达式的特点：就是比较“贪婪”，使用该模式修正符可以取消贪婪模式 1，模式修正符m。123456789101112&lt;?php$pattern = ‘/^abc/m’;$string = ‘bcdabccba’;if (preg_match($pattern, $string, $arr)) &#123;echo “正则表达式&lt;b&gt;&#123;$pattern&#125;&lt;/b&gt;和字符串&lt;b&gt;&#123;$string&#125;&lt;/b&gt;匹配成功&lt;br&gt;”;print_r($arr);&#125; else &#123;echo “&lt;font color=’red’&gt;正则表达式&#123;$pattern&#125;和字符串&#123;$string&#125;匹配失败&lt;/font&gt;”;&#125;?&gt; 匹配结果是成功的。注意：我们在使用模式修正符m的时候，将匹配字符串看成是多行而不是默认的单行，所以任何一行只要是以abc开头，就匹配成功。但是，如果能匹配的行前面有空格的话，就不能匹配了!除非修改正则表达式的匹配模式。 2，模式修正符s。1234567891011&lt;?php$pattern = ‘/a.*c/s’;$string = ‘adsadsac’;if (preg_match($pattern, $string, $arr)) &#123;echo “正则表达式&lt;b&gt;&#123;$pattern&#125;&lt;/b&gt;和字符串&lt;b&gt;&#123;$string&#125;&lt;/b&gt;匹配成功&lt;br&gt;”;print_r($arr);&#125; else &#123;echo “&lt;font color=’red’&gt;正则表达式&#123;$pattern&#125;和字符串&#123;$string&#125;匹配失败&lt;/font&gt;”;&#125;?&gt; 这次的匹配记过也是成功的。如果你将上例中的模式修正符s去掉的话，匹配就会失败。因为模式修正符s将匹配字符串看作是单行的，所以这个时候，元字符中的”.”就可以表示换行符号了。 3，模式修正符x。12345678910&lt;?php$pattern = ‘/a c/x’;$string = ‘a c’;if (preg_match($pattern, $string, $arr)) &#123;echo “正则表达式&lt;b&gt;&#123;$pattern&#125;&lt;/b&gt;和字符串&lt;b&gt;&#123;$string&#125;&lt;/b&gt;匹配成功&lt;br&gt;”;print_r($arr);&#125; else &#123;echo “&lt;font color=’red’&gt;正则表达式&#123;$pattern&#125;和字符串&#123;$string&#125;匹配失败&lt;/font&gt;”;&#125;?&gt; 这次的匹配结果是失败的。因为我们使用模式修正符x取消了模式中的空格。注意：我们无法使用模式修正符取消\\s表示的空白。 4，模式修正符A。1234567891011&lt;?php$pattern = ‘/ac/A’;$string = ‘acahgyghvbm’;if (preg_match($pattern, $string, $arr)) &#123;echo “正则表达式&lt;b&gt;&#123;$pattern&#125;&lt;/b&gt;和字符串&lt;b&gt;&#123;$string&#125;&lt;/b&gt;匹配成功&lt;br&gt;”;print_r($arr);&#125; else &#123;echo “&lt;font color=’red’&gt;正则表达式&#123;$pattern&#125;和字符串&#123;$string&#125;匹配失败&lt;/font&gt;”;&#125;?&gt; 正则表达式表示的含义是匹配以ac开头的字符串，结果成功。 模式修正符Z表示的是以字符串结尾的匹配，和A的用法是一样的，我们不再进行演示。 5，模式修正符U。这个模式修正符是十分重要的!在正则表达式中，其本身是“贪婪”的。那什么是贪婪模式呢?贪婪模式的意思就是说，正则表达式默认会在查找到第一个匹配后，继续尝试后面的匹配，如果能找到匹配，则匹配最大的范围字符串。但有的时候这并不是我们想要的结果，所以我们需要取消贪婪模式。 我们还是先看一个贪婪模式的例子： 12345678910&lt;?php$pattern = ‘/&lt;b&gt;.*&lt;\\/b&gt;/’;$string = ‘&lt;b&gt;welcome&lt;/b&gt; &lt;b&gt;to&lt;/b&gt; &lt;b&gt;phpfuns&lt;/b&gt;’;if (preg_match($pattern, $string, $arr)) &#123;echo “正则表达式&lt;b&gt;&#123;$pattern&#125;&lt;/b&gt;和字符串&lt;b&gt;&#123;$string&#125;&lt;/b&gt;匹配成功&lt;br&gt;”;print_r($arr);&#125; else &#123;echo “&lt;font color=’red’&gt;正则表达式&#123;$pattern&#125;和字符串&#123;$string&#125;匹配失败&lt;/font&gt;”;&#125;?&gt; 这个实例的本意是匹配welcome，但是结果却匹配了welcome to phpfuns整个字符串(注意我们的字符串’welcome to phpfuns’，其开头和结尾正好构成了正则表达式的模式匹配，所以匹配成功)，这就是正则表达式的贪婪模式。当然，这不是我们要的结果。 取消贪婪模式我们可以使用模式修正符U和元字符?两种方式取消正则表达式的贪婪模式。 模式修正符U取消贪婪模式 12345678910&lt;?php$pattern = ‘/&lt;b&gt;.*&lt;\\/b&gt;/U’;$string = ‘&lt;b&gt;welcome&lt;/b&gt; &lt;b&gt;to&lt;/b&gt; &lt;b&gt;phpfuns&lt;/b&gt;’;if (preg_match($pattern, $string, $arr)) &#123;echo “正则表达式&lt;b&gt;&#123;$pattern&#125;&lt;/b&gt;和字符串&lt;b&gt;&#123;$string&#125;&lt;/b&gt;匹配成功&lt;br&gt;”;print_r($arr);&#125; else &#123;echo “&lt;font color=’red’&gt;正则表达式&#123;$pattern&#125;和字符串&#123;$string&#125;匹配失败&lt;/font&gt;”;&#125;?&gt; 元字符?取消贪婪模式 12345678910&lt;?php$pattern = ‘/&lt;b&gt;.*?&lt;\\/b&gt;/’;$string = ‘&lt;b&gt;welcome&lt;/b&gt; &lt;b&gt;to&lt;/b&gt; &lt;b&gt;phpfuns&lt;/b&gt;dsadsadas’;if (preg_match($pattern, $string, $arr)) &#123;echo “正则表达式&lt;b&gt;&#123;$pattern&#125;&lt;/b&gt;和字符串&lt;b&gt;&#123;$string&#125;&lt;/b&gt;匹配成功&lt;br&gt;”;print_r($arr);&#125; else &#123;echo “&lt;font color=’red’&gt;正则表达式&#123;$pattern&#125;和字符串&#123;$string&#125;匹配失败&lt;/font&gt;”;&#125;?&gt; 注意元字符的位置，我们必须在“”之前结束贪婪模式，才能达到我们的目的","categories":[{"name":"PHP","slug":"PHP","permalink":"https://smartxia.github.io/blog/categories/PHP/"}],"tags":[]},{"title":"关于 URL 中协议的省略","slug":"前端知识/关于-URL-中协议的省略","date":"2021-05-25T01:15:06.000Z","updated":"2024-03-12T03:55:12.897Z","comments":true,"path":"2021/05/25/前端知识/关于-URL-中协议的省略/","permalink":"https://smartxia.github.io/blog/2021/05/25/%E5%89%8D%E7%AB%AF%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8E-URL-%E4%B8%AD%E5%8D%8F%E8%AE%AE%E7%9A%84%E7%9C%81%E7%95%A5/","excerpt":"","text":"前天看了 Google HTML&#x2F;CSS 代码风格指南，里面有很多值得借鉴的地方，也学到了一些新东西，其中第一条说道，HTML 和 CSS 代码中引用的图片、媒体、CSS 和 JS 文件中的 URL 都可以去掉协议部分（http: 和 https:），比如 都可以换成： 只要是使用 http、https 这两种协议都可以省略。原因是可以节省一点文件体积（当然只是那么一点点），另外一个原因 Google 说是可以解决混合内容的问题。起初我对这个第二点不是很了解，所以特意搜索了下。最后从 Paul Irish 的一篇文章找到答案，链接在文后。文章是两三年前写的，老外研究问题总是比我们要早啊。 以 &#x2F;&#x2F; 开头的叫做相对URL（protocol-relative URL），相关的标准可以看 RFC 3986 Section 4.2，内容不是一般的长估计大家也没耐心去看吧。总之浏览器遇到相对 URL，则会根据当前的网页协议，自动在 &#x2F;&#x2F; 前面加上相同的协议。如当前网页是 http 访问，那么所有的相对引用 &#x2F;&#x2F; 都会变成http:&#x2F;&#x2F;。https 同理。如果你在本地查看，协议就会变成 file:&#x2F;&#x2F;。 所以，如果省略协议，就需要保证引用的外部资源也采用和网页相同的协议，或者保证资源可以同时通过 http 和 https 访问。经过 StackOverflow 网友测试，这种用法几乎所有的浏览器都能支持，只有在 IE7&#x2F;8 下会有一点小问题，就是通过相对 URL 引用的 CSS 文件（无论 或 @import）会被下载两遍。所以对性能有一点影响。 至于 Google 提到的混合内容问题，其实是指IE有时会弹出的一个警告框： 这个框想必大家也都见过。通常是在浏览 https 网页的时候出现，原因是网页里引用了 http 协议的外部资源，由于 http 被认为是不安全的，IE 才会给出提示。如果引用的时候写成相对 URL，浏览器就会自动采用 https 协议下载，这样就解决了问题。 所以，我们平时写代码还是可以放心使用相对 URL 的，写博客的大概很少开 https，当然做项目的就例外了。如果你引用的资源里有 https 协议的就特别处理一下，或者只要 http 也能访问到资源就可以。我看了下国内的站点这么用的还不多，有一次看到百度音乐这么用过。不过 Google 很多站点都已经是这样的写法了。 > 参考资料： http://paulirish.com/2010/the-protocol-relative-url/http://stackoverflow.com/questions/4831741/can-i-change-all-my-http-links-to-justhttps://developer.mozilla.org/zh-CN/ 转载 自：http://pandacafe.net/post/231?huvqlc=r5eup1","categories":[{"name":"前端知识","slug":"前端知识","permalink":"https://smartxia.github.io/blog/categories/%E5%89%8D%E7%AB%AF%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"http://","slug":"http","permalink":"https://smartxia.github.io/blog/tags/http/"},{"name":"https://","slug":"https","permalink":"https://smartxia.github.io/blog/tags/https/"}]},{"title":"天气晴-2021-5-20","slug":"我的日记/天气晴-2021-5-20","date":"2021-05-20T01:09:27.000Z","updated":"2024-03-12T03:55:12.916Z","comments":true,"path":"2021/05/20/我的日记/天气晴-2021-5-20/","permalink":"https://smartxia.github.io/blog/2021/05/20/%E6%88%91%E7%9A%84%E6%97%A5%E8%AE%B0/%E5%A4%A9%E6%B0%94%E6%99%B4-2021-5-20/","excerpt":"","text":"今天是2021年5月20日，是个好日子 早上打开电脑 撇了下右下角的电脑，是2021&#x2F;5&#x2F;20 嗯是个吉利的数字","categories":[{"name":"diary","slug":"diary","permalink":"https://smartxia.github.io/blog/categories/diary/"}],"tags":[]},{"title":"百年孤独","slug":"经典读物/经典读物","date":"2021-05-18T01:33:24.000Z","updated":"2024-03-12T03:55:12.918Z","comments":true,"path":"2021/05/18/经典读物/经典读物/","permalink":"https://smartxia.github.io/blog/2021/05/18/%E7%BB%8F%E5%85%B8%E8%AF%BB%E7%89%A9/%E7%BB%8F%E5%85%B8%E8%AF%BB%E7%89%A9/","excerpt":"","text":"家族的第一个人被捆在树上，最后一个人正被蚂蚁吃掉 这本书到底讲了什么？作者想表达什么？自己有了什么样的感触 经典语句1、多年以后，奥雷连诺上校站在行刑队面前，准会想起父亲带他去参观冰块的那个遥远的下午。 2、 过去都是假的，回忆是一条没有归途的路，以往的一切春天都无法复原，即使最狂热最坚贞的爱情，归根结底也不过是一种瞬息即逝的现实，唯有孤独永恒。 3、买下一张永久车票，登上一列永无终点的火车。 4、我们趋行在人生这个亘古的旅途，在坎坷中奔跑，在挫折里涅槃，忧愁缠满全身，痛苦飘洒一地。我们累，却无从止歇；我们苦，却无法回避。 5、生命中真正重要的不是你遭遇了什么，而是你记住了哪些事，又是如何铭记的。 6、我确实一度死去，但难以忍受孤独又重返人世。 7、他渴望孤独，对整个世界的怨恨咬噬着他的内心。 8、我们趋行在人生这个亘古的旅途，在坎坷中奔跑，在挫折里涅槃，忧愁缠满全身，痛苦飘洒一地。我们累，却无从止歇；我们苦，却无法回避。 9、所有人都显得很寂寞，用自己的方式想尽办法排遣寂寞，事实上仍是延续自己的寂寞。寂寞是造化对群居者的诅咒，孤独才是寂寞的唯一出口。 10、这手稿上所写的事情过去不曾，将来也永远不会重复，因为命中注定要一百年处于孤独的世家决不会有出现在世上的第二次机会。 百年孤独讲述了什么《百年孤独》讲的是一个叫布恩迪亚家族百年的兴衰以及小镇马孔多的发展变迁史。 布恩迪亚家族的每一代人都在努力地摆脱孤独落后的生活状态，但是却一次又一次的失败，最终，家族的最后一个人被蚂蚁吃掉，整个屋子也被风卷走，从此消失在地球上，再未出现。 孤独会让人丧失对生活的希望。没有人喜欢孤独，布恩迪亚家族的人付出了一辈又一辈的努力，却依然是一场空，书也表现了人类的抗争，对命运的无可奈何以及天性的顽固。 百年孤独反思《百年孤独》是哥伦比亚作家加西亚·马尔克斯的一部长篇小说 百年孤独比较适合25岁以上，经历过社会的人看。这样才能读出韵味的。 说到底《百年孤独》好在它的新颖，不仅让人们看到一个不一样的故事，也让人看到了小说不一样的表现手，而且这种不一样的表现手法，被国内许多的作家所借鉴引用。这也就是《百年孤独》的好处。 可以不客气地说，《百年孤独》影响了中国当代文学的走向，国内许多的作家，正是由于看了这本小说之后，才开始写出了自己最为重要的作品，例如莫言、陈忠实、余华、阎连科等等，这些国内一线作家，那都是受到了《百年孤独》的影响，他们的作品里，都有着《百年孤独》的影子。也正是这一份影响，使得它在国人心目中，有着崇高的地位。","categories":[],"tags":[]},{"title":"git 使用 connot stat","slug":"GIT/cannot stat","date":"2021-05-17T06:12:35.000Z","updated":"2024-03-12T03:55:12.805Z","comments":true,"path":"2021/05/17/GIT/cannot stat/","permalink":"https://smartxia.github.io/blog/2021/05/17/GIT/cannot%20stat/","excerpt":"","text":"1.记一次使用buggit error: cannot stat原因是因为，在某个编辑器打开了master分支的一个文件，然后切换到feat分支，文件并不消失，拉取时候出现问题， 解决办法：关掉编辑器","categories":[{"name":"git","slug":"git","permalink":"https://smartxia.github.io/blog/categories/git/"}],"tags":[]},{"title":"GOLANG-改善golang50个有效实践","slug":"GOLANG/GOLANG-改善golang50个有效实践","date":"2021-05-14T05:24:11.000Z","updated":"2024-03-12T03:55:12.819Z","comments":true,"path":"2021/05/14/GOLANG/GOLANG-改善golang50个有效实践/","permalink":"https://smartxia.github.io/blog/2021/05/14/GOLANG/GOLANG-%E6%94%B9%E5%96%84golang50%E4%B8%AA%E6%9C%89%E6%95%88%E5%AE%9E%E8%B7%B5/","excerpt":"","text":"闲逛好久go论坛，找到一本适合看的教程，花了点时间将这个文章搬运过来，自己慢慢研读 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 转载自慕课资源，仅供学习使用，如有侵权联系自行删除","categories":[{"name":"GOLANG","slug":"GOLANG","permalink":"https://smartxia.github.io/blog/categories/GOLANG/"}],"tags":[{"name":"golang","slug":"golang","permalink":"https://smartxia.github.io/blog/tags/golang/"},{"name":"书籍","slug":"书籍","permalink":"https://smartxia.github.io/blog/tags/%E4%B9%A6%E7%B1%8D/"},{"name":"推荐","slug":"推荐","permalink":"https://smartxia.github.io/blog/tags/%E6%8E%A8%E8%8D%90/"}]},{"title":"其他-软件行业高频单词","slug":"Wiki/其他-软件行业高频单词","date":"2021-05-14T02:20:48.000Z","updated":"2024-03-12T03:55:12.872Z","comments":true,"path":"2021/05/14/Wiki/其他-软件行业高频单词/","permalink":"https://smartxia.github.io/blog/2021/05/14/Wiki/%E5%85%B6%E4%BB%96-%E8%BD%AF%E4%BB%B6%E8%A1%8C%E4%B8%9A%E9%AB%98%E9%A2%91%E5%8D%95%E8%AF%8D/","excerpt":"","text":"1.golang高频英语并发：(Concurrency) [kənˈkʌrənsɪ] 并行：(Parallelism) [ˈpærəlelɪzəm] 摩尔定律：(Moore’s Law):集成电路上可以容纳的晶体管数目在大约每经过18个月便会增加一倍。换言之，处理器的性能每隔两年翻一倍 cup主频：（CPU Clock Speed）:主频即CPU的时钟频率，计算机的操作在时钟信号的控制下分步执行，每个时钟信号周期完成一步操作，时钟频率的高低在很大程度上反映了CPU速度的快慢 时钟频率：(clock rate):是指同步电路中时钟的基础频率，它以“若干次周期每秒”来度量，量度单位采用SI单位赫兹（Hz）。它是评定CPU性能的重要指标。一般来说主频数字值越大越好。外频，是CPU外部的工作频率，是由主板提供的基准时钟频率。FSB频率，是连接CPU和主板芯片组中的北桥芯片的前端总线（Front Side Bus）上的数据传输频率。CPU的主频和外频间存在这样的关系：主频&#x3D;外频×倍频。 pthread： (线程)kernel ：（核心） 好的命名就像一个好笑话。如果你必须解释它，那就不好笑了 在 Go 语言中 interface 名字仍然以单个词为优先。对于拥有唯一方法 (method) 或通过多个拥有唯一方法的接口组合而成的接口，Go 语言的惯例是一般用 “方法名 + er” 的方式为 interface 命名coined：创造Syntax: 语法Semantics: 语意 Go 设计者认为隐式转换带来的便利性不足以抵消其带来的诸多问题 1，因此要解决上面的编译错误，我们必须进行显式地转型：","categories":[{"name":"其他","slug":"其他","permalink":"https://smartxia.github.io/blog/categories/%E5%85%B6%E4%BB%96/"}],"tags":[]},{"title":"设计模式-概述，为什么要使用设计模式","slug":"设计模式/设计模式-概述，为什么要使用设计模式","date":"2021-05-13T05:39:46.000Z","updated":"2024-03-12T03:55:12.918Z","comments":true,"path":"2021/05/13/设计模式/设计模式-概述，为什么要使用设计模式/","permalink":"https://smartxia.github.io/blog/2021/05/13/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E6%A6%82%E8%BF%B0%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BD%BF%E7%94%A8%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"设计模式（Design pattern） GOF(gong of for)可复用面向对象软件元素 对接口编程而不是对实现编程 优先使用对象组合而不是继承 设计模式的类型（23种）基本可以分为四大类： 创建型模式（Creational Patterns）提供一种在创建对象的时候隐藏逻辑方法的形式，而不是直接new一个对象，这使得程序在判断针对某个特定的实例需要创建哪些对象的时候更加灵活。 结构型模式 (Structural Patterns)关注类和对象组合，集成的概念用来组合接口和定义组合对象 获取新的功能方式 行为型模式 (Behavioral Patterns)关注对象之间的通信 j2EE模式这些模式主要由java 中的设计模式提供（Sun Java Center） 模式描述 包括 1 创建型模式 工厂模式（Factory Pattern） 抽象工厂模式（Abstract Factory Pattern） 单例模式（Singleton Pattern） 建造者模式（Builder Pattern） 原型模式（Prototype Pattern） 2 结构型模式 适配器模式（Adapter Pattern） 桥接模式（Bridge Pattern） 过滤器模式（Filter、Criteria Pattern） 组合模式（Composite Pattern） 装饰器模式（Decorator Pattern） 外观模式（Facade Pattern） 享元模式（Flyweight Pattern） 代理模式（Proxy Pattern） 3 行为型模式 责任链模式（Chain of Responsibility Pattern） 命令模式（Command Pattern） 解释器模式（Interpreter Pattern） 迭代器模式（Iterator Pattern） 中介者模式（Mediator Pattern） 备忘录模式（Memento Pattern） 观察者模式（Observer Pattern） 状态模式（State Pattern） 空对象模式（Null Object Pattern） 策略模式（Strategy Pattern） 模板模式（Template Pattern） 访问者模式（Visitor Pattern） 4 J2ee型模式 MVC 模式（MVC Pattern） 业务代表模式（Business Delegate Pattern） 组合实体模式（Composite Entity Pattern） 数据访问对象模式（Data Access Object Pattern） 前端控制器模式（Front Controller Pattern） 拦截过滤器模式（Intercepting Filter Pattern） 服务定位器模式（Service Locator Pattern） 传输对象模式（Transfer Object Pattern） 设计模式 之间关系 设计模式的六大原则 开闭原则（Open Close Principle）: 对扩展开放，对修改关闭 ，在程序需要进行扩展的时候，不能去修改原代码，实现一个热拔插的效果。为了的是使程序的扩展性更好，易于维护和升级，我们需要使用接口和抽象类来实现 里氏代换原则（Liskow Substitution Priciple） 任何基类出现的地方，子类一定可以出现。LSP是继承复用的基石，只有当派生类可以替换掉基类，且软件单位不受影响的时候，基类才能真正的被附中，而派生类可以在基类中增加新的行为，LSP是对开闭原则的补充。开闭原则关键步骤就是抽象化，基类与子类的继承关系就是抽象化的具体实现，即：对实现抽象化具体步骤的规范 依赖倒转原则（Dependence Inversion Priciple） 针对接口变成，依赖于抽象而不依赖于具体 接口隔离原则（Interface Segregation Priciple） 多实用隔离的接口，比使用单个接口更好。降低类之间的耦合度。 迪米特法则（Demeter Priciple） 最少知道的原则：一个实体应当尽量少跟其他实体之间发生相互的作用，是得系统模块相对 合成复用原则（composite Reuse Priciple） 尽量使用合成&#x2F;聚合方式，而不是使用继承","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://smartxia.github.io/blog/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://smartxia.github.io/blog/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"PHP-Phpfpm进程管理的三种模式","slug":"PHP/PHP-Phpfpm进程管理的三种模式","date":"2021-05-10T03:44:49.000Z","updated":"2024-03-12T03:55:12.827Z","comments":true,"path":"2021/05/10/PHP/PHP-Phpfpm进程管理的三种模式/","permalink":"https://smartxia.github.io/blog/2021/05/10/PHP/PHP-Phpfpm%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"","categories":[{"name":"PHP","slug":"PHP","permalink":"https://smartxia.github.io/blog/categories/PHP/"}],"tags":[]},{"title":"PHP-Phpfmp-如何分配任务到子进程的","slug":"PHP/PHP-Phpfmp-如何分配任务到子进程的","date":"2021-05-10T03:43:54.000Z","updated":"2024-03-12T03:55:12.826Z","comments":true,"path":"2021/05/10/PHP/PHP-Phpfmp-如何分配任务到子进程的/","permalink":"https://smartxia.github.io/blog/2021/05/10/PHP/PHP-Phpfmp-%E5%A6%82%E4%BD%95%E5%88%86%E9%85%8D%E4%BB%BB%E5%8A%A1%E5%88%B0%E5%AD%90%E8%BF%9B%E7%A8%8B%E7%9A%84/","excerpt":"","text":"https://blog.csdn.net/liuqun0319/article/details/92573976?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-2.vipsorttest&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-2.vipsorttest","categories":[{"name":"PHP","slug":"PHP","permalink":"https://smartxia.github.io/blog/categories/PHP/"}],"tags":[]},{"title":"GOLANG-笔记5-gin开发规范","slug":"GOLANG/GOLANG-笔记5-gin开发规范","date":"2021-04-29T09:32:51.000Z","updated":"2024-03-12T03:55:12.821Z","comments":true,"path":"2021/04/29/GOLANG/GOLANG-笔记5-gin开发规范/","permalink":"https://smartxia.github.io/blog/2021/04/29/GOLANG/GOLANG-%E7%AC%94%E8%AE%B05-gin%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83/","excerpt":"","text":"Go语言Web框架基线版本一.框架简介此web框架已gin为核心，包含了mysq、redis、rabbitmq、log、es等基础组件。此框架内dockerfile和makefile已适配中台的打镜像流程，一般情况下不需要对这两个文件进行修改。 123456789101112131415161718192021222324├── controller //控制器│ └── v1├── dao //dao层│ ├── mysql│ └── redis├── db //mysql文件初始化├── docs //swagger 接口文档├── middleware //中间件├── model //model层│ ├── mapi│ ├── mdb│ ├── mmysql│ └── mparam├── pconst //常量定义├── route //路由层│ └── v1├── script //脚本层│ └── logic├── server //服务启动├── service //业务层├── tgo //基础组件└── util //工具包 ├── curl └── ip 二.框架分层2.1.路由层框架采用强路由模式，支持路由群组、中间件模式，自带跨域组件并默认开启，路由文件存放在 route 目录下 2.2.控制器层控制器存放在controller目录下，并区分版本，此层仅针对参数进行过滤处理，不处理相关业务。已集成swagger自动生成接口文档 2.3.业务层业务层存放在service目录下，用来处理业务相关的逻辑 2.4.数据处理层业务层存放在dao目录下，并根据下游不同服务放入不同目录下，此层仅处理数据，不处理业务相关逻辑 2.5.对象层对象层存放在mode目录下，并根据对象的不同类型存放下级不同目录 2.6.中间件层中间件层存放在middleware目录下，用以对同一分组或具有相同特征的路由进行全局业务处理 2.7.脚本层脚本层存放在script目录下，用以处理非http类型的业务类型 2.8.常量层常量定义存放在pconst目录下 三.整体流程框架整体请求请求流程为route - middleware - controller - service - dao，控制器、业务、数据处理禁止逆向调用 四.请求示例参考控制器下 log_platform.go 文件 五.中台服务间调用 gosdk使用和服务间调用有问题和建议可以联系联系基础架构部：张超 中台服务间调用通过gosdk进行调用，gosdk如何使用可以参考服务内的readme文档。 为了降低使用成本，我们对gosdk进行了一次封装requester包，并提供了一个案例account服务的接口封装。 【强烈建议】：对子服务（比如A）的调用封装成单独的包，并在gitlab.oneitfarm.com&#x2F;ci123sdk group下创建项目A，将服务A的接口调用封装。这样其他项目（人）在接入A项目时，不需要再重复封装此部分内容。简单来说就是每个服务在ci123sdk的group下创建项目，后续所有对此服务调用的封装都在此项目中，所有引用此服务的服务或应用，只需要引用此包进行开发，如果支持接口不全就在此项目中完善并打新的tag增加版本。 六.关于PR有任何疑问或者建议，欢迎随时联系基础架构部：陶圣，也欢迎各位提交有价值的PR，也将纳入年终绩效考核一部分","categories":[{"name":"GOLANG","slug":"GOLANG","permalink":"https://smartxia.github.io/blog/categories/GOLANG/"}],"tags":[{"name":"golang","slug":"golang","permalink":"https://smartxia.github.io/blog/tags/golang/"},{"name":"farmworker","slug":"farmworker","permalink":"https://smartxia.github.io/blog/tags/farmworker/"},{"name":"gin","slug":"gin","permalink":"https://smartxia.github.io/blog/tags/gin/"}]},{"title":"高性能库zap gox","slug":"GOLANG/GOLANG-笔记4-高性能库zap","date":"2021-04-29T09:31:41.000Z","updated":"2024-03-12T03:55:12.820Z","comments":true,"path":"2021/04/29/GOLANG/GOLANG-笔记4-高性能库zap/","permalink":"https://smartxia.github.io/blog/2021/04/29/GOLANG/GOLANG-%E7%AC%94%E8%AE%B04-%E9%AB%98%E6%80%A7%E8%83%BD%E5%BA%93zap/","excerpt":"","text":"zap高性能日志库分析 参数配置##GOX交叉编译工具可以编译各种的环境go get github.com&#x2F;mitchellh&#x2F;goxgox -build-toolchain 直接运行gox。程序会一口气生成17个文件横跨windows,linux,mac,freebsd,netbsd五大操作系统#####固定平台gox -osarch “windows&#x2F;amd64 linux&#x2F;amd64” 或 gox -os “windows linux” -arch amd64 go mod init 命令go.sum是一个模块版本内容的校验值，用来验证当前缓存的模块。go.sum包含了直接依赖和间接依赖的包的信息，比go.mod要多一些。 查看依赖包go list -m all 模块配置文本格式化go mod edit -fmt Windows 下开启 GO111MODULE 的命令为：set GO111MODULE&#x3D;on 或者 set GO111MODULE&#x3D;auto 代理GOPROXY&#x3D;https://goproxy.cn,direct 以索引整个 GOPATH.Preferences -&gt; Go -&gt; GOPATH，勾选上 Index entire GOPATH 基础命令关于module的go mod downloadgo mod download -json 参数会以JSON的格式打印下载的模块对象go mod tidygo mod tidy -v 可以将执行的信息可以使用go mod tidy命令来清除它go mod vendorgo mod vendor -v会将添加到vendor中的模块打印到标准输出。go mod graph打印模块依赖图","categories":[{"name":"GOLANG","slug":"GOLANG","permalink":"https://smartxia.github.io/blog/categories/GOLANG/"}],"tags":[{"name":"golang","slug":"golang","permalink":"https://smartxia.github.io/blog/tags/golang/"},{"name":"zap","slug":"zap","permalink":"https://smartxia.github.io/blog/tags/zap/"},{"name":"gox","slug":"gox","permalink":"https://smartxia.github.io/blog/tags/gox/"},{"name":"module","slug":"module","permalink":"https://smartxia.github.io/blog/tags/module/"}]},{"title":"最近太懒了","slug":"我的日记/最近太懒了","date":"2021-04-29T09:22:49.000Z","updated":"2024-03-12T03:55:12.917Z","comments":true,"path":"2021/04/29/我的日记/最近太懒了/","permalink":"https://smartxia.github.io/blog/2021/04/29/%E6%88%91%E7%9A%84%E6%97%A5%E8%AE%B0/%E6%9C%80%E8%BF%91%E5%A4%AA%E6%87%92%E4%BA%86/","excerpt":"","text":"自定义支持markdown只会让我的VsCode越来越卡 技术性不强但是打字还慢无语了，这个打字的东西 1print(a) 强行换行","categories":[{"name":"diary","slug":"diary","permalink":"https://smartxia.github.io/blog/categories/diary/"}],"tags":[]},{"title":"golang调度-channel","slug":"GOLANG/GOLANG-Channel","date":"2021-01-10T10:56:27.000Z","updated":"2024-03-12T03:55:12.806Z","comments":true,"path":"2021/01/10/GOLANG/GOLANG-Channel/","permalink":"https://smartxia.github.io/blog/2021/01/10/GOLANG/GOLANG-Channel/","excerpt":"","text":"Channel 设计原理不要通过恭喜内存的方式进行通信，二十通过通信的方式共享内存。 很多主流编程语言中，多个线程传递数据方式一般情况都是共享内存，为了解决线程竞争，需要限制同一时间读写这些变量的线程数量 虽然可以通过共享内存加互斥锁进行通信，但是go提供了一种不同并发的模型，即顺序通讯进程， Gorouting 和channel分别对应csp中实体和传递信息媒介。 gorutine通过channel传递数据 两个独立的goroutine ，一个会向channel中发送数据，另一个会从channel中读取数据，两个能独立的运行，并不存在直接关联，但是通过channel完成通讯 先入先出原则（FIFO） 先从channel读取数据的goroutine会先接受到数据 先向channel发送数据的goroutine会得到先发送的权力 这种 FIFO 的设计是相对好理解的，但是稍早的 Go 语言实现却没有严格遵循这一语义，我们能在 runtime: make sure blocked channels run operations in FIFO order 中找到关于带缓冲区的 Channel 在执行收发操作时没有遵循先进先出的讨论2。 发送方会向缓冲区写入数据，然后唤醒接收方，多个接受方会先尝试从缓冲区读取数据，如果没有读取到会重新陷入休眠。 接收方会从缓冲区去读数据，然后唤醒接收方，发送方会尝试像缓冲去写入数据，如果缓冲区已满会重新陷入休眠 这种基于重试的机制会导致channel的处理遵循先进先出的原则。 无锁管道 数据结构 Go在channel中运行使用runtime.hchan ,新建chnanel结构 1234567891011121314type hchan struct &#123; qcount uint dataqsiz uint buf unsafe.Pointer elemsize uint16 closed uint32 elemtype *_type sendx uint recvx uint recvq waitq sendq waitq lock mutex&#125; 创建新的channel，如上结构构造地城循环队列：五个字段 qcount channel中元素个数 dataqsiz channel循环长度 buf channel缓冲指针 sendx channel发送操作处理到的位置 recvx channel 接受的操作位置 除此之外，elemsize elemtype 标识channel收发的元素类型和大小 sendq和recvq存储当前channel由于缓冲区元素不足而阻塞的goroutine 列表，这些等待队列可以用双向列表runtime.waitq标识，链表中所有元素都是runtime.sudog 1234type waitq struct &#123; first *sudog last *sudog&#125; runtime.sudog 表示一个在等待列表中的 Goroutine，该结构中存储了两个分别指向前后 runtime.sudog 的指针以构成链表。 创建管道 go中所有channel节点创建都会使用make关键字，编译器会将make(chan int,10)表达式转换成OMAKE类型的节点，并在类型检查阶段，将OMAKEl类型节点转为OMAKECHAN类型： 1234567891011121314151617func typecheck1(n *Node, top int) (res *Node) &#123; switch n.Op &#123; case OMAKE: ... switch t.Etype &#123; case TCHAN: l = nil if i &lt; len(args) &#123; // 带缓冲区的异步 Channel ... n.Left = l &#125; else &#123; // 不带缓冲区的同步 Channel n.Left = nodintconst(0) &#125; n.Op = OMAKECHAN &#125; &#125;&#125; 这一阶段会对传入 make 关键字的缓冲区大小进行检查，如果我们不向 make 传递表示缓冲区大小的参数，那么就会设置一个默认值 0，也就是当前的 Channel 不存在缓冲区。 如果当前 Channel 中不存在缓冲区，那么就只会为 runtime.hchan 分配一段内存空间； 如果当前 Channel 中存储的类型不是指针类型，会为当前的 Channel 和底层的数组分配一块连续的内存空间； 在默认情况下会单独为 runtime.hchan 和缓冲区分配内存； 在函数的最后会统一更新 runtime.hchan 的 elemsize、elemtype 和 dataqsiz 几个字段。 发送数据 当我们想要向Channel发送数据时候，就需要使用ch&lt;-i语句，编译器将会将它解析冲OSEND节点，并在xxx ,转换runtime.channelsend1 12345678910func walkexpr(n *Node, init *Nodes) *Node &#123; switch n.Op &#123; case OSEND: n1 := n.Right n1 = assignconv(n1, n.Left.Type.Elem(), &quot;chan send&quot;) n1 = walkexpr(n1, init) n1 = nod(OADDR, n1, nil) n = mkcall1(chanfn(&quot;chansend1&quot;, 2, n.Left.Type), nil, init, n.Left, n1) &#125;&#125; runtime.chansend1 只是调用了 runtime.chansend 并传入 Channel 和需要发送的数据。runtime.chansend 是向 Channel 中发送数据时一定会调用的函数，该函数包含了发送数据的全部逻辑，如果我们在调用时将 block 参数设置成 true，那么表示当前发送操作是阻塞的： 1234567func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool &#123; lock(&amp;c.lock) if c.closed != 0 &#123; unlock(&amp;c.lock) panic(plainError(&quot;send on closed channel&quot;)) &#125; 在发送数据的逻辑执行之前会先为当前 Channel 加锁，防止多个线程并发修改数据。如果 Channel 已经关闭，那么向该 Channel 发送数据时会报 “send on closed channel” 错误并中止程序。 因为 runtime.chansend 函数的实现比较复杂，所以我们这里将该函数的执行过程分成以下的三个部分： 当存在等待的接收者时，通过 runtime.send 直接将数据发送给阻塞的接收者； 当缓冲区存在空余空间时，将发送的数据写入 Channel 的缓冲区； 当不存在缓冲区或者缓冲区已满时，等待其他 Goroutine 从 Channel 接收数据； 小结： 小结 我们在这里可以简单梳理和总结一下使用 ch &lt;- i 表达式向 Channel 发送数据时遇到的几种情况： 如果当前 Channel 的 recvq 上存在已经被阻塞的 Goroutine，那么会直接将数据发送给当前 Goroutine 并将其设置成下一个运行的 Goroutine； 如果 Channel 存在缓冲区并且其中还有空闲的容量，我们会直接将数据存储到缓冲区 sendx 所在的位置上； 如果不满足上面的两种情况，会创建一个 runtime.sudog 结构并将其加入 Channel 的 sendq 队列中，当前 Goroutine 也会陷入阻塞等待其他的协程从 Channel 接收数据； 发送数据的过程中包含几个会触发 Goroutine 调度的时机： 发送数据时发现 Channel 上存在等待接收数据的 Goroutine，立刻设置处理器的 runnext 属性，但是并不会立刻触发调度； 发送数据时并没有找到接收方并且缓冲区已经满了，这时会将自己加入 Channel 的 sendq 队列并调用 runtime.goparkunlock 触发 Goroutine 的调度让出处理器的使用权；","categories":[{"name":"GOLANG","slug":"GOLANG","permalink":"https://smartxia.github.io/blog/categories/GOLANG/"}],"tags":[{"name":"golang","slug":"golang","permalink":"https://smartxia.github.io/blog/tags/golang/"}]},{"title":"以及如何使用rpc","slug":"HTTP/GRPC-go-php","date":"2020-09-19T02:55:30.000Z","updated":"2024-03-12T03:55:12.824Z","comments":true,"path":"2020/09/19/HTTP/GRPC-go-php/","permalink":"https://smartxia.github.io/blog/2020/09/19/HTTP/GRPC-go-php/","excerpt":"","text":"http://doc.oschina.net/grpc?t=57966 gRPC 基于 HTTP&#x2F;2 标准设计，带来诸如双向流、流控、头部压缩、单 TCP 连接上的多复用请求等特。这些特性使得其在移动设备上表现更好，更省电和节省空间占用。gRPC 也是基于以下理念：定义一个服务，指定其能够被远程调用的方法（包含参数和返回类型）。在服务端实现这个接口，并运行一个 gRPC 服务器来处理客户端调用。在客户端拥有一个存根能够像服务端一样的方法。 正如其他 RPC 系统，gRPC 基于如下思想：定义一个服务， 指定其可以被远程调用的方法及其参数和返回类型。gRPC 默认使用 protocol buffers 作为接口定义语言，来描述服务接口和有效载荷消息结构。如果有需要的话，可以使用其他替代方案。 使用 protocol buffers","categories":[{"name":"HTTP","slug":"HTTP","permalink":"https://smartxia.github.io/blog/categories/HTTP/"}],"tags":[{"name":"rpc()","slug":"rpc","permalink":"https://smartxia.github.io/blog/tags/rpc/"}]},{"title":"PHP-解决循环内存占用溢出-缓冲查询","slug":"PHP/PHP-解决循环内存占用溢出-缓冲查询","date":"2020-09-02T06:50:51.000Z","updated":"2024-03-12T03:55:12.846Z","comments":true,"path":"2020/09/02/PHP/PHP-解决循环内存占用溢出-缓冲查询/","permalink":"https://smartxia.github.io/blog/2020/09/02/PHP/PHP-%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E5%86%85%E5%AD%98%E5%8D%A0%E7%94%A8%E6%BA%A2%E5%87%BA-%E7%BC%93%E5%86%B2%E6%9F%A5%E8%AF%A2/","excerpt":"","text":"","categories":[{"name":"PHP","slug":"PHP","permalink":"https://smartxia.github.io/blog/categories/PHP/"}],"tags":[]},{"title":"PHP-深拷贝浅拷贝-_clone","slug":"PHP/PHP-深拷贝浅拷贝","date":"2020-09-02T06:50:07.000Z","updated":"2024-03-12T03:55:12.846Z","comments":true,"path":"2020/09/02/PHP/PHP-深拷贝浅拷贝/","permalink":"https://smartxia.github.io/blog/2020/09/02/PHP/PHP-%E6%B7%B1%E6%8B%B7%E8%B4%9D%E6%B5%85%E6%8B%B7%E8%B4%9D/","excerpt":"","text":"深拷贝&#x2F;&#x2F;变量复制了一份传递给另一个变量就是深拷贝,一个值改变了,另一个值不会变（直接复制） 浅拷贝&#x2F;&#x2F;变量之间的值是地址*|&amp;传递,这就是浅拷贝.值如果改变了两个变量的值都会改变 （引用复制，可变） 关键次 _clone 对象赋值：浅拷贝 普通类型的变量是深拷贝 php默认浅拷贝即普通赋值 例1： 1234567891011class Persion&#123;public $age = 0;public $name = &#x27;xiapeifus&#x27;;public $obj = null;&#125;$persion = new Persion();$xiaoming = clone $persion; //使用clone关键字复制一份$a的值,进行深拷贝.拷贝之后不会改变$a之前的值$xiaoming-&gt;age = 1;var_dump($persion-&gt;age);// 0var_dump($xiaoming-&gt;age);// 1 &#x2F;&#x2F;例2：增加__clone对象的赋值 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class doclone&#123; private $id,$name,$address; public function __construct($id=0,$name=&#x27;&#x27;,$address=&#x27;&#x27;)&#123; $this-&gt;name=$name; $this-&gt;id=$id; $this-&gt;address=$address; &#125; public function get_id()&#123; return $this-&gt;id; &#125; public function get_name()&#123; return $this-&gt;name; &#125; public function get_address()&#123; return $this-&gt;address; &#125; public function __clone()&#123; $this-&gt;id=$this-&gt;id+1; $this-&gt;name=&#x27;wqw&#x27;; $this-&gt;address=&#x27;USA&#x27;; &#125;&#125;$A = new doclone(1,&#x27;xiapeifu&#x27;,&#x27;UK&#x27;);echo &#x27;克隆之前的对象:&#x27;;echo &#x27;id=&#x27;.$A-&gt;get_id();echo &#x27;name=&#x27;.$A-&gt;get_name();echo &#x27;address=&#x27;.$A-&gt;get_address();echo &quot;\\n&quot;;$B = clone $A;echo &#x27;克隆过后的对象：&#x27;;echo &#x27;id=&#x27;.$A-&gt;get_id();echo &#x27;name=&#x27;.$A-&gt;get_name();echo &#x27;address=&#x27;.$A-&gt;get_address();echo &quot;\\n&quot;;echo &#x27;克隆过后的对象属性:&#x27;;echo &#x27;id=&#x27;.$B-&gt;get_id();echo &#x27;name=&#x27;.$B-&gt;get_name();echo &#x27;address=&#x27;.$B-&gt;get_address();//结果//克隆之前的对象:id=1name=xiapeifuaddress=UK//克隆过后的对象：id=1name=xiapeifuaddress=UK//克隆过后的对象属性:id=2name=wqwaddress=USA 思考：colne 关键词 当对象没__colne 方法时候类似于new 一个对象出来没区别 当对象有__clone时候会在clone里面的重新赋值新的属性，类似于重新new 一个对象 ，只不过把重新new的对象进行一些默认操作，其实重新new一个对象重新赋值也一样，clone可能就是单纯炫技吧","categories":[{"name":"PHP","slug":"PHP","permalink":"https://smartxia.github.io/blog/categories/PHP/"}],"tags":[]},{"title":"Git-代码提交规范","slug":"GIT/Git-代码提交规范","date":"2020-09-02T06:13:27.000Z","updated":"2024-03-12T03:55:12.805Z","comments":true,"path":"2020/09/02/GIT/Git-代码提交规范/","permalink":"https://smartxia.github.io/blog/2020/09/02/GIT/Git-%E4%BB%A3%E7%A0%81%E6%8F%90%E4%BA%A4%E8%A7%84%E8%8C%83/","excerpt":"","text":"Git commit message 是Git提交的必要信息，message的信息完整度也反映了工程师对于代码提交的重视程度，不清晰的git message信息甚至会让工程师完全回忆不起自己当初做了什么调整，导致后续代码维护成本特别大。因此为了提高线上代码库的管理程度，特此制定GIT commit message规范。 一、commit message格式1、Type(必须)用于说明 git commit 的类别，只允许使用下面的标识。feat：新功能（feature）。fix&#x2F;to：修复bug，可以是QA发现的BUG，也可以是研发自己发现的BUG。fix：产⽣diff并自动修复此问题。适合于一次提交直接修复问题to：只产⽣diff不自动修复此问题。适合于多次提交。最终修复问题提交时使用fixdocs：文档（documentation）。style：格式（不影响代码运行的变动）。refactor：重构（即不是新增功能，也不是修改bug的代码变动）。perf：优化相关，比如提升性能、体验。test：增加测试。chore：构建过程或辅助工具的变动。revert：回滚到上一个版本。merge：代码合并。sync：同步主线或分⽀的Bug 2、scope(可选)scope用于说明 commit 影响的范围，比如数据层、控制层、视图层等等，视项目不同而不同。例如在Angular，可以是location，browser，compile，compile，rootScope， ngHref，ngClick，ngView等。如果你的修改影响了不止一个scope，你可以使用*代替。 3、subject(必须)subject是commit目的的简短描述，不超过50个字符。1.建议使用中文。2.结尾不加句号或其他标点符号。根据以上规范 git commit message 将是如下的格式：fix(DAO): 用户查询缺少username属性feat(Controller): 用户查询接口开发 二、规范的好处我们这样规范git commit到底有哪些好处呢？1.便于程序员对提交历史进行追溯，了解发⽣了什么情况。2.一旦约束了commit message，意味着我们将慎重的进行每一次提交，不能再一股脑的把各种各样的改动都放在一个git commit里面，这样一来整个代码改动的历史也将更加清晰。3.格式化的commit message才可以用于自动化输出Change log。 三、标准执行监管为了更好的执行标准，公司针对git提交会进行相关监管功能的研发，当工程师提了不合规的commit，会收到相关的邮件警告。","categories":[{"name":"git","slug":"git","permalink":"https://smartxia.github.io/blog/categories/git/"}],"tags":[]},{"title":"前端-npm私有源加载平台","slug":"前端知识/前端-npm私有源加载平台","date":"2020-09-01T09:30:06.000Z","updated":"2024-03-12T03:55:12.897Z","comments":true,"path":"2020/09/01/前端知识/前端-npm私有源加载平台/","permalink":"https://smartxia.github.io/blog/2020/09/01/%E5%89%8D%E7%AB%AF%E7%9F%A5%E8%AF%86/%E5%89%8D%E7%AB%AF-npm%E7%A7%81%E6%9C%89%E6%BA%90%E5%8A%A0%E8%BD%BD%E5%B9%B3%E5%8F%B0/","excerpt":"","text":"调研平台：sinopia，VerdaccioVerdaccio官方文档https://verdaccio.org/docs/en/configuration 搭建： 认证方式身份验证与您正在使用的auth 插件相关。软件包限制也由Package Access处理。 客户端：基于npm客户端登录后会生成一个配置令牌，在.npmrc中 https://docs.npmjs.com/files/npmrc 且允许匿名发布包 包发布的时候允许阻止访问和下载 服务端关于组的验证: ​ access: $all-&gt;​ publish: $all​ proxy: npmjs 不同的包读取权限限制： 1234567891011121314packages: &#x27;jquery&#x27;: access: $all publish: $all &#x27;my-company-*&#x27;: access: $all publish: $authenticated &#x27;@my-local-scope/*&#x27;: access: $all publish: $authenticated &#x27;**&#x27;: access: $all publish: $authenticated proxy: npmjs 组 定义： 12345678&#x27;company-*&#x27;: access: admin internal publish: admin proxy: server1&#x27;supersecret-*&#x27;: access: secret super-secret-area ultra-secret-area publish: secret ultra-secret-area proxy: server1","categories":[{"name":"前端知识","slug":"前端知识","permalink":"https://smartxia.github.io/blog/categories/%E5%89%8D%E7%AB%AF%E7%9F%A5%E8%AF%86/"}],"tags":[]},{"title":"其他-CRLF、CR、LF详解","slug":"Wiki/其他-CRLF、CR、LF详解","date":"2020-09-01T06:42:31.000Z","updated":"2024-03-12T03:55:12.871Z","comments":true,"path":"2020/09/01/Wiki/其他-CRLF、CR、LF详解/","permalink":"https://smartxia.github.io/blog/2020/09/01/Wiki/%E5%85%B6%E4%BB%96-CRLF%E3%80%81CR%E3%80%81LF%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"很长一段时间里，对于CRLF、CR、LF的理解仅限于不同操作系统下对换行符的定义。所谓知其然需知其所以然，从学习中找到乐趣，对知识的记忆才会更加深刻。 名词解释CR：Carriage Return，对应ASCII中转义字符\\r，表示回车LF：Linefeed，对应ASCII中转义字符\\n，表示换行CRLF：Carriage Return &amp; Linefeed，\\r\\n，表示回车并换行众所周知，Windows操作系统采用两个字符来进行换行，即CRLF；Unix&#x2F;Linux&#x2F;Mac OS X操作系统采用单个字符LF来进行换行；另外，MacIntosh操作系统（即早期的Mac操作系统）采用单个字符CR来进行换行。 野史老式机械打字机（来源：视觉中国）据野史记载，在很久以前的机械打字机时代，CR和LF分别具有不同的作用：LF会将打印纸张上移一行位置，但是保持当前打字的水平位置不变；CR则会将“Carriage”（打字机上的滚动托架）滚回到打印纸张的最左侧，但是保持当前打字的垂直位置不变，即还是在同一行。 当CR和LF组合使用时，则会将打印纸张上移一行，且下一个打字位置将回到该行的最左侧，也就是我们今天所理解的换行操作。 随着时间的推移，机械打字机渐渐地退出了历史舞台，当初的纸张变成了今天的显示器，打字机的按键也演变为了如今的键盘。在操作系统出现的年代，受限于内存和软盘空间的不足，一些操作系统的设计者决定采用单个字符来表示换行符，如Unix的LF、MacIntosh的CR。他们的意图都是为了进行换行操作，只是当初并没有一个国际标准（或者其他原因，鬼知道），所以才有这样字符上的不同。 结论许多现代的文本编辑器和命令行工具都提供了可选择的换行符配置，方便用户按照自己的意愿来改变换行符的表现形式，所以我们只需要知道CRLF、CR、LF的作用即可。 参考文献http://en.wikipedia.org/wiki/Newlinehttps://en.wikipedia.org/wiki/Control_characterhttps://stackoverflow.com/questions/1552749/difference-between-cr-lf-lf-and-cr-line-break-types 作者：JSoon链接：https://www.jianshu.com/p/b03ad01acd69来源：简书著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","categories":[{"name":"其他","slug":"其他","permalink":"https://smartxia.github.io/blog/categories/%E5%85%B6%E4%BB%96/"}],"tags":[]},{"title":"关于blog更新周期","slug":"我的日记/关于blog更新周期","date":"2020-08-31T02:22:54.000Z","updated":"2024-03-12T03:55:12.915Z","comments":true,"path":"2020/08/31/我的日记/关于blog更新周期/","permalink":"https://smartxia.github.io/blog/2020/08/31/%E6%88%91%E7%9A%84%E6%97%A5%E8%AE%B0/%E5%85%B3%E4%BA%8Eblog%E6%9B%B4%E6%96%B0%E5%91%A8%E6%9C%9F/","excerpt":"","text":"每周 三篇基础知识文档编写 每两周一次总结工作情况 每月一次的软件使用教程记录","categories":[{"name":"diary","slug":"diary","permalink":"https://smartxia.github.io/blog/categories/diary/"}],"tags":[]},{"title":"PHP-辅助函数","slug":"PHP/PHP-辅助函数","date":"2020-08-28T05:33:20.000Z","updated":"2024-03-12T03:55:12.846Z","comments":true,"path":"2020/08/28/PHP/PHP-辅助函数/","permalink":"https://smartxia.github.io/blog/2020/08/28/PHP/PHP-%E8%BE%85%E5%8A%A9%E5%87%BD%E6%95%B0/","excerpt":"","text":"","categories":[{"name":"PHP","slug":"PHP","permalink":"https://smartxia.github.io/blog/categories/PHP/"}],"tags":[]},{"title":"PHP-匿名类匿名函数（闭包）","slug":"PHP/PHP-匿名类匿名函数（闭包）","date":"2020-08-28T03:31:08.000Z","updated":"2024-03-12T03:55:12.844Z","comments":true,"path":"2020/08/28/PHP/PHP-匿名类匿名函数（闭包）/","permalink":"https://smartxia.github.io/blog/2020/08/28/PHP/PHP-%E5%8C%BF%E5%90%8D%E7%B1%BB%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0%EF%BC%88%E9%97%AD%E5%8C%85%EF%BC%89/","excerpt":"","text":"1.写一个匿名函数 类中 的写法 123456789101112131415161718//第一种写法 public function qq() &#123; $result = array_reduce([1, 2, 3, 4, 1], function ($result, $value) &#123; return array_merge($result, array_values($value)); &#125;, array()); return $result; &#125;//第二种写法 public function qq2() &#123; //将匿名函数交个一个变量 $a = function ($result, $value) &#123; return array_merge($result, array_values($value)); &#125;; $result = array_reduce([1, 2, 3, 4, 1], $a, array()); return $result; &#125; 2.理解一个闭包（匿名函数）目前php用到闭包的数组函数包括： 1234567891011121314array_map — 为数组的每个元素应用回调函数array_walk — 使用用户自定义函数对数组中的每个元素做回调处理array_reduce — 用回调函数迭代地将数组简化为单一的值array_filter — 用回调函数过滤数组中的单元该函数把输入数组中的每个键值传给回调函数。如果回调函数返回 true，则把输入数组中的当前键值返回结果数组中。数组键名保持不变。array_intersect_uassoc — 带索引检查计算数组的交集，用回调函数比较索引array_intersect_ukey — 用回调函数比较键名来计算数组的交集array_reduce — 用回调函数迭代地将数组简化为单一的值拼接成类似 (1,2,3,4,5) array_walk_recursive — 对数组中的每个成员递归地应用用户函数----等等常用的就是: array_map array_walk 3.临时总结异同点 array_filter() 重点在于过滤（而不是新增）某个元素，当你处理到一个元素时，返回过滤后的数组 array_map() 重点在于遍历一个数组或多个数组的元素，返回一个新的数组 array_walk() 重点在于遍历数组进行某种操作 array_filter() 和 array_walk()对一个数组进行操作，数组参数在前，函数参数在后 array_map() 可以处理多个数组，因此函数参数在前，数组参数在后，可以根据实际情况放入多个数组参数","categories":[{"name":"PHP","slug":"PHP","permalink":"https://smartxia.github.io/blog/categories/PHP/"}],"tags":[{"name":"Closure","slug":"Closure","permalink":"https://smartxia.github.io/blog/tags/Closure/"},{"name":"匿名函数","slug":"匿名函数","permalink":"https://smartxia.github.io/blog/tags/%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0/"},{"name":"匿名类","slug":"匿名类","permalink":"https://smartxia.github.io/blog/tags/%E5%8C%BF%E5%90%8D%E7%B1%BB/"}]},{"title":"PHP-运行模式cli fastcgi","slug":"PHP/PHP-运行模式","date":"2020-08-28T03:31:08.000Z","updated":"2024-03-12T03:55:12.847Z","comments":true,"path":"2020/08/28/PHP/PHP-运行模式/","permalink":"https://smartxia.github.io/blog/2020/08/28/PHP/PHP-%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"1.cgi全称“通用网关接口”(Common Gateway Interface)， 它可以让一个客户端，从浏览器向Web服务器上的程序请求数据，是客户端和程序之间传输数据的一种标准，另外CGI独立于任何语言，所以可以用任何一种语言编写，只要这种语言具有标准输入、输出和环境变量。如php,perl,tcl等。CGI针对每个用户请求都要开单独的子进程去维护，执行结束处理掉这个进程。典型的fork-and-execute方式 2.fastcgi，根据1中cgi的特性，可以知道消耗很大，如果很多用户请求，则会申请很多个子进程。。这时候出现了FastCGI。FastCGI 像是一个常驻 (long-live) 型的 CGI，它可以一直执行着，只要激活后，不会每次都要花费时间去 fork 一次 (这是 CGI 最为人诟病的 fork-and-execute 模式)。这个是当下用的最多的了。。linux+nginx+php+mysql FastCGI的工作原理是： (1)、Web Server启动时载入FastCGI进程管理器【PHP的FastCGI进程管理器是PHP-FPM(php-FastCGI Process Manager)】（nginx);(2)、FastCGI进程管理器自身初始化，启动多个CGI解释器进程 (在任务管理器中可见多个php-cgi.exe)并等待来自WebServer的连接。(3)、当客户端请求到达Web Server时，FastCGI进程管理器选择并连接到一个CGI解释器。Web server将CGI环境变量和标准输入发送到FastCGI子进程php-cgi。(4)、FastCGI子进程完成处理后将标准输出和错误信息从同一连接返回Web Server。当FastCGI子进程关闭连接时，请求便告处理完成。FastCGI子进程接着等待并处理来自FastCGI进程管理器（运行在 WebServer中）的下一个连接。在正常的CGI模式中，php-cgi或 .exe在此便退出了。在CGI模式中，你可以想象 CGI通常有多慢。每一个Web请求PHP都必须重新解析php.ini、重新载入全部dll扩展并重初始化全部数据结构。使用FastCGI，所有这些都只在进程启动时发生一次。一个额外的好处是，持续数据库连接(Persistent database connection)可以工作。 3.module形式一般用于apache，模块模式是以mod_php5模块的形式集成，此时mod_php5模块的作用是接收Apache传递过来的PHP文件请求，并处理这些请求，然后将处理后的结果返回给Apache。 4.cli模式。命令行执行php，一般不用。我们在linux下经常使用 “php -m”查找PHP安装了那些扩展就是PHP命令行运行模式；也可以直接命令行执行php xxx.php 1.php一共分为五大运行模式：包括ducgi 、fast-cgi、cli、isapi、apache 模块的 DLLCGI 关于PHP目前比较常见的五大运行模式： 1）CGI（通用网关接口&#x2F; Common Gateway Interface）2）FastCGI（常驻型CGI &#x2F; Long-Live CGI）3）CLI（命令行运行 &#x2F; Command Line Interface）4）LoadModule（Apache独有）：在Apache配置文件httpd.conf里，通常加的LoadModule php7_module “D:&#x2F;…&#x2F;php71&#x2F;php7apache2_4.dll”起到的作用就是这个5）ISAPI（Internet Server Application Program Interface）IIS独有：备注：在PHP5.3以后，PHP不再有ISAPI模式，安装后也不再有php5isapi.dll这个文件。要在IIS6上使用高版本PHP，必须安装FastCGI 扩展，然后使IIS6支持FastCGI。 2、php-cli 与php-fpm（fastcgi process manager） cli 模式就是常见的命令使用的php命令，其实他也可以提供http请求服务，内置了http服务器fpm 是一个多进程架构的FastCgi 服务，内置PHP解释器进程常驻后台，自带进程管理支持进程池配置和配置Nginx使用 cli 和fpm 是两个运行方式","categories":[{"name":"PHP","slug":"PHP","permalink":"https://smartxia.github.io/blog/categories/PHP/"}],"tags":[{"name":"cgi","slug":"cgi","permalink":"https://smartxia.github.io/blog/tags/cgi/"},{"name":"fastcgi","slug":"fastcgi","permalink":"https://smartxia.github.io/blog/tags/fastcgi/"},{"name":"cli","slug":"cli","permalink":"https://smartxia.github.io/blog/tags/cli/"}]},{"title":"PHP-理解php的Generator,yield,Iterator接口","slug":"PHP/PHP-理解php的Generator,yield,Iterator接口","date":"2020-08-28T03:21:32.000Z","updated":"2024-03-12T03:55:12.846Z","comments":true,"path":"2020/08/28/PHP/PHP-理解php的Generator,yield,Iterator接口/","permalink":"https://smartxia.github.io/blog/2020/08/28/PHP/PHP-%E7%90%86%E8%A7%A3php%E7%9A%84Generator,yield,Iterator%E6%8E%A5%E5%8F%A3/","excerpt":"","text":"等待更新yield解决读取大文","categories":[{"name":"PHP","slug":"PHP","permalink":"https://smartxia.github.io/blog/categories/PHP/"}],"tags":[{"name":"Generator","slug":"Generator","permalink":"https://smartxia.github.io/blog/tags/Generator/"},{"name":"yield","slug":"yield","permalink":"https://smartxia.github.io/blog/tags/yield/"},{"name":"Iterator - 等待更新","slug":"Iterator-等待更新","permalink":"https://smartxia.github.io/blog/tags/Iterator-%E7%AD%89%E5%BE%85%E6%9B%B4%E6%96%B0/"}]},{"title":"其他-server酱打卡网易云","slug":"Wiki/其他-Server酱打卡网易云 小技巧","date":"2020-08-26T01:57:49.000Z","updated":"2024-03-12T03:55:12.871Z","comments":true,"path":"2020/08/26/Wiki/其他-Server酱打卡网易云 小技巧/","permalink":"https://smartxia.github.io/blog/2020/08/26/Wiki/%E5%85%B6%E4%BB%96-Server%E9%85%B1%E6%89%93%E5%8D%A1%E7%BD%91%E6%98%93%E4%BA%91%20%E5%B0%8F%E6%8A%80%E5%B7%A7/","excerpt":"","text":"等待更新","categories":[{"name":"其他","slug":"其他","permalink":"https://smartxia.github.io/blog/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"网易云 server酱 py 云函数  待更新","slug":"网易云-server酱-py-云函数-待更新","permalink":"https://smartxia.github.io/blog/tags/%E7%BD%91%E6%98%93%E4%BA%91-server%E9%85%B1-py-%E4%BA%91%E5%87%BD%E6%95%B0-%E5%BE%85%E6%9B%B4%E6%96%B0/"}]},{"title":"Docker-info","slug":"DOCKER/Docker-制作-1","date":"2020-08-20T09:18:43.000Z","updated":"2024-03-12T03:55:12.804Z","comments":true,"path":"2020/08/20/DOCKER/Docker-制作-1/","permalink":"https://smartxia.github.io/blog/2020/08/20/DOCKER/Docker-%E5%88%B6%E4%BD%9C-1/","excerpt":"","text":"注册登录https://hub.docker.com/ Docker快捷键 常用： start restart stop images ps-a 带有参数的使用docker ps -a ：查看最近使用的容器id docker rm 容器id:删除某个容器 docker images docker rmi 镜像id:删除某个镜像 docker run : docker run -d -p 9200:9200 -p 5601:5601 nshou&#x2F;elasticsearch-kibana -d 后台运行，-p 内部端口&#x2F;宿主机端口 容器id docker exec -it &#x2F;bash :进入容器 docker login -u xx -p xxx：登录 配置加速源1.阿里云：百度如何通过阿里云加速docker拉取和推送速度 2.DaoCloud ：大公司，国内的。网站：https://www.daocloud.io/mirror 加速url 1Linux:curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://f1361db2.m.daocloud.io 原理：编辑 &#x2F;etc&#x2F;docker&#x2F;daemon.json 这个文件夹 1&#123;&quot;registry-mirrors&quot;: [&quot;http://f1361db2.m.daocloud.io&quot;,&quot;https://vbw6t0eb.mirror.aliyuncs.com&quot;]&#125; 查看当前docker配置文件docker info :可以查看是否配置成功加速 版本信息等各种信息 打包镜像源和推送到docker.io1.docker pull xxx镜像:tag 2.docker images 查看镜像 3.docker run -d -p 8080:8081 xxx镜像:version 4.docker ps -a 查看是不是启动了，然后stop start restart 找找感觉 5.docker exec -it 镜像id bash :进入镜像进行修改：拉代码，查bug ,增加mysql实例等 6.docker commit -m “php71-daemon:xhprof-graphviz” -a “some” f69187b4375e “18260356308&#x2F;php71-daemon:xhprof” ​ docker commit -m “提交log” -a “作者” 容器id “docker账户名&#x2F;自定义镜像名：tag” 就会制作成一个新的image了 7.执行docker push xxx镜像的id： tips: 前提是得登录，还有 注意一个问题,给自己镜像命名的时候格式应该是: docker注册用户名&#x2F;镜像名,比如我的docker用户名为 test123,那么我的镜像tag就为 test123&#x2F;whalesay,不然是push不上去的","categories":[{"name":"DOCKER","slug":"DOCKER","permalink":"https://smartxia.github.io/blog/categories/DOCKER/"}],"tags":[{"name":"docekr images","slug":"docekr-images","permalink":"https://smartxia.github.io/blog/tags/docekr-images/"}]},{"title":"PHP-xhprof-性能优化","slug":"PHP/PHP-xhprof-性能优化","date":"2020-08-20T09:16:14.000Z","updated":"2024-03-12T03:55:12.843Z","comments":true,"path":"2020/08/20/PHP/PHP-xhprof-性能优化/","permalink":"https://smartxia.github.io/blog/2020/08/20/PHP/PHP-xhprof-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","excerpt":"","text":"简介 安装 嵌入代码 查看分析报告 总结 名词解释Function Name：方法名称。 Calls：方法被调用的次数。 Calls%：方法调用次数在同级方法总数调用次数中所占的百分比。 Incl.Wall Time(microsec)：方法执行花费的时间，包括子方法的执行时间。（单位：微秒） IWall%：方法执行花费的时间百分比。 Excl. Wall Time(microsec)：方法本身执行花费的时间，不包括子方法的执行时间。（单位：微秒） EWall%：方法本身执行花费的时间百分比。 Incl. CPU(microsecs)：方法执行花费的CPU时间，包括子方法的执行时间。（单位：微秒） ICpu%：方法执行花费的CPU时间百分比。 Excl. CPU(microsec)：方法本身执行花费的CPU时间，不包括子方法的执行时间。（单位：微秒） ECPU%：方法本身执行花费的CPU时间百分比。 Incl.MemUse(bytes)：方法执行占用的内存，包括子方法执行占用的内存。（单位：字节） IMemUse%：方法执行占用的内存百分比。 Excl.MemUse(bytes)：方法本身执行占用的内存，不包括子方法执行占用的内存。（单位：字节） EMemUse%：方法本身执行占用的内存百分比。 Incl.PeakMemUse(bytes)：Incl.MemUse峰值。（单位：字节） IPeakMemUse%：Incl.MemUse峰值百分比。 Excl.PeakMemUse(bytes)：Excl.MemUse峰值。单位：（字节） EPeakMemUse%：Excl.MemUse峰值百分比。","categories":[{"name":"PHP","slug":"PHP","permalink":"https://smartxia.github.io/blog/categories/PHP/"}],"tags":[{"name":"xhprof docker push","slug":"xhprof-docker-push","permalink":"https://smartxia.github.io/blog/tags/xhprof-docker-push/"}]},{"title":"GOLANG-笔记-ArrayMapSlice","slug":"GOLANG/GOLANG-笔记2-ArrayMapSlice","date":"2020-06-29T11:17:32.000Z","updated":"2024-03-12T03:55:12.820Z","comments":true,"path":"2020/06/29/GOLANG/GOLANG-笔记2-ArrayMapSlice/","permalink":"https://smartxia.github.io/blog/2020/06/29/GOLANG/GOLANG-%E7%AC%94%E8%AE%B02-ArrayMapSlice/","excerpt":"","text":"1.golang 数据类型1、基本数据类型：整形、浮点、布尔、字符串、字符2、复合数据类型：函数与指针、数组、切片、map、list、结构体、通道 1.1 函数与指针函数：func（）指针：* 代表指针 &amp; 去地址符 （引用传值） *可以表示一个变量是指针类型 , 也可以表示一个指针变量所指向的存储单元 , 也就是这个地址所存储的值 .打印 *类型数据获取的一堆2进制数据 &amp;对变量取地址 即取得某个变量的地址 , 如 ; &amp;a 1.2数组Array(数组)数组是很有价值的数据结构，因为它的内存分配是连续的，内存连续意味着可是让它在 CPU 缓存中待更久，所以迭代数组和移动元素都会非常迅速。 数组所有 的key 都是int 默认从0 开始，string类型的是map和list其他，不建议使用数组，一般直接上切片 var 变量名 [数组长度]数据类型123456789101112131415161718192021 var a [4]int println(a) d := [3]int&#123;1, 2, 4&#125; println(d) f := [...]int&#123;1, 2, 4, 5, 6&#125; //... 省略数组长度 自动计算 println(f) a2 := [...]int&#123;1, 2, 4: 5, 6&#125; println(a2) for key, val := range a2 &#123; println(key,val) &#125; // 二维数组赋值 var arrayarr = [3][4]int&#123;&#123;1, 2, 3, 4&#125;, &#123;5, 6, 7, 8&#125;, &#123;9, 10, 11, 12&#125;&#125; dd := [...][...]string&#123; &#123;&quot;3&quot;, &quot;4&quot;&#125;, &#123;&quot;c&quot;, &quot;2&quot;&#125;, &#125; println(dd) println(arrayarr) 补充一个很恶心的代码12345678910//补充一种确定下标的数组声明及定义方式：func testArray04()&#123; //a1数组下标0的没有定义，默认为0，下标1的是2，下标2的是3， a1 := [...]int&#123;2:3,1:2&#125; //这边的2 是key 打印按照key来打印 fmt.Println(a1) //[0 2 3] //a2数组下标4定义为5，之前下标2和3未定义，默认为0 a2 := [...]int&#123;1,2,4:5,6&#125; fmt.Println(a2) //[1 2 0 0 5 6]&#125; 1.3 Map(集合)Map 是一种无序的键值对的集合。Map 最重要的一点是通过 key 来快速检索数据，key 类似于索引，指向数据的值。Map 是一种集合，所以我们可以像迭代数组和切片那样迭代它。不过，Map 是无序的，我们无法决定它的返回顺序，这是因为 Map 是使用 hash 表来实现的。 声明： m :&#x3D; make(map[string]string) 123456789101112131415161718ff := map[string]string&#123; &quot;a&quot;: &quot;c&quot;, &#125; var keys []string for k := range m &#123; keys = append(keys, k) //append 直接在切片级别进行描述 &#125; for s, s2 := range ff &#123; println(s,s2) &#125;ff := map[string]string&#123; &quot;a&quot;: &quot;c&quot;,&#125; fff:=make(map[string]int) //直接声明不加参数 ff[&quot;cc&quot;]=&quot;cccc&quot;;//赋值 delete(ff,&quot;cc&quot;) 1.4切片1.5 结构体定义切片:你可以声明一个未指定大小的数组来定义切片： 1var identifier []type//未定义大小的数组即切片 或使用 make() 函数来创建切片: 1slice1 := make([]type, len) //make([]T, length, capacity) append 和copy 浅拷贝 123456var numbers []intnumbers = append(numbers, 0)//append追加 /* 同时添加多个元素 */numbers = append(numbers, 2,3,4) /* 拷贝 numbers 的内容到 numbers1 */copy(numbers1,numbers) 1.6 List（链表）遍历 1234567891011121314151617// 声明链表l := list.New()// 数据添加到尾部l.PushBack(4)l.PushBack(5)l.PushBack(6)// 遍历for e := l.Front(); e != nil; e = e.Next() &#123; fmt.Printf(&quot;%v\\n&quot;, e.Value)&#125; l := list.New() l.PushBack(4) six := l.PushBack(6) l.Remove(six) // 删除6这个节点 1.6 通道 其他文章会有详细讲述 2总结数组是 slice 和 map 的底层结构。slice 是 Go 里面惯用的集合数据的方法，map 则是用来存储键值对。内建函数 make 用来创建 slice 和 map，并且为它们指定长度和容量等等。slice 和 map 字面值也可以做同样的事。slice 有容量的约束，不过可以通过内建函数 append 来增加元素。map 没有容量一说，所以也没有任何增长限制。内建函数 len 可以用来获得 slice 和 map 的长度。内建函数 cap 只能作用在 slice 上。可以通过组合方式来创建多维数组和 slice。map 的值可以是 slice 或者另一个 map。slice 不能作为 map 的键。在函数之间传递 slice 和 map 是相当廉价的，因为他们不会传递底层数组的拷贝。","categories":[{"name":"GOLANG","slug":"GOLANG","permalink":"https://smartxia.github.io/blog/categories/GOLANG/"}],"tags":[{"name":"Slice","slug":"Slice","permalink":"https://smartxia.github.io/blog/tags/Slice/"}]},{"title":"PHP-SPL(数据结构)","slug":"PHP/PHP-SPL(数据结构)","date":"2020-06-23T10:04:39.000Z","updated":"2024-03-12T03:55:12.827Z","comments":true,"path":"2020/06/23/PHP/PHP-SPL(数据结构)/","permalink":"https://smartxia.github.io/blog/2020/06/23/PHP/PHP-SPL(%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84)/","excerpt":"","text":"php SPL四种常用的数据结构1.栈【先进后出】 123456789&lt;span style=&quot;font-size:18px;&quot;&gt;$stack = new SplStack();$stack-&gt;push(&#x27;data1&#x27;);$stack-&gt;push(&#x27;data2&#x27;);$stack-&gt;push(&#x27;data3&#x27;);echo $stack-&gt;pop(); //输出结果为//data3&lt;/span&gt;&lt;span style=&quot;font-size:24px;font-weight: bold;&quot;&gt;&lt;/span&gt; 2.队列【先进先出 后进后出】 1234567&lt;span style=&quot;font-size:18px;&quot;&gt;$queue = new SplQueue();$queue-&gt;enqueue(&quot;data1&quot;);$queue-&gt;enqueue(&quot;data2&quot;);$queue-&gt;enqueue(&quot;data3&quot;);echo $queue-&gt;dequeue();//输出结果为//data1&lt;/span&gt; 3.堆 123456&lt;span style=&quot;font-size:18px;&quot;&gt;$heap = new SplMinHeap();$heap-&gt;insert(&quot;data1&quot;);$heap-&gt;insert(&quot;data2&quot;);echo $heap-&gt;extract();//输出结果为//data1&lt;/span&gt; 4.固定尺寸数组 1234567891011&lt;span style=&quot;font-size:18px;&quot;&gt;$array = new SplFixedArray(5);$array[0]=1;$array[3]=3;$array[2]=2;var_dump($array);//输出结果为// object(SplFixedArray)[1]// public 0 =&gt; int 1// public 1 =&gt; null// public 2 =&gt; int 2// public 3 =&gt; int 3 ————————————————推荐学习：http://www.imooc.com/video/4849原文链接：https://blog.csdn.net/zhengwish/article/details/51742264","categories":[{"name":"PHP","slug":"PHP","permalink":"https://smartxia.github.io/blog/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://smartxia.github.io/blog/tags/PHP/"},{"name":"数据结构","slug":"数据结构","permalink":"https://smartxia.github.io/blog/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"PHP-use","slug":"PHP/PHP-Use-使用场景","date":"2020-06-23T10:04:39.000Z","updated":"2024-03-12T03:55:12.827Z","comments":true,"path":"2020/06/23/PHP/PHP-Use-使用场景/","permalink":"https://smartxia.github.io/blog/2020/06/23/PHP/PHP-Use-%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/","excerpt":"","text":"php use用法 1、user namespace2、use 一个trait针对于trait的即多继承 12345678910trait A&#123; eat()&#125; trait B&#123; drink()&#125; class C &#123; use A; use B; &#125;public Class D&#123;d=new Class C()d-&gt;eat();&#125; 当不同的trait中，却有着同名的方法或属性，会产生冲突，可以使用insteadof或 as进行解决，insteadof 是进行替代，而as是给它取别名 123456use trait1,trait2&#123; trait1::eat insteadof trait2; trait1::drive insteadof trait2; trait2::eat as eaten; trait2::drive as driven; &#125; 3.闭包-&gt;匿名函数好处：节省内存 适合做回调函数 匿名函数：定义时未定义函数的名称闭包： 创建时封装周围状态的函数，及时周围的环境不存在了，闭包中的状态还会存在 使用法则：","categories":[{"name":"PHP","slug":"PHP","permalink":"https://smartxia.github.io/blog/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://smartxia.github.io/blog/tags/PHP/"},{"name":"USE","slug":"USE","permalink":"https://smartxia.github.io/blog/tags/USE/"}]},{"title":"PHP-strlen与mb_strlen","slug":"PHP/PHP-strlen与mb-strlen","date":"2020-06-22T11:11:39.000Z","updated":"2024-03-12T03:55:12.827Z","comments":true,"path":"2020/06/22/PHP/PHP-strlen与mb-strlen/","permalink":"https://smartxia.github.io/blog/2020/06/22/PHP/PHP-strlen%E4%B8%8Emb-strlen/","excerpt":"","text":"在PHP中，strlen与mb_strlen是求字符串长度的函数PHP内置的字符串长度函数strlen无法正确处理中文字符串，它得到的只是字符串所占的字节数。对于GB2312的中文编码，strlen得到的值是汉字个数的2倍，而对于UTF-8编码的中文，就是3倍（在 UTF-8编码下，一个汉字占3个字节）。 采用mb_strlen函数可以较好地解决这个问题。mb_strlen的用法和strlen类似，只不过它有第二个可选参数用于指定字符编码。例如得到UTF-8的字符串str长度，可以用mbstrlen(str长度，可以用mbstrlen(str,‘UTF-8’)。如果省略第二个参数，则会使用PHP的内部编码。内部编码可以通过 mb_internal_encoding()函数得到。 需要注意的是，mb_strlen并不是PHP核心函数，使用前需要确保在php.ini中加载了php_mbstring.dll，即确保“extension&#x3D;php_mbstring.dll”这一行存在并且没有被注释掉，否则会出现未定义函 数的问题。 在strlen计算中，对待一个UTF8的中文字符，处理为3个字节长度，所以为3+1+2+1+9&#x3D;16个 当mb_strlen的内码选择为UTF-8的时候，则会将中文字符当成一个字符,所以为3+1+2+1+3&#x3D;10; 当mb_strlen的内码选择为gbk的时候，一个中文字符当成1.5个字符来处理来处理,最后就是:3+1+2+1+4.5&#x3D;11.5 函数：mb_internal_encoding()会得到当前PHP使用的内部编码 strlen,得到的是字符串所占的字节数，所以在查看一个字符串的长度的时候，strlen并不能得到我们需要的真实值 mb_strlen 函数可以很好的处理这一点 注意：mb_strlen函数并不是php的核心函数，只是PHP的一个扩展函数，使用之前要判断是否加在的mbstring扩展模块，在Php.ini文件中可以查看相关配置 strlen结果为什么是4strlen在遇到第一个\\0时结束，后面的字符无视。","categories":[{"name":"PHP","slug":"PHP","permalink":"https://smartxia.github.io/blog/categories/PHP/"}],"tags":[{"name":"strlen","slug":"strlen","permalink":"https://smartxia.github.io/blog/tags/strlen/"}]},{"title":"其他-科学上网","slug":"Wiki/其他-科学上网","date":"2020-06-22T07:57:49.000Z","updated":"2024-03-12T03:55:12.872Z","comments":true,"path":"2020/06/22/Wiki/其他-科学上网/","permalink":"https://smartxia.github.io/blog/2020/06/22/Wiki/%E5%85%B6%E4%BB%96-%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/","excerpt":"","text":"解决System.Reflection.TargetInvocationException: 调用的目标发生了异常。 windows7系统运行没有问题，但是放到Windows10 上面就出现连接不上的问题，试了很多种方法还是这种解决了。 问题： System.Reflection.TargetInvocationException: 调用的目标发生了异常。 —&gt; System.Reflection.TargetInvocationException: 调用的目标发生了异常。 —&gt; System.InvalidOperationException: 此实现不是 Windows 平台 FIPS 验证的加密算法的一部分 解决办法：需要修改注册表,cmd命令，输入regedit打开注册表然后找到以下路径 KEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Lsa\\FipsAlgorithmPolicy 修改此路径下的Enable值为1，然后重新打开shadowsocks，大功告成！记得重启ssr （如果1不行那就切换成0） ————————————————原文链接：https://blog.csdn.net/qq_27536941/article/details/103300646","categories":[{"name":"其他","slug":"其他","permalink":"https://smartxia.github.io/blog/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"ssr","slug":"ssr","permalink":"https://smartxia.github.io/blog/tags/ssr/"}]},{"title":"PHP-异常类","slug":"PHP/PHP-异常类","date":"2020-06-22T03:27:10.000Z","updated":"2024-03-12T03:55:12.844Z","comments":true,"path":"2020/06/22/PHP/PHP-异常类/","permalink":"https://smartxia.github.io/blog/2020/06/22/PHP/PHP-%E5%BC%82%E5%B8%B8%E7%B1%BB/","excerpt":"","text":"PHP 异常与错误 —— ThrowableThrowable 官方文档地址： http://php.net/manual/en/class.throwable.php PHP 支持版本： 7 PHP7 异常与错误处理机制 Exception, Error, ThrowableThrowable 是 PHP 7 中可以用作任何对象抛出声明的基本接口，包括 Expection （异常）和 Error （错误）。 1234567891011121314151617181920Throwable &#123; /* 抽象方法 */ abstract public string getMessage ( void ) // 获取抛出的消息内容 abstract public int getCode ( void ) // 获取抛出的错误代码 abstract public string getFile ( void ) // 获取产生异常的文件名 abstract public int getLine ( void ) // 获取相关行号 abstract public array getTrace ( void ) // 获取追踪信息，返回数组形式 abstract public string getTraceAsString ( void ) // 获取追踪信息，返回字符串形式 abstract public Throwable getPrevious ( void ) // 返回上一个 Throwable abstract public string __toString ( void ) // 抛出的对象以字符串形式返回，可以用 echo 打印相应结果&#125; 请一定要注意，没有特殊说明：本例 PHP Version &lt; 7 说起 PHP 异常处理，大家首先会想到 try-catch，那好，我们先看一段程序吧：有一个 test.php 文件，有一段简单的 PHP 程序，内容如下，然后命令行执行：php test.php 1234567891 &lt;?php2 $num = 0;3 try &#123;4 echo 1/$num;56 &#125; catch (Exception $e)&#123;7 echo $e-&gt;getMessage();8 &#125;9 ?&gt; 我的问题是：这段程序能正确的捕捉到除 0 的错误信息吗？ 如果你回答能，那你就把这篇文章看完吧！应该能学点东西。 本文章分 5 个部分介绍我的异常处理的理解： 一、异常与错误的概述 二、ERROR 的级别 三、PHP 异常处理中的黑科技 四、巧妙的捕获错误和异常 五、自定义异常处理和异常嵌套 六、PHP7 中的异常处理 一、异常与错误的概述 PHP 中什么是异常： 程序在运行中出现不符合预期的情况，允许发生（你也不想让他出现不正常的情况）但他是一种不正常的情况，按照我们的正常逻辑本不该出的错误，但仍然会出现的错误，属于逻辑和业务流程的错误，而不是编译或者语法上的错误。 PHP 中什么是错误： 属于 php 脚本自身的问题，大部分情况是由错误的语法，服务器环境导致，使得编译器无法通过检查，甚至无法运行的情况。warning、notice 都是错误，只是他们的级别不同而已，并且错误是不能被 try-catch 捕获的。 上面的说法是有前提条件的： 在 PHP 中，因为在其他语言中就不能这样下结论了，也就是说异常和错误的说法在不同的语言有不同的说法。在 PHP 中任何自身的错误或者是非正常的代码都会当做错误对待，并不会以异常的形式抛出，但是也有一些情况会当做异常和错误同时抛出(据说是，我没有找到合适的例子)。也就是说，你想在数据库连接失败的时候自动捕获异常是行不通的，因为这就不是异常，是错误。但是在 java 中就不一样了，他会把很多和预期不一致的行为当做异常来进行捕获。 PHP 异常处理很鸡肋？ 在上面的分析中我们可以看出，PHP 并不能主动的抛出异常，但是你可以手动抛出异常，这就很无语了，如果你知道哪里会出问题，你添加 if else 解决不就行了吗，为啥还要手动抛出异常，既然能手动抛出就证明这个不是异常，而是意料之中。以我的理解，这就是 PHP 异常处理鸡肋的地方（不一定对啊）。所以 PHP 的异常机制不是那么的完美，但是使用过框架的同学都知道有这个情况：你在框架中直接写开头那段 php“自动”捕获异常的代码是可以的，这是为什么？看过源码的同学都知道框架中都会涉及三个函数：register_shutdown_function，set_error_handler，set_exception_handler 后面我会重点讲解着三个黑科技，通过这几个函数我们可以实现 PHP 假自动捕获异常和错误。 二、ERROR 的级别 只有熟悉错误级别才能对错误捕捉有更好的认识。 ERROR 有不同的错误级别，我之前的一篇文章中有写到：http://www.cnblogs.com/zyf-zhaoyafei/p/3649434.html 下面我再总结性的给出这几类错误级别： 1234567891011121314151617181 Fatal Error:致命错误（脚本终止运行）2 E_ERROR // 致命的运行错误，错误无法恢复，暂停执行脚本3 E_CORE_ERROR // PHP 启动时初始化过程中的致命错误4 E_COMPILE_ERROR // 编译时致命性错，就像由 Zend 脚本引擎生成了一个 E_ERROR5 E_USER_ERROR // 自定义错误消息。像用 PHP 函数 trigger_error（错误类型设置为：E_USER_ERROR）67 Parse Error：编译时解析错误，语法错误（脚本终止运行）8 E_PARSE //编译时的语法解析错误910 Warning Error：警告错误（仅给出提示信息，脚本不终止运行）11 E_WARNING // 运行时警告 (非致命错误)。12 E_CORE_WARNING // PHP 初始化启动过程中发生的警告 (非致命错误) 。13 E_COMPILE_WARNING // 编译警告14 E_USER_WARNING // 用户产生的警告信息1516 Notice Error：通知错误（仅给出通知信息，脚本不终止运行）17 E_NOTICE // 运行时通知。表示脚本遇到可能会表现为错误的情况.18 E_USER_NOTICE // 用户产生的通知信息。 由此可知有 5 类是产生 ERROR 级别的错误，这种错误直接导致 PHP 程序退出。 可以定义成： 1 ERROR &#x3D; E_ERROR | E_CORE_ERROR | E_COMPILE_ERROR | E_USER_ERROR | E_PARSE三、PHP 异常处理中的黑科技 前面提到框架中是可以捕获所有的错误和异常的，之所以能实现应该是使用了黑科技，哈哈！其实也不是什么黑科技，主要是三个重要的函数： 1：set_error_handler() 看到这个名字估计就知道什么意思了，这个函数用于捕获错误，设置一个用户自定义的错误处理函数。 12345671 &lt;?php2 set_error_handler(&#x27;zyferror&#x27;);3 function zyferror($type, $message, $file, $line)4 &#123;5 var_dump(&#x27;&lt;b&gt;set_error_handler: &#x27; . $type . &#x27;:&#x27; . $message . &#x27; in &#x27; . $file . &#x27; on &#x27; . $line . &#x27; line .&lt;/b&gt;&lt;br /&gt;&#x27;);6 &#125;7 ?&gt; 当程序出现错误的时候自动调用此方法，不过需要注意一下两点：第一，如果存在该方法，相应的 error_reporting()就不能在使用了。所有的错误都会交给自定义的函数处理。第二，此方法不能处理以下级别的错误：E_ERROR、 E_PARSE、 E_CORE_ERROR、 E_CORE_WARNING、 E_COMPILE_ERROR、 E_COMPILE_WARNING，set_error_handler() 函数所在文件中产生的 E_STRICT，该函数只能捕获系统产生的一些 Warning、Notice 级别的错误。 并且他有多种调用的方法： 12345671 &lt;?php2 // 直接传函数名 NonClassFunction3 set_error_handler(&#x27;function_name&#x27;);45 // 传 class_name &amp;&amp; function_name6 set_error_handler(array(&#x27;class_name&#x27;, &#x27;function_name&#x27;));7 ?&gt; 2：register_shutdown_function() 捕获 PHP 的错误：Fatal Error、Parse Error 等，这个方法是 PHP 脚本执行结束前最后一个调用的函数，比如脚本错误、die()、exit、异常、正常结束都会调用，多么牛逼的一个函数啊！通过这个函数就可以在脚本结束前判断这次执行是否有错误产生，这时就要借助于一个函数：error_get_last()；这个函数可以拿到本次执行产生的所有错误。error_get_last();返回的信息： [type] - 错误类型 [message] - 错误消息 [file] - 发生错误所在的文件 [line] - 发生错误所在的行 1234567891 &lt;?php2 register_shutdown_function(&#x27;zyfshutdownfunc&#x27;);3 function zyfshutdownfunc()4 &#123;5 if ($error = error_get_last()) &#123;6 var_dump(&#x27;&lt;b&gt;register_shutdown_function: Type:&#x27; . $error[&#x27;type&#x27;] . &#x27; Msg: &#x27; . $error[&#x27;message&#x27;] . &#x27; in &#x27; . $error[&#x27;file&#x27;] . &#x27; on line &#x27; . \\$error[&#x27;line&#x27;] . &#x27;&lt;/b&gt;&#x27;);7 &#125;8 &#125;9 ?&gt; 通过这种方法就可以巧妙的打印出程序结束前所有的错误信息。但是我在测试的时候我发现并不是所有的错误终止后都会调用这个函数，可以看下面的一个测试文件，内容是： 123456789101112131415161718191 &lt;?php2 register_shutdown_function(&#x27;zyfshutdownfunc&#x27;);3 function zyfshutdownfunc()4 &#123;5 if ($error = error_get_last()) &#123; 6 var_dump(&#x27;&lt;b&gt;register_shutdown_function: Type:&#x27; . $error[&#x27;type&#x27;] . &#x27; Msg: &#x27; . $error[&#x27;message&#x27;] . &#x27; in &#x27; . $error[&#x27;file&#x27;] . &#x27; on line &#x27; . \\$error[&#x27;line&#x27;] . &#x27;&lt;/b&gt;&#x27;);7 &#125;8 &#125;9 var_dump(23+-+); //此处语法错误10 ?&gt; 自己可以试一下，你可以看到根本就不会触发 zyfshutdownfunc()函数，其实这是一个语法错误，直接报了一个：1 &lt;?php2 Parse error: syntax error, unexpected &#x27;)&#x27; in /www/mytest/exception/try-catch.php on line 713 ?&gt; 由此引出一个奇葩的问题：问什么不能触发，为什么框架中是可以的？其实原因很简单，只在 parse-time 出错时是不会调用本函数的。只有在 run-time 出错的时候，才会调用本函数，我的理解是语法检查器前没有执行 register_shutdown_function()去把需要注册的函数放到调用的堆栈中，所以就根本不会运行。那框架中为什么任何错误都能进入到 register_shutdown_function()中呢，其实在框架中一般会有统一的入口 index.php，然后每个类库文件都会通过 include \\*\\* 的方式加载到 index.php 中，相当与所有的程序都会在 index.php 中聚集，同样，你写的具有语法错误的文件也会被引入到入口文件中，这样的话，调用框架，执行 index.php，index.php 本身并没有语法错误，也就不会产生 parse-time 错误，而是 include 文件出错了，是 run-time 的时候出错了，所以框架执行完之后就会触发 register_shutdown_function(); 所以现在可是试一下这个写法，这样就会触发 zyfshutdownfunc()回调了： 1 a.php 文件2 67 b.php 文件8 123 3：set_exception_handler() 设置默认的异常处理程序，用在没有用 try/catch 块来捕获的异常，也就是说不管你抛出的异常有没有人捕获，如果没有人捕获就会进入到该方法中，并且在回调函数调用后异常会中止。看一下用法： 1 getMessage() . ''); 6 } 7 throw new Exception(\"zyf exception\"); 8 ?> 1234四、巧妙的捕获错误和异常 1：把错误以异常的形式抛出(不能完全抛出) 由上面的讲解我们知道，php 中的错误是不能以异常的像是捕获的，但是我们需要让他们抛出，已达到扩展 try-catch 的影响范围，我们前面讲到过 set_error_handler() 方法，他是干嘛用的，他是捕获错误的，所以我们就可以借助他来吧错误捕获，然后再以异常的形式抛出，ok，试试下面的写法： 1 getMessage(); 14 } 15 ?> 123456789 好了，试一下，会打印出：1 Division by zero zyf123 流程：本来是除 0 错误，然后触发 set_error_handler()，在 set_error_handler()中相当与杀了个回马枪，再把错误信息以异常的形式抛出来，这样就可以实现错误以异常的形式抛出。大家要注意：这样做是有缺点的，会受到 set_error_handler()函数捕获级别的限制。 2：捕获所有的错误 由set_error_handler()可知，他能够捕获一部分错误，不能捕获系统级E_ERROR、E_PARSE等错误，但是这部分可以由register_shutdown_function()捕获。所以两者结合能出现很好的功能。 看下面的程序： 1 a.php 内容：2 21 b.php 内容：22 12345678 到此就可以解释开头的那个程序了吧，test.php 如果是单文件执行是不能捕获到错误的，如果你在框架中执行就是可以的，当然你按照我上面介绍的来扩展也是可以的。五、自定义异常处理和异常嵌套1：自定义异常处理在复杂的系统中，我们往往需要自己捕获我们需要特殊处理的异常，这些异常可能是特殊情况下抛出的。所以我们就自己定义一个异常捕获类，该类必须是 exception 类的一个扩展，该类继承了 PHP 的 exception 类的所有属性，并且我们可以添加自定义的函数，使用的时候其实和之前的一样，大致写法如下： 1 getLine().' in ' . $this->getFile() 7 .': ' . $this->getMessage() . ' Must in (0 - 60)'; 8 } 9 } 10 11 $age = 10; 12 try { 13 $age = intval($age); 14 if($age > 60) { 15 throw new zyfException($age); 16 } 17 18 } catch (zyfException $e) { 19 echo $e->errorzyfMessage(); 20 21 } 22 ?> 1234 2：异常嵌套异常嵌套是比较常见的写法，在自定义的异常处理中，try 块中可以定义多个异常捕获，然后分层传递异常，理解和冒泡差不多，看下面的实现： 1 60) { 6 throw new zyfException($age); 7 } 8 9 if ($age errorzyfMessage(); 15 16 } catch(Exception $e) { 17 echo \\$e->getMessage(); 18 } 19 ?> 12 当然也可以在 catch 中再抛出异常给上层： 1 60) { 7 throw new Exception($age); 8 } 9 10 } catch (Exception $e) { 11 throw new zyfException($age); 12 13 } 14 15 } catch (zyfException $e) { 16 echo \\$e->errorzyfMessage(); 17 } 18 ?> 123六、PHP7 中的异常处理 现在写 PHP 必须考虑版本情况，上面的写法在 PHP7 中大部分都能实现，但是也会有不同点，在 PHP7 更新中有一条：更多的 Error 变为可捕获的 Exception，现在的 PHP7 实现了一个全局的 throwable 接口，原来老的 Exception 和其中一部分 Error 实现了这个接口(interface)，PHP7 中更多的 Error 变为可捕获的 Exception 返回给捕捉器，这样其实和前面提到的扩展 try-catch 影响范围一样，但是如果不捕获则还是按照 Error 对待，看下面两个： 1 getMessage() . ' zyf'; 7 } 8 9 try { 10 test(); 11 12 } catch(Error $e) { 13 echo $e->getMessage() . ' zyf'; 14 } 15 ?> 因为 PHP7 实现了 throwable 接口，那么就可以使用第一个这种方式来捕获异常。又因为部分 Error 实现了接口，并且更多的 Error 变为可捕获的 Exception，那么就可以使用第二种方式来捕获异常。下面是在网上找的 PHP7 的异常层次树： Throwable Exception 异常 ... Error 错误 ArithmeticError 算数错误 DivisionByZeroError 除数为 0 的错误 AssertionError 声明错误 ParseError 解析错误 TypeError 类型错误 转载： http://www.cnblogs.com/zyf-zhaoyafei/p/6928149.html","categories":[{"name":"PHP","slug":"PHP","permalink":"https://smartxia.github.io/blog/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://smartxia.github.io/blog/tags/PHP/"},{"name":"异常","slug":"异常","permalink":"https://smartxia.github.io/blog/tags/%E5%BC%82%E5%B8%B8/"}]},{"title":"设计模式-工厂模式","slug":"设计模式/设计模式-简单工厂模式","date":"2020-06-19T02:57:29.000Z","updated":"2024-03-12T03:55:12.919Z","comments":true,"path":"2020/06/19/设计模式/设计模式-简单工厂模式/","permalink":"https://smartxia.github.io/blog/2020/06/19/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%AE%80%E5%8D%95%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"等待更新","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://smartxia.github.io/blog/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"待更新","slug":"待更新","permalink":"https://smartxia.github.io/blog/tags/%E5%BE%85%E6%9B%B4%E6%96%B0/"}]},{"title":"设计模式-工厂模式","slug":"设计模式/设计模式-抽象工厂模式","date":"2020-06-19T02:57:29.000Z","updated":"2024-03-12T03:55:12.918Z","comments":true,"path":"2020/06/19/设计模式/设计模式-抽象工厂模式/","permalink":"https://smartxia.github.io/blog/2020/06/19/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"等待更新","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://smartxia.github.io/blog/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"待更新","slug":"待更新","permalink":"https://smartxia.github.io/blog/tags/%E5%BE%85%E6%9B%B4%E6%96%B0/"}]},{"title":"http与rpc区别，以及如何使用rpc","slug":"HTTP/微服务-http与rpc区别，以及如何使用rpc","date":"2020-06-19T02:55:30.000Z","updated":"2024-03-12T03:55:12.825Z","comments":true,"path":"2020/06/19/HTTP/微服务-http与rpc区别，以及如何使用rpc/","permalink":"https://smartxia.github.io/blog/2020/06/19/HTTP/%E5%BE%AE%E6%9C%8D%E5%8A%A1-http%E4%B8%8Erpc%E5%8C%BA%E5%88%AB%EF%BC%8C%E4%BB%A5%E5%8F%8A%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8rpc/","excerpt":"","text":"HTTP就是一种RPC(Remote Procedure Call) ,http是七层iso模型，转换步骤多，且基于http有更多的报文 http好比普通话，rpc好比团伙内部黑话。只要是远程调用都可以叫RPC()，和是不是通过http没什么关系讲普通话，好处就是谁都听得懂，谁都会讲。讲黑话，好处是可以更精简、更加保密、更加可定制，坏处就是要求“说”黑话的那一方（client端）也要懂，而且一旦大家都说一种黑话了，换黑话就困难了。 首先 http 和 rpc 并不是一个并行概念。 rpc是远端过程调用，其调用协议通常包含传输协议和序列化协议。 传输协议包含: 如著名的 [gRPC](grpc &#x2F; grpc.io) 使用的 http2 协议，也有如dubbo一类的自定义报文的tcp协议。 序列化协议包含: 如基于文本编码的 xml json，也有二进制编码的 protobuf hessian等。 因此我理解的问题应该是：为什么要使用自定义 tcp 协议的 rpc 做后端进程通信？ 解决这个问题就应该搞清楚 http 使用的 tcp 协议，和我们自定义的 tcp 协议在报文上的区别。 首先要否认一点 http 协议相较于自定义tcp报文协议，增加的开销在于连接的建立与断开。http协议是支持连接池复用的，也就是建立一定数量的连接不断开，并不会频繁的创建和销毁连接。要说的是http也可以使用protobuf这种二进制编码协议对内容进行编码，因此二者最大的区别还是在传输协议上。 通用定义的http1.1协议的tcp报文包含太多废信息，一个POST协议的格式大致如下： 12345678910HTTP/1.0 200 OK Content-Type: text/plainContent-Length: 137582Expires: Thu, 05 Dec 1997 16:00:00 GMTLast-Modified: Wed, 5 August 1996 15:55:28 GMTServer: Apache 0.84&lt;html&gt; &lt;body&gt;Hello World&lt;/body&gt;&lt;/html&gt; 即使编码协议也就是body是使用二进制编码协议，报文元数据也就是header头的键值对却用了文本编码，非常占字节数。如上图所使用的报文中有效字节数仅仅占约 30%，也就是70%的时间用于传输元数据废编码。当然实际情况下报文内容可能会比这个长，但是报头所占的比例也是非常可观的。 那么假如我们使用自定义tcp协议的报文如下 报头占用的字节数也就只有16个byte，极大地精简了传输内容。 这也就是为什么后端进程间通常会采用自定义tcp协议的rpc来进行通信的原因 简单来说成熟的rpc库相对http容器，更多的是封装了“服务发现”，”负载均衡”，“熔断降级”一类面向服务的高级特性。可以这么理解，rpc框架是面向服务的更高级的封装。如果把一个http servlet容器上封装一层服务发现和函数代理调用，那它就已经可以做一个rpc框架了。 那http和rpc和websocket三者有什么关系呢？ Web Service 也提出了好久了, 那么究竟什么是 Web Service ? 简单地说, 也就是服务器如何向客户端提供服务. 常用的方法有: RPC 所谓的远程过程调用 (面向方法) SOA 所谓的面向服务的架构(面向消息) REST 所谓的 Representational state transfer (面向资源) 转载整理自：https://www.zhihu.com/question/41609070/answer/191965937","categories":[{"name":"HTTP","slug":"HTTP","permalink":"https://smartxia.github.io/blog/categories/HTTP/"}],"tags":[{"name":"rpc()","slug":"rpc","permalink":"https://smartxia.github.io/blog/tags/rpc/"}]},{"title":"GOLANG笔记1-基础数据类型","slug":"GOLANG/GOLANG-笔记1-基础数据类型","date":"2020-06-09T09:36:01.000Z","updated":"2024-03-12T03:55:12.819Z","comments":true,"path":"2020/06/09/GOLANG/GOLANG-笔记1-基础数据类型/","permalink":"https://smartxia.github.io/blog/2020/06/09/GOLANG/GOLANG-%E7%AC%94%E8%AE%B01-%E5%9F%BA%E7%A1%80%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","excerpt":"","text":"int 和 uintuint类型长度取决于 CPU，如果是32位CPU就是4个字节，如果是64位就是8个字节。我的电脑是64位的，而 playground 是32位的 int是带符号的，表示范围是：-2147483648到2147483648，即-2^31到2^31次方。 uint则是不带符号的，表示范围是：2^32即0到4294967295。 uint可以使用十进制，二进制，十六进制。和long,ulong,float,double,decimal等预定义可以进行隐式转换。但是需要注意值是否在可转换的范围内，不然会出现异常。 The Uint keyword signifies an integral type that stores calues according to the size and ranges shown in the following table. 关键字表示一种整型类型，该类型根据下表显示的大小和范围存储值。———————————————— golang数据类型：布尔类型true false 数字类型 整形 浮点型整形： 无符号：uint 8、uint 16、uint 32、uint 64、长度（0~2次方-1） 有符号：int 8、int 16、int 32、int 64、长度:例如int 8（负的2^7~2^7-1） 有无符号：没有符号位的数字只能有0和正值,有符号位的数字可以有正零,负零和正数负数. 浮点型：float（32单精度） float（64双精度） 序号 类型和描述 1 float32 IEEE-754 32位浮点型数 2 float64 IEEE-754 64位浮点型数 3 complex64 32 位实数和虚数 4 complex128 64 位实数和虚数 字符串类型派生类型派生类型: (a) 指针类型（Pointer） (b) 数组类型 (c) 结构化类型(struct) (d) Channel 类型 (e) 函数类型 (f) 切片类型 (g) 接口类型（interface） (h) Map 类型 虚数：https://www.ruanyifeng.com/blog/2012/09/imaginary_number.html 原文链接：https://blog.csdn.net/janny_flower/article/details/81082424","categories":[{"name":"GOLANG","slug":"GOLANG","permalink":"https://smartxia.github.io/blog/categories/GOLANG/"}],"tags":[]},{"title":"Go并发编程总结","slug":"GOLANG/Go并发编程总结","date":"2020-06-09T09:36:01.000Z","updated":"2024-03-12T03:55:12.823Z","comments":true,"path":"2020/06/09/GOLANG/Go并发编程总结/","permalink":"https://smartxia.github.io/blog/2020/06/09/GOLANG/Go%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E6%80%BB%E7%BB%93/","excerpt":"","text":"Golang :不要通过共享内存来通信，而应该****通过通信来共享内存****。这句风靡在Go社区的话,说的就是 goroutine中的 channel。他在go并发编程中充当着类型安全的管道作用。 1、通过golang中的 goroutine 与sync.Mutex进行 并发同步1234567891011121314151617181920212223242526272829303132333435package mainimport( &quot;fmt&quot; &quot;sync&quot; &quot;runtime&quot;)var count int = 0 //全局共享变量func counter(lock * sync.Mutex)&#123; //goroutinue执行函数 lock.Lock() count++ fmt.Println(count) lock.Unlock()&#125;func main()&#123; lock := &amp;sync.Mutex&#123;&#125; for i := 0; i &lt; 10; i++ &#123; //传递指针是为了防止 函数内的锁和 调用锁不一致 创建10个协程对count++ go counter(lock) &#125; for &#123; lock.Lock() c := count lock.Unlock() ///把时间片给别的goroutine 未来某个时刻运行该routine runtime.Gosched() if c &gt;=10 &#123; fmt.Println(&quot;goroutine end&quot;) break &#125; &#125;&#125; //输出结果：1 2 3 4 5 6 7 8 9 10 &quot;goroutine end&quot; 2、goroutine之间通过 channel进行通信,channel是和类型相关的 可以理解为 是一种类型安全的管道。1234567891011121314151617181920212223package mainimport &quot;fmt&quot;func Count(ch chan int) &#123; ch &lt;- 1 fmt.Println(&quot;Counting&quot;)&#125;func main() &#123; chs := make([]&lt;strong&gt;chan int&lt;/strong&gt;, 10) //[]chan int 表示是chan int类型的切片 和 chan []int区别 标识通道类型是[]int //c := make(chan []int) //t := []int&#123;1,2,3&#125; //c &lt;- t for i := 0; i &lt; 10; i++ &#123; chs[i] = make(chan int) go Count(chs[i]) //创建10个协程 fmt.Println(&quot;Count&quot;,i) &#125; for i, ch := range chs &#123; &lt;-ch fmt.Println(&quot;Counting&quot;,i) &#125;&#125; //调度的顺序不同，可能goroutinue执行的顺序不一样 3、Go语言中的select是语言级内置 非堵塞12345select &#123;case &lt;-chan1: // 如果chan1成功读到数据，则进行该case处理语句 case chan2 &lt;- 1: // 如果成功向chan2写入数据，则进行该case处理语句 default: // 如果上面都没有成功，则进入default处理流程 &#125; 可以看出，select不像switch，后面并不带判断条件，而是直接去查看case语句。每个case语句都必须是一个面向channel的操作。比如上面的例子中，第一个case试图从chan1读取一个数据并直接忽略读到的数据，而第二个case则是试图向chan2中写入一个整型数1，如果这两者都没有成功，则到达default语句。 4、channel 的带缓冲读取写入要创建一个带缓冲的channel，其实也非常容易： 1c := make(chan int, 1024) 在调用make()时将缓冲区大小作为第二个参数传入即可，比如上面这个例子就创建了一个大小为1024的int类型channel，即使没有读取方，写入方也可以一直往channel里写入，在缓冲区被填完之前都不会阻塞。 从带缓冲的channel中读取数据可以使用与常规非缓冲channel完全一致的方法，但我们也可以使用range关键来实现更为简便的循环读取： 123for i := range c &#123; fmt.Println(&quot;Received:&quot;, i)&#125; 5、用goroutine模拟生产消费者因为程序会****优先执行主线程，主线程执行完成后，程序会立即退出****，没有多余的时间去执行子线程。如果在程序的最后让主线程休眠1秒钟，那程序就会有足够的时间去执行子线程。 通道又叫channel，顾名思义，channel的作用就是在多线程之间传递数据的。 1234567891011121314151617181920212223242526272829303132333435363738394041chreadandwrite :=make(chan int)chonlyread := make(&lt;-chan int) //创建只读channel var read &lt;-chan int = chreadandwrite chonlywrite := make(chan&lt;- int) //创建只写channel var write chan&lt;- int = chreadandwrite package mainimport ( &quot;fmt&quot; &quot;time&quot;)func Producer(p chan&lt;- int) &#123; for i := 0; i &lt; 10; i++ &#123; p &lt;- i fmt.Println(&quot;send:&quot;, i) &#125;&#125;func Consumer(c &lt;-chan int) &#123; for i := 0; i &lt; 10; i++ &#123; v := &lt;-c fmt.Println(&quot;receive:&quot;, v) &#125;&#125;func main()&#123; queue := make(chan int) /*ch :=make(chan int) ch &lt;- 1 这个错误的意思是说线程陷入了死锁，程序无法继续往下执行。那么造成这种错误的原因是什么呢？&lt;span style=&quot;white-space:pre;&quot;&gt; &lt;/span&gt;我们创建了一个无缓冲的channel，然后给这个channel赋值了，程序就是在赋值完成后陷入了死锁。&lt;span style=&quot;white-space:pre;&quot;&gt; &lt;/span&gt;因为我们的channel是无缓冲的，即同步的，赋值完成后来不及读取channel，程序就已经阻塞了。 ===== 顺序执行满阻塞&lt;span style=&quot;white-space:pre;&quot;&gt; &lt;/span&gt;queue &lt;- 1&lt;span style=&quot;white-space:pre;&quot;&gt; &lt;/span&gt;queue &lt;- 2 //满阻塞 */ go Producer(queue) //开启协程执行函数单独去执行，主程序直接往下执行 //i = 0 的时候，写入阻塞 生产者和消费者是异步执行，消费者会去读取channel值。 go Consumer(queue) time.Sleep(1e9) //让Producer与Consumer完成&#125; 因为channel是没有缓冲的，所以当生产者给channel赋值后，生产者这个线程会阻塞，****直到消费者线程将channel中的数据取出****。消费者第一次将数据取出后，进行下一次循环时，消费者的线程也会阻塞，因为生产者还没有将数据存入，这时程序会去执行生产者的线程。程序就这样在消费者和生产者两个线程间不断切换，直到循环结束。 12345678910111213141516171819202122232425package mainimport ( &quot;fmt&quot; &quot;time&quot;)func produce(p chan&lt;- int) &#123; for i := 0; i &lt; 10; i++ &#123; p &lt;- i fmt.Println(&quot;send:&quot;, i) &#125;&#125;func consumer(c &lt;-chan int) &#123; for i := 0; i &lt; 10; i++ &#123; v := &lt;-c fmt.Println(&quot;receive:&quot;, v) &#125;&#125;func main() &#123; ch := make(chan int, 10) //带缓冲的例子 go produce(ch) go consumer(ch) time.Sleep(1 * time.Second)&#125; 在这个程序中，缓冲区可以存储10个int类型的整数，在执行生产者线程的时候，线程就不会阻塞，一次性将10个整数存入channel，在读取的时候，也是一次性读取。读取的话，没有数据就阻塞，有的话依次进行读取操作。 6、通过make 创建通道12make(c1 chan int) 创建的是 同步channel ...读写完全对应 先写满的话就会阻塞 顺序程序不会执行make(c1 chan int ,10) 创建带缓冲的通道 上来可以写10次 7、随机向通道中写入0或者112345678910111213141516171819202122package mainimport ( &quot;fmt&quot; &quot;time&quot;)func main()&#123; ch := make(chan int, 1) for i := 0; i &lt; 10; i++ &#123; ///不停向channel中随机写入 0 或者1 select &#123; case ch &lt;- 0: case ch &lt;- 1: &#125; //从通道中取出数据 i := &lt;-ch fmt.Println(&quot;Value received:&quot;,i) time.Sleep(1e8) &#125;&#125; 8、带缓冲的channel之前创建的都是不带缓冲的channel，这种做法对于传递单个数据的场景可以接受，但对于需要持续传输大量数据的场景就有些不合适了。接下来我们介绍如何给channel带上缓冲，从而达到消息队列的效果。 要创建一个带缓冲的channel，其实也非常容易： 1c := make(chan int, 1024) 在调用make()时将缓冲区大小作为第二个参数传入即可，比如上面这个例子就创建了一个大小为1024的int类型channel，即使没有读取方，写入方也可以一直往channel里写入，在缓冲区被填完之前都不会阻塞。 从带缓冲的channel中读取数据可以使用与常规非缓冲channel完全一致的方法，但我们也可以使用range关键来实现更为简便的循环读取： 12345678910111213141516171819202122232425262728for i := range c &#123; fmt.Println(&quot;Received:&quot;, i)&#125;package mainimport ( &quot;fmt&quot; &quot;time&quot;)func A(c chan int)&#123; for i:=0;i&lt;10;i++&#123; c&lt;- i &#125;&#125;func B(c chan int)&#123; for val:=range c &#123; fmt.Println(&quot;Value:&quot;,val) &#125;&#125;func main()&#123; chs:=make(chan int,10) //只要有通道操作一定要放到goroutine中否则会堵塞当前的主线程 并且导致程序退出 //对于同步通道 或者带缓冲的通道 一定要封装成函数 使用 goroutine 包装 go A(chs) go B(chs) time.Sleep(1e9)&#125; 9、关于创建多个goroutine具体到go语言会创建多少个线程12345678910111213141516171819package mainimport ( //&quot;fmt&quot; //&quot;time&quot; &quot;os&quot;)func main() &#123; for i:=0; i&lt;20; i++ &#123; go func() &#123; for &#123; b:=make([]byte, 10) os.Stdin.Read(b) // will block &#125; &#125;() &#125; select&#123;&#125;&#125; 会产生21个线程：runtime scheduler(src&#x2F;pkg&#x2F;runtime&#x2F;proc.c)会*维护一个线程池，当某个goroutine被block后，scheduler会创建一个新线程给其他ready的goroutine。*GOMAXPROCS控制的是未被阻塞的所有goroutine被multiplex到多少个线程上运行 10、在channel中也是可以传递channel的,Go语言的channel和map slice等一样都是原生类型1[]chan int chan int切片 chan []int 表示的是chan里面存的数据时[]int 需要注意的是，在Go语言中channel本身也是一个原生类型，与map之类的类型地位一样，因此channel本身在定义后也可以通过channel来传递。 我们可以使用这个特性来实现*nix上非常常见的管道（pipe）特性。管道也是使用非常广泛的一种设计模式，比如在处理数据时，我们可以采用管道设计，这样可以比较容易以插件的方式增加数据的处理流程。 下面我们****利用channel可被传递的特性来实现我们的管道****。 为了简化表达， 我们假设在管道中传递的数据只是一个整型数，在实际的应用场景中这通常会是一个数据块。 首先限定基本的数据结构： 12345type PipeData struct &#123; value int handler func(int) int next chan int&#125; 然后我们写一个常规的处理函数。我们只要定义一系列PipeData的数据结构并一起传递给 这个函数，就可以达到流式处理数据的目的： 12345func handle(queue chan *PipeData) &#123;for data := range queue &#123; data.next &lt;- data.handler(data.value) &#125;&#125; 11、我们默认创建的是双向通道,单向通道没有意义,但是我们却可以通过强制转换 将双向通道 转换成为单向通道123var ch1 chan int // ch1是一个正常的channel，不是单向的 var ch2 chan&lt;- float64// ch2是单向channel，只用于写float64数据var ch3 &lt;-chan int // ch3是单向channel，只用于读取int数据 channel是一个原生类型，因此不仅支持被传递，还支持类型转换。只有在介绍了单向channel的概念后，读者才会明白类型转换对于channel的意义：就是在单向channel和双向channel之间进行转换。 示例如下： 123ch4 := make(chan int)ch5 := &lt;-chan int(ch4) // ch5就是一个单向的读取channelch6 := chan&lt;- int(ch4) // ch6 是一个单向的写入channel 基于ch4，我们通过类型转换初始化了两个单向channel：单向读的ch5和单向写的ch6。 从设计的角度考虑，所有的代码应该都遵循”最小权限原则” ，从而避免没必要地使用泛滥问题， 进而导致程序失控。 写过C++程序的读者肯定就会联想起const 指针的用法。非const指针具备const指针的所有功能，将一个指针设定为const就是明确告诉 ****函数实现者不要试图对该指针进行修改。单向channel也是起到这样的一种契约作用****。下面我们来看一下单向channel的用法： 12345func Parse(ch &lt;-chan int) &#123;for value := range ch &#123; fmt.Println(&quot;Parsing value&quot;, value) &#125;&#125; 除非这个函数的实现者无耻地使用了类型转换，否则这个函数就不会因为各种原因而对ch 进行写，避免在ch中出现非期望的数据，从而很好地实践最小权限原则。 12、只读只写 单向 channel 代码例子 遵循权限最小化的原则12345678910111213141516171819202122package mainimport ( &quot;fmt&quot; &quot;time&quot;)//接受一个参数 是只允许读取通道 除非直接强制转换 要么你只能从channel中读取数据func sCh(ch &lt;-chan int)&#123; for val:= range ch &#123; fmt.Println(val) &#125;&#125;func main()&#123; //创建一个带100缓冲的通道 可以直接写入 而不会导致 主线程堵塞 dch:=make(chan int,100) for i:=0;i&lt;100;i++&#123; dch&lt;- i &#125; //传递进去 只读通道 go sCh(dch) time.Sleep(1e9)&#125; 13、channel的关闭,以及判断channel的关闭关闭channel非常简单，直接使用Go语言内置的close()函数即可： 1close(ch) 在介绍了如何关闭channel之后，我们就多了一个问题：如何判断一个channel是否已经被关闭？我们可以在读取的时候使用多重返回值的方式： 1x, ok := &lt;-ch 这个用法与map中的按键获取value的过程比较类似，只需要看第二个bool返回值即可，如果返回值是false则表示ch已经被关闭。 14、Go的多核并行化编程 高性能并发编程 必须设置GOMAXPROCS 为最大核数目 这个值由runtime.NumCPU()获取在执行一些昂贵的计算任务时， 我们希望能够尽量****利用现代服务器普遍具备的多核特性来尽量将任务并行化*，从而达到降低总计算时间的目的。此时我们需要了解*CPU核心的数量****，并针对性地分解计算任务到多个goroutine中去并行运行。 下面我们来模拟一个完全可以并行的计算任务：计算N个整型数的总和。我们可以将****所有整型数分成M份，M即CPU的个数****。让每个CPU开始计算分给它的那份计算任务，最后将每个CPU的计算结果再做一次累加，这样就可以得到所有N个整型数的总和： 12345678910111213141516171819202122type Vector []float64// 分配给每个CPU的计算任务func (v Vector) DoSome(i, n int, u Vector, c chan int) &#123;for ; i &lt; n; i++ &#123; v[i] += u.Op(v[i]) &#125; c &lt;- 1 // 发信号告诉任务管理者我已经计算完成了&#125;const NCPU = 16 // 假设总共有16核 func (v Vector) DoAll(u Vector) &#123; c := make(chan int, NCPU) // 用于接收每个CPU的任务完成信号 for i := 0; i &lt; NCPU; i++ &#123; go v.DoSome(i*len(v)/NCPU, (i+1)*len(v)/NCPU, u, c) &#125; // 等待所有CPU的任务完成 for i := 0; i &lt; NCPU; i++ &#123; &lt;-c // 获取到一个数据，表示一个CPU计算完成了 &#125;// 到这里表示所有计算已经结束&#125; 这两个函数看起来设计非常合理。****DoAll()会根据CPU核心的数目对任务进行分割*，然后开辟多个goroutine来并行执行这些计算任务。是否可以将总的计算时间降到接近原来的1&#x2F;N呢？答案是不一定。如果掐秒表（正常点的话，应该用7.8节中介绍的Benchmark方法） ，会发现总的执行时间没有明显缩短。再去观察CPU运行状态， 你会发现*尽管我们有16个CPU核心， 但在计算过程中其实只有一个CPU核心处于繁忙状态****，这是会让很多Go语言初学者迷惑的问题。 官方的答案是，这是当前版本的Go编译器还不能很智能地去发现和利用多核的优势。虽然我们确实创建了多个goroutine，并且从运行状态看这些goroutine也都在并行运行，但实际上****所有这些goroutine都运行在同一个CPU核心上， 在一个goroutine得到时间片执行的时候， 其他goroutine都会处于等待状态****。从这一点可以看出，虽然goroutine简化了我们写并行代码的过程，但实际上整体运行效率并不真正高于单线程程序。 在Go语言升级到默认支持多CPU的某个版本之前，我们可以先通过设置环境变量 GOMAXPROCS的值来控制使用多少个CPU核心。具体操作方法是通过直接设置环境变量GOMAXPROCS的值，或者在代码中启动goroutine之前先调用以下这个语句以设置使用16个CPU核心： 1runtime.GOMAXPROCS(16) 到底应该设置多少个CPU核心呢，其实runtime包中还提供了另外一个****函数NumCPU()来获取核心数****。可以看到，Go语言其实已经感知到所有的环境信息，下一版本中完全可以利用这些信息将goroutine调度到所有CPU核心上，从而最大化地利用服务器的多核计算能力。抛弃GOMAXPROCS只是个时间问题。 15、主动出让时间片给其他 goroutine 在未来的某一时刻再来执行当前goroutine我们可以在每个goroutine中控制何时主动出让时间片给其他goroutine，这可以使用****runtime包中的Gosched()函数****实现。实际上，如果要比较精细地控制goroutine的行为，就必须比较深入地了解Go语言开发包中runtime包所提供的具体功能。 16、Go中的同步及同步锁倡导用通信来共享数据，而不是通过共享数据来进行通信，但考虑到即使成功地用channel来作为通信手段，还是****避免不了多个goroutine之间共享数据的问题*，Go语言的设计者虽然对channel有极高的期望，但也提供了妥善的*资源锁方案****。 对于这两种锁类型， 任何一个Lock()或RLock()均需要保证对应有Unlock()或RUnlock()调用与之对应，*否则可能导致等待该锁的*****所有goroutine处于饥饿状态，甚至可能导致死锁****。锁的典型使用模式如下： 1234567var l sync.Mutex func foo() &#123;l.Lock() //延&lt;strong&gt;迟调用 在函数退出 并且局部资源被释放的时候 调用&lt;/strong&gt;defer l.Unlock() //...&#125; 这里我们再一次见证了Go语言defer关键字带来的优雅。 17、全局唯一操作 sync.Once.Do() sync.atomic原子操作子包对于从全局的角度只需要运行一次的代码，比如全局初始化操作，Go语言提供了一个****Once类型来保证全局的唯一性操作****，具体代码如下： 12345678910111213var a stringvar once sync.Once func setup() &#123; a = &quot;hello, world&quot;&#125; func doprint() &#123; once.Do(setup) print(a) &#125; func twoprint() &#123; go doprint() go doprint() &#125; 如果这段代码没有引入Once， setup()将会被每一个goroutine先调用一次， 这至少对于这个例子是多余的。在现实中，我们也经常会遇到这样的情况。Go语言标准库为我们引入了Once类型以解决这个问题。****once的Do()方法可以保证在全局范围内只调用指定的函数一次****（这里指setup()函数），而且所有其他goroutine在调用到此语句时，将会先被阻塞，直至全局唯一的once.Do()调用结束后才继续。 这个机制比较轻巧地解决了使用其他语言时开发者不得不自行设计和实现这种Once效果的难题，也是Go语言为并发性编程做了尽量多考虑的一种体现。 如果没有once.Do()，我们很可能只能添加一个全局的bool变量，在函数setup()的最后一行将该bool变量设置为true。在对setup()的所有调用之前，需要先判断该bool变量是否已经被设置为true，如果该值仍然是false，则调用一次setup()，否则应跳过该语句。实现代码 1234567891011var done bool = falsefunc setup() &#123; a = &quot;hello, world&quot; done = true&#125; func doprint() &#123; if !done &#123; setup() &#125; print(a) &#125; 这段代码初看起来比较合理， 但是细看还是会有问题， 因为****setup()并不是一个原子性操作****，这种写法可能导致setup()函数被多次调用，从而无法达到全局只执行一次的目标。这个问题的复杂性也更加体现了Once类型的价值。 &#x2F;&#x2F;还没有执行到done&#x3D;true的时候 另外调用doprint已经执行起来。 为了更好地控制并行中的原子性操作，sync包中还包含一个atomic子包，它提供了对于一些基础数据类型的原子操作函数，比如下面这个函数： 1func CompareAndSwapUint64(val *uint64, old, new uint64) (swapped bool) 就提供了比较和交换两个uint64类型数据的操作。这让开发者无需再为这样的操作专门添加Lock操作。 转载链接：http://lib.csdn.net/article/53/36140?knId=1441","categories":[{"name":"GOLANG","slug":"GOLANG","permalink":"https://smartxia.github.io/blog/categories/GOLANG/"}],"tags":[]},{"title":"HEXO快捷方式","slug":"建站/建站-HEXO-快捷方式","date":"2020-06-09T06:23:15.000Z","updated":"2024-03-12T03:55:12.899Z","comments":true,"path":"2020/06/09/建站/建站-HEXO-快捷方式/","permalink":"https://smartxia.github.io/blog/2020/06/09/%E5%BB%BA%E7%AB%99/%E5%BB%BA%E7%AB%99-HEXO-%E5%BF%AB%E6%8D%B7%E6%96%B9%E5%BC%8F/","excerpt":"","text":"https://www.jianshu.com/p/1c888a6b8297?utm_source=oschina-app 新编写BLOGhexo new [layout] push到github：hexo deploy hexo clean hexo deploy 每次都要执行 hexo clean 和 hexo deploy，不如写个新的脚本123// package.json&quot;dev&quot;: &quot;hexo s&quot;,&quot;build&quot;: &quot;hexo clean &amp; hexo deploy&quot; npm run build","categories":[{"name":"建站","slug":"建站","permalink":"https://smartxia.github.io/blog/categories/%E5%BB%BA%E7%AB%99/"}],"tags":[]},{"title":"MYSQl索引","slug":"MSYQL/MYSQl-索引","date":"2020-06-09T06:20:36.000Z","updated":"2024-03-12T03:55:12.826Z","comments":true,"path":"2020/06/09/MSYQL/MYSQl-索引/","permalink":"https://smartxia.github.io/blog/2020/06/09/MSYQL/MYSQl-%E7%B4%A2%E5%BC%95/","excerpt":"","text":"docker logs -t -f –tail 100 im4处理init问题 一、查询和更新上的区别这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。建议尽量选择普通索引。1.1 MySQL 的查询操作普通索引查找到第一个满足条件的记录后，继续向后遍历，直到第一个不满足条件的记录。唯一索引由于索引定义了唯一性，查找到第一个满足条件的记录后，直接停止继续检索。普通索引会多检索一次，几乎没有影响。因为 InnoDB 的数据是按照数据页为单位进行读写的，需要读取数据时，并不是直接从磁盘读取记录，而是先把数据页读到内存，再去数据页中检索。一个数据页默认 16 KB，对于整型字段，一个数据页可以放近千个 key，除非要读取的数据在数据页的最后一条记录，就需要再读一个数据页，这种情况很少，对CPU的消耗基本可以忽略了。因此说，在查询数据方面，普通索引和唯一索引没差别。 1.2 MySQL 的更新操作更新操作并不是直接对磁盘中的数据进行更新，是先把数据页从磁盘读入内存，再更新数据页。普通索引将数据页从磁盘读入内存，更新数据页。唯一索引将数据页从磁盘读入内存，判断是否唯一，再更新数据页。由于 MySQL 中有个 change buffer 的机制，会导致普通索引和唯一索引在更新上有一定的区别。change buffer的作用是为了降低IO 操作，避免系统负载过高。change buffer将数据写入数据页的过程，叫做merge。如果需要更新的数据页在内存中时，会直接更新数据页；如果数据不在内存中，会先将更新操作记入change buffer，当下一次读取数据页时，顺带merge到数据页中，change buffer也有定期merge策略。数据库正常关闭的过程中，也会触发merge。对于唯一索引，更新前需要判断数据是否唯一（不能和表中数据重复），如果数据页在内存中，就可以直接判断并且更新，如果不在内存中，就需要去磁盘中读出来，判断一下是否唯一，是的话就更新。change buffer是用不到的。即使数据页不在内存中，还是要读出来。change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。 结论：唯一索引用不了change buffer，只有普通索引可以用。 二、change buffer 和 redo log的区别2.1 change buffer 的适用场景change buffer 的作用是降低更新操作的频率，缓存更新操作。这样会有一个缺点，就是更新不及时，对于读操作比较频繁的表，不建议使用 change buffer。因为更新操作刚记录进change buffer中，就读取了该表，数据页被读到了内存中，数据马上就merge到数据页中了。这样不仅不会降低性能消耗，反而会增加维护change buffer的成本。适用于写多读少的表。 2.2 change buffer 和 redo log 区别我们举一个例子用来理解 redo log 和 change buffer。我们执行以下 SQL 语句：mysql&gt; insert into t(id,k) values(id1,k1),(id2,k2); 假设，(id1,k1) 在数据页 Page 1 中，(id2,k2) 在数据页 Page 2 中。并且 Page 1 在内存中，Page 2 不在内存中。执行过程如下：直接向 Page 1 中写入 (id1,k1)；在change buffer 中记下”向 Page 2 中写入(id2,k2)”这条信息；将以上两个动作记入redo log。做完上面这些，事务就可以完成了。执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的。这条更新语句，涉及了四个部分：内存、redo log（ib_log_fileX）、 数据表空间（t.ibd）、系统表空间（ibdata1）。如果要读数据的话，过程是怎样的？mysql&gt; select * from t where k in (k1, k2); 假设读操作在更新后不久，此时内存中还有 Page 1，没有 Page 2，那么读操作就和 redo log 以及 ibdata1 无关了。从内存中获取到 Page 1 上的最新数据 (id1,k1)；将数据页 Page 2 读入内存，执行merge 操作，此时内存中的 Page 2 也有最新数据(id2,k2)；需要注意的是：redo log中的数据，可能还没有 flush 到磁盘，磁盘中的 Page 1 和 Page 2 中并没有最新数据，但我们依然可以拿到最新数据（内存中的 Page 1 就是最新的，Page 2 虽然不是最新的，但是从磁盘读到内存中后，执行了merge操作，内存中的 Page 2 就是最新的了。）如果此时 MySQL 异常宕机了，比如服务器异常掉电，change buffer 中的数据会不会丢？ change buffer 中的数据分为两部分，一部分是已经merge到ibdata1中的数据，这部分数据已经持久化，不会丢失。另一部分数据，还在 change buffer 中，没有merge 到ibdata1，分 3 种情况： （1）change buffer 写入数据到内存，redo log 也已经写入（ib-log-filex），但是未 commit，binlog中也没有fsync到磁盘，这部分数据会丢失；（2）change buffer 写入数据到内存，redo log 也已经写入（ib-log-filex），但是未 commit，binlog 已写入到磁盘，这部分不会多丢失，异常重启后会先从 binlog 恢复 redo log，再从 redo log 恢复 change buffer；（3）change buffer 写入数据到内存，redo log 和 binlog 都已经fsync，直接从redo log 恢复，不会丢失。redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗 转载自：https://www.cnblogs.com/hhhhuanzi/p/12318504.html","categories":[{"name":"MYSQL","slug":"MYSQL","permalink":"https://smartxia.github.io/blog/categories/MYSQL/"}],"tags":[{"name":"索引","slug":"索引","permalink":"https://smartxia.github.io/blog/tags/%E7%B4%A2%E5%BC%95/"}]},{"title":"MYSQL_排序","slug":"MSYQL/MYSQL-排序","date":"2020-01-20T05:39:46.000Z","updated":"2024-03-12T03:55:12.825Z","comments":true,"path":"2020/01/20/MSYQL/MYSQL-排序/","permalink":"https://smartxia.github.io/blog/2020/01/20/MSYQL/MYSQL-%E6%8E%92%E5%BA%8F/","excerpt":"","text":"","categories":[{"name":"MYSQL","slug":"MYSQL","permalink":"https://smartxia.github.io/blog/categories/MYSQL/"}],"tags":[{"name":"MSYQL","slug":"MSYQL","permalink":"https://smartxia.github.io/blog/tags/MSYQL/"},{"name":"排序","slug":"排序","permalink":"https://smartxia.github.io/blog/tags/%E6%8E%92%E5%BA%8F/"}]},{"title":"日志","slug":"MSYQL/MYSQL-日志","date":"2019-12-27T08:27:05.000Z","updated":"2024-03-12T03:55:12.826Z","comments":true,"path":"2019/12/27/MSYQL/MYSQL-日志/","permalink":"https://smartxia.github.io/blog/2019/12/27/MSYQL/MYSQL-%E6%97%A5%E5%BF%97/","excerpt":"","text":"MYSQL 首先分享一个查看大日志的工具，只有几百k,适合用来实时查看mysql的日志 BareTail","categories":[{"name":"MYSQL","slug":"MYSQL","permalink":"https://smartxia.github.io/blog/categories/MYSQL/"}],"tags":[{"name":"日志","slug":"日志","permalink":"https://smartxia.github.io/blog/tags/%E6%97%A5%E5%BF%97/"},{"name":"工具","slug":"工具","permalink":"https://smartxia.github.io/blog/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"redis基础知识","slug":"REDIS/REDIS-redis基础知识","date":"2019-12-27T03:48:42.000Z","updated":"2024-03-12T03:55:12.869Z","comments":true,"path":"2019/12/27/REDIS/REDIS-redis基础知识/","permalink":"https://smartxia.github.io/blog/2019/12/27/REDIS/REDIS-redis%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","excerpt":"","text":"redis pubsub 发布和订阅常用命令： 查看发布的频道：PUBSUB CHANNELS 新建频道： PUBLISH mychannel “hello world” 订阅频道：SUBSCRIBE mychannel | Psubscribe 多个channel |支持 channel* 格式 退订频道：UNSUBSCRIBE mychannel | Punsubscribe 多个channel |支持 channel* 格式","categories":[{"name":"redis","slug":"redis","permalink":"https://smartxia.github.io/blog/categories/redis/"}],"tags":[{"name":"pubsub","slug":"pubsub","permalink":"https://smartxia.github.io/blog/tags/pubsub/"}]},{"title":"redisTips","slug":"REDIS/REDIS-TIPS","date":"2019-12-27T03:01:49.000Z","updated":"2024-03-12T03:55:12.869Z","comments":true,"path":"2019/12/27/REDIS/REDIS-TIPS/","permalink":"https://smartxia.github.io/blog/2019/12/27/REDIS/REDIS-TIPS/","excerpt":"","text":"概述什么是RedisRedis(Remote Dictionary Server) 是一个使用 C 语言编写的，开源的（BSD许可）高性能非关系型（NoSQL）的键值对数据库。 Redis 可以存储键和五种不同类型的值之间的映射。键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。 与传统数据库不同的是 Redis 的数据是存在内存中的，所以读写速度非常快，因此 redis 被广泛应用于缓存方向，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。另外，Redis 也经常用来做分布式锁。除此之外，Redis 支持事务 、持久化、LUA脚本、LRU驱动事件、多种集群方案。 Redis有哪些优缺点优点 读写性能优异， Redis能读的速度是110000次&#x2F;s，写的速度是81000次&#x2F;s。 支持数据持久化，支持AOF和RDB两种持久化方式。 支持事务，Redis的所有操作都是原子性的，同时Redis还支持对几个操作合并后的原子性执行。 数据结构丰富，除了支持string类型的value外还支持hash、set、zset、list等数据结构。 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离。 缺点 数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。 Redis 不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复。 主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。 Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。 为什么要用 Redis &#x2F;为什么要用缓存主要从“高性能”和“高并发”这两点来看待这个问题。 高性能：假如用户第一次访问数据库中的某些数据。这个过程会比较慢，因为是从硬盘上读取的。将该用户访问的数据存在数缓存中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。如果数据库中的对应数据改变的之后，同步改变缓存中相应的数据即可！ img 高并发：直接操作缓存能够承受的请求是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。 img 为什么要用 Redis 而不用 map&#x2F;guava 做缓存?缓存分为本地缓存和分布式缓存。以 Java 为例，使用自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。 使用 redis 或 memcached 之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。缺点是需要保持 redis 或 memcached服务的高可用，整个程序架构上较为复杂。 Redis为什么这么快1、完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是O(1)； 2、数据结构简单，对数据操作也简单，Redis 中的数据结构是专门进行设计的； 3、采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗； 4、使用多路 I&#x2F;O 复用模型，非阻塞 IO； 5、使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求； 数据类型Redis有哪些数据类型Redis主要有5种数据类型，包括String，List，Set，Zset，Hash，满足大部分的使用要求 Redis的应用场景总结一 计数器 可以对 String 进行自增自减运算，从而实现计数器功能。Redis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。 缓存 将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。 会话缓存 可以使用 Redis 来统一存储多台应用服务器的会话信息。当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。 全页缓存（FPC） 除基本的会话token之外，Redis还提供很简便的FPC平台。以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。此外，对WordPress的用户来说，Pantheon有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。 查找表 例如 DNS 记录就很适合使用 Redis 进行存储。查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。 消息队列(发布&#x2F;订阅功能) List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息。不过最好使用 Kafka、RabbitMQ 等消息中间件。 分布式锁实现 在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。可以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。 其它 Set 可以实现交集、并集等操作，从而实现共同好友等功能。ZSet 可以实现有序性操作，从而实现排行榜等功能。 总结二Redis相比其他缓存，有一个非常大的优势，就是支持多种数据类型。 数据类型说明string字符串，最简单的k-v存储hashhash格式，value为field和value，适合ID-Detail这样的场景。list简单的list，顺序列表，支持首位或者末尾插入数据set无序list，查找速度快，适合交集、并集、差集处理sorted set有序的set 其实，通过上面的数据类型的特性，基本就能想到合适的应用场景了。 如上所述，虽然Redis不像关系数据库那么复杂的数据结构，但是，也能适合很多场景，比一般的缓存数据结构要多。了解每种数据结构适合的业务场景，不仅有利于提升开发效率，也能有效利用Redis的性能。 持久化什么是Redis持久化？持久化就是把内存的数据写到磁盘中去，防止服务宕机了内存数据丢失。 Redis 的持久化机制是什么？各自的优缺点？Redis 提供两种持久化机制 RDB（默认） 和 AOF 机制: RDB：是Redis DataBase缩写快照 RDB是Redis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保存到硬盘中，对应产生的数据文件为dump.rdb。通过配置文件中的save参数来定义快照的周期。 img 优点： 1、只有一个文件 dump.rdb，方便持久化。 2、容灾性好，一个文件可以保存到安全的磁盘。 3、性能最大化，fork 子进程来完成写操作，让主进程继续处理命令，所以是 IO 最大化。使用单独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了 redis 的高性能 4.相对于数据集大时，比 AOF 的启动效率更高。 缺点： 1、数据安全性低。RDB 是间隔一段时间进行持久化，如果持久化之间 redis 发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候) 2、AOF（Append-only file)持久化方式：是指所有的命令行记录以 redis 命令请 求协议的格式完全持久化存储)保存为 aof 文件。 AOF：持久化 AOF持久化(即Append Only File持久化)，则是将Redis执行的每次写命令记录到单独的日志文件中，当重启Redis会重新将持久化的日志中文件恢复数据。 当两种方式同时开启时，数据恢复Redis会优先选择AOF恢复。 img 优点： 1、数据安全，aof 持久化可以配置 appendfsync 属性，有 always，每进行一次 命令操作就记录到 aof 文件中一次。 2、通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof 工具解决数据一致性问题。 3、AOF 机制的 rewrite 模式。AOF 文件没被 rewrite 之前（文件过大时会对命令 进行合并重写），可以删除其中的某些命令（比如误操作的 flushall）) 缺点： 1、AOF 文件比 RDB 文件大，且恢复速度慢。 2、数据集大的时候，比 rdb 启动效率低。 优缺点是什么？ AOF文件比RDB更新频率高，优先使用AOF还原数据。 AOF比RDB更安全也更大 RDB性能比AOF好 如果两个都配了优先加载AOF 如何选择合适的持久化方式 一般来说， 如果想达到足以媲美PostgreSQL的数据安全性，你应该同时使用两种持久化功能。在这种情况下，当 Redis 重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。 如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失，那么你可以只使用RDB持久化。 有很多用户都只使用AOF持久化，但并不推荐这种方式，因为定时生成RDB快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比AOF恢复的速度要快，除此之外，使用RDB还可以避免AOF程序的bug。 如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化方式。 Redis持久化数据和缓存怎么做扩容？ 如果Redis被当做缓存使用，使用一致性哈希实现动态扩容缩容。 如果Redis被当做一个持久化存储使用，必须使用固定的keys-to-nodes映射关系，节点的数量一旦确定不能变化。否则的话(即Redis节点需要动态变化的情况），必须使用可以在运行时进行数据再平衡的一套系统，而当前只有Redis集群可以做到这样。 搜索公众号 Java面试题精选，回复“面试资料”，送你一份Java面试宝典.pdf 过期键的删除策略Redis的过期键的删除策略我们都知道，Redis是key-value数据库，我们可以设置Redis中缓存的key的过期时间。Redis的过期策略就是指当Redis中缓存的key过期了，Redis如何处理。 过期策略通常有以下三种： 定时过期：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。 惰性过期：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。 定期过期：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。(expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。) Redis中同时使用了惰性过期和定期过期两种过期策略。 Redis key的过期时间和永久有效分别怎么设置？EXPIRE和PERSIST命令。 我们知道通过expire来设置key 的过期时间，那么对过期的数据怎么处理呢?除了缓存服务器自带的缓存失效策略之外（Redis默认的有6中策略可供选择），我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种： 定时去清理过期的缓存； 当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。 两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂！具体用哪种方案，大家可以根据自己的应用场景来权衡。 内存相关MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。 Redis的内存淘汰策略有哪些Redis的内存淘汰策略是指在Redis的用于缓存的内存不足时，怎么处理需要新写入且需要申请额外空间的数据。 全局的键空间选择性移除 noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。 allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。（这个是最常用的） allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。 设置过期时间的键空间选择性移除 volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。 volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。 volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。 总结 Redis的内存淘汰策略的选取并不会影响过期的key的处理。内存淘汰策略用于处理内存不足时的需要申请额外空间的数据；过期策略用于处理过期的缓存数据。 Redis主要消耗什么物理资源？内存。 Redis的内存用完了会发生什么？如果达到设置的上限，Redis的写命令会返回错误信息（但是读命令还可以正常返回。）或者你可以配置内存淘汰机制，当Redis达到内存上限时会冲刷掉旧的内容。 Redis如何做内存优化？可以好好利用Hash,list,sorted set,set等集合类型数据，因为通常情况下很多小的Key-Value可以用更紧凑的方式存放到一起。尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key，而是应该把这个用户的所有信息存储到一张散列表里面 线程模型Redis线程模型Redis基于Reactor模式开发了网络事件处理器，这个处理器被称为文件事件处理器（file event handler）。它的组成结构为4部分：多个套接字、IO多路复用程序、文件事件分派器、事件处理器。因为文件事件分派器队列的消费是单线程的，所以Redis才叫单线程模型。 文件事件处理器使用 I&#x2F;O 多路复用（multiplexing）程序来同时监听多个套接字， 并根据套接字目前执行的任务来为套接字关联不同的事件处理器。 当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时， 与操作相对应的文件事件就会产生， 这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。 虽然文件事件处理器以单线程方式运行， 但通过使用 I&#x2F;O 多路复用程序来监听多个套接字， 文件事件处理器既实现了高性能的网络通信模型， 又可以很好地与 redis 服务器中其他同样以单线程方式运行的模块进行对接， 这保持了 Redis 内部单线程设计的简单性。 事务什么是事务？事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。 Redis事务的概念Redis 事务的本质是通过MULTI、EXEC、WATCH等一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。 总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。 搜索公众号 Java面试题精选，回复“面试资料”，送你一份Java面试宝典.pdf Redis事务的三个阶段 事务开始 MULTI 命令入队 事务执行 EXEC 事务执行过程中，如果服务端收到有EXEC、DISCARD、WATCH、MULTI之外的请求，将会把请求放入队列中排 事务管理（ACID）概述 原子性（Atomicity） 原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。 一致性（Consistency） 事务前后数据的完整性必须保持一致。 隔离性（Isolation） 多个事务并发执行时，一个事务的执行不应影响其他事务的执行 持久性（Durability） 持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来即使数据库发生故障也不应该对其有任何影响 Redis的事务总是具有ACID中的一致性和隔离性，其他特性是不支持的。当服务器运行在_AOF_持久化模式下，并且appendfsync选项的值为always时，事务也具有耐久性。 Redis事务支持隔离性吗Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。因此，Redis 的事务是总是带有隔离性的。 Redis事务保证原子性吗，支持回滚吗Redis中，单条命令是原子性执行的，但事务不保证原子性，且没有回滚。事务中任意命令执行失败，其余的命令仍会被执行。 Redis事务其他实现 基于Lua脚本，Redis可以保证脚本内的命令一次性、按顺序地执行，其同时也不提供事务运行错误的回滚，执行过程中如果部分命令运行错误，剩下的命令还是会继续运行完 基于中间标记变量，通过另外的标记变量来标识事务是否执行完成，读取数据时先读取该标记变量判断是否事务执行完成。但这样会需要额外写代码实现，比较繁琐 集群方案哨兵模式 哨兵的介绍 sentinel，中文名是哨兵。哨兵是 redis 集群机构中非常重要的一个组件，主要有以下功能： 集群监控：负责监控 redis master 和 slave 进程是否正常工作。 消息通知：如果某个 redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。 故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。 配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。 哨兵用于实现 redis 集群的高可用，本身也是分布式的，作为一个哨兵集群去运行，互相协同工作。 故障转移时，判断一个 master node 是否宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题。 即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身是单点的，那就很坑爹了。 哨兵的核心知识 哨兵至少需要 3 个实例，来保证自己的健壮性。 哨兵 + redis 主从的部署架构，是不保证数据零丢失的，只能保证 redis 集群的高可用性。 对于哨兵 + redis 主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练。 官方Redis Cluster 方案(服务端路由查询) redis 集群模式的工作原理能说一下么？在集群模式下，redis 的 key 是如何寻址的？分布式寻址都有哪些算法？了解一致性 hash 算法吗？ 简介 Redis Cluster是一种服务端Sharding技术，3.0版本开始正式提供。Redis Cluster并没有使用一致性hash，而是采用slot(槽)的概念，一共分成16384个槽。将请求发送到任意节点，接收到请求的节点会将查询请求发送到正确的节点上执行 方案说明 通过哈希的方式，将数据分片，每个节点均分存储一定哈希槽(哈希值)区间的数据，默认分配了16384 个槽位 每份数据分片会存储在多个互为主从的多节点上 数据写入先写主节点，再同步到从节点(支持配置为阻塞同步) 同一分片多个节点间的数据不保持一致性 读取数据时，当客户端操作的key没有分配在该节点上时，redis会返回转向指令，指向正确的节点 扩容时时需要需要把旧节点的数据迁移一部分到新节点 在 redis cluster 架构下，每个 redis 要放开两个端口号，比如一个是 6379，另外一个就是 加1w 的端口号，比如 16379。 16379 端口号是用来进行节点间通信的，也就是 cluster bus 的东西，cluster bus 的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus 用了另外一种二进制的协议，gossip 协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间。 节点间的内部通信机制 基本通信原理 集群元数据的维护有两种方式：集中式、Gossip 协议。redis cluster 节点间采用 gossip 协议进行通信。 分布式寻址算法 hash 算法（大量缓存重建） 一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡） redis cluster 的 hash slot 算法 优点 无中心架构，支持动态扩容，对业务透明 具备Sentinel的监控和自动Failover(故障转移)能力 客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可 高性能，客户端直连redis服务，免去了proxy代理的损耗 缺点 运维也很复杂，数据迁移需要人工干预 只能使用0号数据库 不支持批量操作(pipeline管道操作) 分布式逻辑和存储模块耦合等 基于客户端分配 简介 Redis Sharding是Redis Cluster出来之前，业界普遍使用的多Redis实例集群方法。其主要思想是采用哈希算法将Redis数据的key进行散列，通过hash函数，特定的key会映射到特定的Redis节点上。Java redis客户端驱动jedis，支持Redis Sharding功能，即ShardedJedis以及结合缓存池的ShardedJedisPool 优点 优势在于非常简单，服务端的Redis实例彼此独立，相互无关联，每个Redis实例像单服务器一样运行，非常容易线性扩展，系统的灵活性很强 缺点 由于sharding处理放到客户端，规模进一步扩大时给运维带来挑战。 客户端sharding不支持动态增删节点。服务端Redis实例群拓扑结构有变化时，每个客户端都需要更新调整。连接不能共享，当应用规模增大时，资源浪费制约优化 基于代理服务器分片 简介 客户端发送请求到一个代理组件，代理解析客户端的数据，并将请求转发至正确的节点，最后将结果回复给客户端 特征 透明接入，业务程序不用关心后端Redis实例，切换成本低 Proxy 的逻辑和存储的逻辑是隔离的 代理层多了一次转发，性能有所损耗 业界开源方案 Twtter开源的Twemproxy 豌豆荚开源的Codis Redis 主从架构单机的 redis，能够承载的 QPS 大概就在上万到几万不等。对于缓存来说，一般都是用来支撑读高并发的。因此架构做成主从(master-slave)架构，一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的读请求全部走从节点。这样也可以很轻松实现水平扩容，支撑读高并发。 redis-master-slave redis replication -&gt; 主从架构 -&gt; 读写分离 -&gt; 水平扩容支撑读高并发 redis replication 的核心机制 redis 采用异步方式复制数据到 slave 节点，不过 redis2.8 开始，slave node 会周期性地确认自己每次复制的数据量； 一个 master node 是可以配置多个 slave node 的； slave node 也可以连接其他的 slave node； slave node 做复制的时候，不会 block master node 的正常工作； slave node 在做复制的时候，也不会 block 对自己的查询操作，它会用旧的数据集来提供服务；但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候就会暂停对外服务了； slave node 主要用来进行横向扩容，做读写分离，扩容的 slave node 可以提高读的吞吐量。 注意，如果采用了主从架构，那么建议必须开启 master node 的持久化，不建议用 slave node 作为 master node 的数据热备，因为那样的话，如果你关掉 master 的持久化，可能在 master 宕机重启的时候数据是空的，然后可能一经过复制， slave node 的数据也丢了。 另外，master 的各种备份方案，也需要做。万一本地的所有文件丢失了，从备份中挑选一份 rdb 去恢复 master，这样才能确保启动的时候，是有数据的，即使采用了后续讲解的高可用机制，slave node 可以自动接管 master node，但也可能 sentinel 还没检测到 master failure，master node 就自动重启了，还是可能导致上面所有的 slave node 数据被清空。 往期面试题汇总：001期~150期汇总 redis 主从复制的核心原理当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。 如果这是 slave node 初次连接到 master node，那么会触发一次 full resynchronization 全量复制。此时 master 会启动一个后台线程，开始生成一份 RDB 快照文件， 同时还会将从客户端 client 新收到的所有写命令缓存在内存中。RDB 文件生成完毕后， master 会将这个 RDB 发送给 slave，slave 会先写入本地磁盘，然后再从本地磁盘加载到内存中， 接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。 slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。 redis-master-slave-replication 过程原理 当从库和主库建立MS关系后，会向主数据库发送SYNC命令 主库接收到SYNC命令后会开始在后台保存快照(RDB持久化过程)，并将期间接收到的写命令缓存起来 当快照完成后，主Redis会将快照文件和所有缓存的写命令发送给从Redis 从Redis接收到后，会载入快照文件并且执行收到的缓存的命令 之后，主Redis每当接收到写命令时就会将命令发送从Redis，从而保证数据的一致 缺点 所有的slave节点数据的复制和同步都由master节点来处理，会照成master节点压力太大，使用主从从结构来解决 Redis集群的主从复制模型是怎样的？为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型，每个节点都会有N-1个复制品 生产环境中的 redis 是怎么部署的？redis cluster，10 台机器，5 台机器部署了 redis 主实例，另外 5 台机器部署了 redis 的从实例，每个主实例挂了一个从实例，5 个节点对外提供读写服务，每个节点的读写高峰qps可能可以达到每秒 5 万，5 台机器最多是 25 万读写请求&#x2F;s。 机器是什么配置？32G 内存+ 8 核 CPU + 1T 磁盘，但是分配给 redis 进程的是10g内存，一般线上生产环境，redis 的内存尽量不要超过 10g，超过 10g 可能会有问题。 5 台机器对外提供读写，一共有 50g 内存。 因为每个主实例都挂了一个从实例，所以是高可用的，任何一个主实例宕机，都会自动故障迁移，redis 从实例会自动变成主实例继续提供读写服务。 你往内存里写的是什么数据？每条数据的大小是多少？商品数据，每条数据是 10kb。100 条数据是 1mb，10 万条数据是 1g。常驻内存的是 200 万条商品数据，占用内存是 20g，仅仅不到总内存的 50%。目前高峰期每秒就是 3500 左右的请求量。 其实大型的公司，会有基础架构的 team 负责缓存集群的运维。 说说Redis哈希槽的概念？Redis集群没有使用一致性hash,而是引入了哈希槽的概念，Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分hash槽。 Redis集群会有写操作丢失吗？为什么？Redis并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可能会丢失写操作。 Redis集群之间是如何复制的？异步复制 Redis集群最大节点个数是多少？16384个 Redis集群如何选择数据库？Redis集群目前无法做数据库选择，默认在0数据库。 分区Redis是单线程的，如何提高多核CPU的利用率？可以在同一个服务器部署多个Redis的实例，并把他们当作不同的服务器来使用，在某些时候，无论如何一个服务器是不够的， 所以，如果你想使用多个CPU，你可以考虑一下分片（shard）。 为什么要做Redis分区？分区可以让Redis管理更大的内存，Redis将可以使用所有机器的内存。如果没有分区，你最多只能使用一台机器的内存。分区使Redis的计算能力通过简单地增加计算机得到成倍提升，Redis的网络带宽也会随着计算机和网卡的增加而成倍增长。 你知道有哪些Redis分区实现方案？ 客户端分区就是在客户端就已经决定数据会被存储到哪个redis节点或者从哪个redis节点读取。大多数客户端已经实现了客户端分区。 代理分区 意味着客户端将请求发送给代理，然后代理决定去哪个节点写数据或者读数据。代理根据分区规则决定请求哪些Redis实例，然后根据Redis的响应结果返回给客户端。redis和memcached的一种代理实现就是Twemproxy 查询路由(Query routing) 的意思是客户端随机地请求任意一个redis实例，然后由Redis将请求转发给正确的Redis节点。Redis Cluster实现了一种混合形式的查询路由，但并不是直接将请求从一个redis节点转发到另一个redis节点，而是在客户端的帮助下直接redirected到正确的redis节点。 Redis分区有什么缺点？ 涉及多个key的操作通常不会被支持。例如你不能对两个集合求交集，因为他们可能被存储到不同的Redis实例（实际上这种情况也有办法，但是不能直接使用交集指令）。 同时操作多个key,则不能使用Redis事务. 分区使用的粒度是key，不能使用一个非常长的排序key存储一个数据集（The partitioning granularity is the key, so it is not possible to shard a dataset with a single huge key like a very big sorted set） 当使用分区的时候，数据处理会非常复杂，例如为了备份你必须从不同的Redis实例和主机同时收集RDB &#x2F; AOF文件。 分区时动态扩容或缩容可能非常复杂。Redis集群在运行时增加或者删除Redis节点，能做到最大程度对用户透明地数据再平衡，但其他一些客户端分区或者代理分区方法则不支持这种特性。然而，有一种预分片的技术也可以较好的解决这个问题。 分布式问题Redis实现分布式锁Redis为单进程单线程模式，采用队列模式将并发访问变成串行访问，且多客户端对Redis的连接并不存在竞争关系Redis中可以使用SETNX命令实现分布式锁。 当且仅当 key 不存在，将 key 的值设为 value。若给定的 key 已经存在，则 SETNX 不做任何动作 SETNX 是『SET if Not eXists』(如果不存在，则 SET)的简写。 返回值：设置成功，返回 1 。设置失败，返回 0 。 img 使用SETNX完成同步锁的流程及事项如下： 使用SETNX命令获取锁，若返回0（key已存在，锁已存在）则获取失败，反之获取成功 为了防止获取锁后程序出现异常，导致其他线程&#x2F;进程调用SETNX命令总是返回0而进入死锁状态，需要为该key设置一个“合理”的过期时间 释放锁，使用DEL命令将锁数据删除 如何解决 Redis 的并发竞争 Key 问题所谓 Redis 的并发竞争 Key 的问题也就是多个系统同时对一个 key 进行操作，但是最后执行的顺序和我们期望的顺序不同，这样也就导致了结果的不同！ 推荐一种方案：分布式锁（zookeeper 和 redis 都可以实现分布式锁）。（如果不存在 Redis 的并发竞争 Key 问题，不要使用分布式锁，这样会影响性能） 基于zookeeper临时有序节点可以实现的分布式锁。大致思想为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。完成业务流程后，删除对应的子节点释放锁。 在实践中，当然是从以可靠性为主。所以首推Zookeeper。 参考：https://www.jianshu.com/p/8bddd381de06 分布式Redis是前期做还是后期规模上来了再做好？为什么？既然Redis是如此的轻量（单实例只使用1M内存），为防止以后的扩容，最好的办法就是一开始就启动较多实例。即便你只有一台服务器，你也可以一开始就让Redis以分布式的方式运行，使用分区，在同一台服务器上启动多个实例。 一开始就多设置几个Redis实例，例如32或者64个实例，对大多数用户来说这操作起来可能比较麻烦，但是从长久来看做这点牺牲是值得的。 这样的话，当你的数据不断增长，需要更多的Redis服务器时，你需要做的就是仅仅将Redis实例从一台服务迁移到另外一台服务器而已（而不用考虑重新分区的问题）。一旦你添加了另一台服务器，你需要将你一半的Redis实例从第一台机器迁移到第二台机器。 什么是 RedLockRedis 官方站提出了一种权威的基于 Redis 实现分布式锁的方式名叫 Redlock，此种方式比原先的单节点的方法更安全。它可以保证以下特性： 安全特性：互斥访问，即永远只有一个 client 能拿到锁 避免死锁：最终 client 都可能拿到锁，不会出现死锁的情况，即使原本锁住某资源的 client crash 了或者出现了网络分区 容错性：只要大部分 Redis 节点存活就可以正常提供服务 往期面试题汇总：001期~150期汇总 缓存异常缓存雪崩缓存雪崩是指缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。 解决方案 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。 一般并发量不是特别多的时候，使用最多的解决方案是加锁排队。 给每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则更新数据缓存。 缓存穿透缓存穿透是指缓存和数据库中都没有的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。 解决方案 接口层增加校验，如用户鉴权校验，id做基础校验，id&lt;&#x3D;0的直接拦截； 从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击 采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力 附加对于空间的利用到达了一种极致，那就是Bitmap和布隆过滤器(Bloom Filter)。 Bitmap：典型的就是哈希表 缺点是，Bitmap对于每个元素只能记录1bit信息，如果还想完成额外的功能，恐怕只能靠牺牲更多的空间、时间来完成了。 布隆过滤器（推荐） 就是引入了k(k&gt;1)k(k&gt;1)个相互独立的哈希函数，保证在给定的空间、误判率下，完成元素判重的过程。 它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。 Bloom-Filter算法的核心思想就是利用多个不同的Hash函数来解决“冲突”。 Hash存在一个冲突（碰撞）的问题，用同一个Hash得到的两个URL的值有可能相同。为了减少冲突，我们可以多引入几个Hash，如果通过其中的一个Hash值我们得出某元素不在集合中，那么该元素肯定不在集合中。只有在所有的Hash函数告诉我们该元素在集合中时，才能确定该元素存在于集合中。这便是Bloom-Filter的基本思想。 Bloom-Filter一般用于在大数据量的集合中判定某元素是否存在。 缓存击穿缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。和缓存雪崩不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。 解决方案 设置热点数据永远不过期。 加互斥锁，互斥锁 缓存预热缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！ 解决方案 直接写个缓存刷新页面，上线时手工操作一下； 数据量不大，可以在项目启动的时候自动进行加载； 定时刷新缓存； 缓存降级当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。 缓存降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。 在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案： 一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级； 警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警； 错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级； 严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。 服务降级的目的，是为了防止Redis服务故障，导致数据库跟着一起发生雪崩问题。因此，对于不重要的缓存数据，可以采取服务降级策略，例如一个比较常见的做法就是，Redis出现问题，不去数据库查询，而是直接返回默认值给用户。 热点数据和冷数据热点数据，缓存才有价值 对于冷数据而言，大部分数据可能还没有再次访问到就已经被挤出内存，不仅占用内存，而且价值不大。频繁修改的数据，看情况考虑使用缓存 对于热点数据，比如我们的某IM产品，生日祝福模块，当天的寿星列表，缓存以后可能读取数十万次。再举个例子，某导航产品，我们将导航信息，缓存以后可能读取数百万次。 数据更新前至少读取两次，缓存才有意义。这个是最基本的策略，如果缓存还没有起作用就失效了，那就没有太大价值了。 那存不存在，修改频率很高，但是又不得不考虑缓存的场景呢？有！比如，这个读取接口对数据库的压力很大，但是又是热点数据，这个时候就需要考虑通过缓存手段，减少数据库的压力，比如我们的某助手产品的，点赞数，收藏数，分享数等是非常典型的热点数据，但是又不断变化，此时就需要将数据同步保存到Redis缓存，减少数据库压力。 缓存热点key缓存中的一个Key(比如一个促销商品)，在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。 解决方案 对缓存查询加锁，如果KEY不存在，就加锁，然后查DB入缓存，然后解锁；其他进程如果发现有锁就等待，然后等解锁后返回数据或者进入DB查询 常用工具Redis支持的Java客户端都有哪些？官方推荐用哪个？Redisson、Jedis、lettuce等等，官方推荐使用Redisson。 Redis和Redisson有什么关系？Redisson是一个高级的分布式协调Redis客服端，能帮助用户在分布式环境中轻松实现一些Java的对象 (Bloom filter, BitSet, Set, SetMultimap, ScoredSortedSet, SortedSet, Map, ConcurrentMap, List, ListMultimap, Queue, BlockingQueue, Deque, BlockingDeque, Semaphore, Lock, ReadWriteLock, AtomicLong, CountDownLatch, Publish &#x2F; Subscribe, HyperLogLog)。 Jedis与Redisson对比有什么优缺点？Jedis是Redis的Java实现的客户端，其API提供了比较全面的Redis命令的支持；Redisson实现了分布式和可扩展的Java数据结构，和Jedis相比，功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等Redis特性。Redisson的宗旨是促进使用者对Redis的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。 往期面试题汇总：001期~150期汇总 其他问题Redis与Memcached的区别两者都是非关系型内存键值数据库，现在公司一般都是用 Redis 来实现缓存，而且 Redis 自身也越来越强大了！Redis 与 Memcached 主要有以下不同： (1) memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型 (2) redis的速度比memcached快很多 (3) redis可以持久化其数据 如何保证缓存与数据库双写时的数据一致性？你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题？ 一般来说，就是如果你的系统不是严格要求缓存+数据库必须一致性的话，缓存可以稍微的跟数据库偶尔有不一致的情况，最好不要做这个方案，读请求和写请求串行化，串到一个内存队列里去，这样就可以保证一定不会出现不一致的情况 串行化之后，就会导致系统的吞吐量会大幅度的降低，用比正常情况下多几倍的机器去支撑线上的一个请求。 还有一种方式就是可能会暂时产生不一致的情况，但是发生的几率特别小，就是先更新数据库，然后再删除缓存。 Redis常见性能问题和解决方案？ Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化。 如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。 为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内。 尽量避免在压力较大的主库上增加从库 Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。 为了Master的稳定性，主从复制不要用图状结构，用单向链表结构更稳定，即主从关系为：Master&lt;–Slave1&lt;–Slave2&lt;–Slave3…，这样的结构也方便解决单点故障问题，实现Slave对Master的替换，也即，如果Master挂了，可以立马启用Slave1做Master，其他不变。 Redis官方为什么不提供Windows版本？因为目前Linux版本已经相当稳定，而且用户量很大，无需开发windows版本，反而会带来兼容性等问题。 一个字符串类型的值能存储最大容量是多少？512M Redis如何做大量数据插入？Redis2.6开始redis-cli支持一种新的被称之为pipe mode的新模式用于执行大量数据插入工作。 假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？使用keys指令可以扫出指定模式的key列表。 对方接着追问：如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？ 这个时候你要回答redis关键的一个特性：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。 使用Redis做过异步队列吗，是如何实现的使用list类型保存数据信息，rpush生产消息，lpop消费消息，当lpop没有消息时，可以sleep一段时间，然后再检查有没有信息，如果不想sleep的话，可以使用blpop, 在没有信息的时候，会一直阻塞，直到信息的到来。redis可以通过pub&#x2F;sub主题订阅模式实现一个生产者，多个消费者，当然也存在一定的缺点，当消费者下线时，生产的消息会丢失。 Redis如何实现延时队列使用sortedset，使用时间戳做score, 消息内容作为key,调用zadd来生产消息，消费者使用zrangbyscore获取n秒之前的数据做轮询处理。 Redis回收进程如何工作的？ 一个客户端运行了新的命令，添加了新的数据。 Redis检查内存使用情况，如果大于maxmemory的限制， 则根据设定好的策略进行回收。 一个新的命令被执行，等等。 所以我们不断地穿越内存限制的边界，通过不断达到边界然后不断地回收回到边界以下。 如果一个命令的结果导致大量内存被使用（例如很大的集合的交集保存到一个新的键），不用多久内存限制就会被这个内存使用量超越。 Redis回收使用的是什么算法？LRU算法 END 来源：thinkwon.blog.csdn.net&#x2F;article&#x2F;details&#x2F;103522351","categories":[{"name":"redis","slug":"redis","permalink":"https://smartxia.github.io/blog/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://smartxia.github.io/blog/tags/redis/"}]},{"title":"redis进阶知识","slug":"REDIS/REDIS-redis进阶知识","date":"2019-12-27T03:01:49.000Z","updated":"2024-03-12T03:55:12.870Z","comments":true,"path":"2019/12/27/REDIS/REDIS-redis进阶知识/","permalink":"https://smartxia.github.io/blog/2019/12/27/REDIS/REDIS-redis%E8%BF%9B%E9%98%B6%E7%9F%A5%E8%AF%86/","excerpt":"","text":"关于redis 一些基本知识点redis基本介绍remote Dictionary Serer (远程字典服务) ANSI C 编写 支持网络 基于内存可持久化的日志型 key&#x3D;&gt;value 数据库 官网 redis.io 作者：Salvatore Sanfilippo 意大利人 网名 antirez redis被使用的原因 传统型关系型数据库如mysql 已经不能适用所有场景，秒杀库存 app首页流量访问高峰 所以考虑缓存中间件，目前市面上比较常用的就是redis 和memcached redis 基本的数据结构String 、字典Hash、列表List、集合Set、有序集合 SortedSet、 HyperLogLog、Geo、Pub&#x2F;Sub BloomFilter 布隆过滤器避免缓存击穿的利器之BloomFilter redis分布式锁-先拿setnx来争抢锁，抢到之后，再用expire给锁加一个过期时间防止锁忘记了释放 redis关键的一个特性：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长 使用Redis做异步队列一般使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候，要适当sleep一会再重试。 list还有个指令叫blpop，在没有消息的时候，它会阻塞住直到消息到来。 实现延时队列使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理。 生产一次消费多次使用pub&#x2F;sub主题订阅者模式，可以实现 1:N 的消息队列 缺点：消费者下线的话 生产者会消失，使用MQ Redis是怎么持久化RDB做镜像全量持久化，AOF做增量持久化。因为RDB会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要AOF来配合使用。在redis实例重启时，会使用RDB持久化文件重新构建内存，再使用AOF重放近期的操作指令来实现完整恢复重启之前的状态。 RDB的原理: fork和cow。fork是指redis通过创建子进程来进行RDB操作，cow指的是copy on write，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。 1这里很好理解，把RDB理解为一整个表全量的数据，AOF理解为每次操作的日志就好了，服务器重启的时候先把表的数据全部搞进去，但是他可能不完整，你再回放一下日志，数据不就完整了嘛。不过Redis本身的机制是 AOF持久化开启且存在AOF文件时，优先加载AOF文件；AOF关闭或者AOF文件不存在时，加载RDB文件；加载AOF/RDB文件城后，Redis启动成功； AOF/RDB文件存在错误时，Redis启动失败并打印错误信息 Pipeline有什么好处可以将多次IO往返的时间缩减为一次，前提是pipeline执行的指令之间没有因果相关性。使用redis-benchmark进行压测的时候可以发现影响redis的QPS峰值的一个重要因素是pipeline批次指令的数目。 Redis的同步机制Redis可以使用主从同步，从从同步。第一次同步时，主节点做一次bgsave，并同时将后续修改操作记录到内存buffer，待完成后将RDB文件全量同步到复制节点，复制节点接受完成后将RDB镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。后续的增量数据通过AOF日志同步即可，有点类似数据库的binlog。","categories":[{"name":"redis","slug":"redis","permalink":"https://smartxia.github.io/blog/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://smartxia.github.io/blog/tags/redis/"}]},{"title":"redis进阶知识","slug":"REDIS/REDIS-redis知识点","date":"2019-12-27T03:01:49.000Z","updated":"2024-03-12T03:55:12.869Z","comments":true,"path":"2019/12/27/REDIS/REDIS-redis知识点/","permalink":"https://smartxia.github.io/blog/2019/12/27/REDIS/REDIS-redis%E7%9F%A5%E8%AF%86%E7%82%B9/","excerpt":"","text":"关于redis 一些基本知识点redis基本介绍remote Dictionary Serer (远程字典服务) ANSI C 编写 支持网络 基于内存可持久化的日志型 key&#x3D;&gt;value 数据库 官网 redis.io 作者：Salvatore Sanfilippo 意大利人 网名 antirez redis被使用的原因 传统型关系型数据库如mysql 已经不能适用所有场景，秒杀库存 app首页流量访问高峰 所以考虑缓存中间件，目前市面上比较常用的就是redis 和memcached redis 基本的数据结构String 、字典Hash、列表List、集合Set、有序集合 SortedSet、 HyperLogLog、Geo、Pub&#x2F;Sub BloomFilter 布隆过滤器避免缓存击穿的利器之BloomFilter redis分布式锁-先拿setnx来争抢锁，抢到之后，再用expire给锁加一个过期时间防止锁忘记了释放 redis关键的一个特性：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长 使用Redis做异步队列一般使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候，要适当sleep一会再重试。 list还有个指令叫blpop，在没有消息的时候，它会阻塞住直到消息到来。 实现延时队列使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理。 生产一次消费多次使用pub&#x2F;sub主题订阅者模式，可以实现 1:N 的消息队列 缺点：消费者下线的话 生产者会消失，使用MQ Redis是怎么持久化RDB做镜像全量持久化，AOF做增量持久化。因为RDB会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要AOF来配合使用。在redis实例重启时，会使用RDB持久化文件重新构建内存，再使用AOF重放近期的操作指令来实现完整恢复重启之前的状态。 RDB的原理: fork和cow。fork是指redis通过创建子进程来进行RDB操作，cow指的是copy on write，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。 1这里很好理解，把RDB理解为一整个表全量的数据，AOF理解为每次操作的日志就好了，服务器重启的时候先把表的数据全部搞进去，但是他可能不完整，你再回放一下日志，数据不就完整了嘛。不过Redis本身的机制是 AOF持久化开启且存在AOF文件时，优先加载AOF文件；AOF关闭或者AOF文件不存在时，加载RDB文件；加载AOF/RDB文件城后，Redis启动成功； AOF/RDB文件存在错误时，Redis启动失败并打印错误信息 Pipeline有什么好处可以将多次IO往返的时间缩减为一次，前提是pipeline执行的指令之间没有因果相关性。使用redis-benchmark进行压测的时候可以发现影响redis的QPS峰值的一个重要因素是pipeline批次指令的数目。 Redis的同步机制Redis可以使用主从同步，从从同步。第一次同步时，主节点做一次bgsave，并同时将后续修改操作记录到内存buffer，待完成后将RDB文件全量同步到复制节点，复制节点接受完成后将RDB镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。后续的增量数据通过AOF日志同步即可，有点类似数据库的binlog。","categories":[{"name":"redis","slug":"redis","permalink":"https://smartxia.github.io/blog/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://smartxia.github.io/blog/tags/redis/"}]},{"title":"HEXO-butteryly","slug":"建站/建站-HEXO-butteryly","date":"2019-12-18T03:20:24.000Z","updated":"2024-03-12T03:55:12.898Z","comments":true,"path":"2019/12/18/建站/建站-HEXO-butteryly/","permalink":"https://smartxia.github.io/blog/2019/12/18/%E5%BB%BA%E7%AB%99/%E5%BB%BA%E7%AB%99-HEXO-butteryly/","excerpt":"","text":"主题·文档https://jerryc.me/ 评论系统gittalkhttps://github.com/settings/applications/1190035登录GitHub进行评论，会生成issueValinehttps://leancloud.cn/dashboard/applist.html#/apps特点在于可以免登陆进行评论，输入验证码评论 Laibili（来必力）域名到期不稳定Disqus暂时未测试使用到期 还是准备用valine做第一期","categories":[{"name":"建站","slug":"建站","permalink":"https://smartxia.github.io/blog/categories/%E5%BB%BA%E7%AB%99/"}],"tags":[{"name":"HEXO","slug":"HEXO","permalink":"https://smartxia.github.io/blog/tags/HEXO/"},{"name":"主题","slug":"主题","permalink":"https://smartxia.github.io/blog/tags/%E4%B8%BB%E9%A2%98/"},{"name":"教程","slug":"教程","permalink":"https://smartxia.github.io/blog/tags/%E6%95%99%E7%A8%8B/"}]},{"title":"词条","slug":"Wiki/计算机基础知识-词条","date":"2019-12-18T02:50:48.000Z","updated":"2024-03-12T03:55:12.896Z","comments":true,"path":"2019/12/18/Wiki/计算机基础知识-词条/","permalink":"https://smartxia.github.io/blog/2019/12/18/Wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E8%AF%8D%E6%9D%A1/","excerpt":"","text":"rss: 简易信息聚合（也叫聚合内容）是一种RSS基于XML标准，在互联网上被广泛采用的内容包装和投递协议。RSS(Really Simple Syndication)是一种描述和同步网站内容的格式，是使用最广泛的XML应用。RSS搭建了信息迅速传播的一个技术平台，使得每个人都成为潜在的信息提供者。发布一个RSS文件后，这个RSS Feed中包含的信息就能直接被其他站点调用，而且由于这些数据都是标准的XML格式，所以也能在其他的终端和服务中使用，是一种描述和同步网站内容的格式。 [1] RSS可以是以下三个解释的其中一个： Really Simple Syndication；RDF (Resource Description Framework) Site Summary； Rich Site Summary。但其实这三个解释都是指同一种Syndication的技术。RSS广泛用于网上新闻频道，blog和wiki，主要的版本有0.91, 1.0, 2.0。使用RSS订阅能更快地获取信息，网站提供RSS输出，有利于让用户获取网站内容的最新更新。网络用户可以在客户端借助于支持RSS的聚合工具软件，在不打开网站内容页面的情况下阅读支持RSS输出的网站内容。","categories":[{"name":"计算机基础知识","slug":"计算机基础知识","permalink":"https://smartxia.github.io/blog/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"wiki","slug":"wiki","permalink":"https://smartxia.github.io/blog/tags/wiki/"}]},{"title":"编码","slug":"Wiki/计算机基础知识-编码","date":"2019-12-17T08:35:07.000Z","updated":"2024-03-12T03:55:12.896Z","comments":true,"path":"2019/12/17/Wiki/计算机基础知识-编码/","permalink":"https://smartxia.github.io/blog/2019/12/17/Wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E7%BC%96%E7%A0%81/","excerpt":"","text":"出现%20 或者%%的问题 http://www.soupan.info/tool/utf-8.php%20&#x2F; 编码空格字符的URL：+或%20？ 当URL中的空格编码为+，什么时候编码到%20? %7C%7C%20 || 按“转换”即可将其转换为UTF-8字符。再按“还原”即可将其还原为简体中文。 【转】utf-8的中文是一个汉字占三个字节长度英文字母和中文汉字在不同字符集编码下的字节数英文字母： 字节数 : 1;编码：GB2312 字节数 : 1;编码：GBK 字节数 : 1;编码：GB18030 字节数 : 1;编码：ISO-8859-1 字节数 : 1;编码：UTF-8 字节数 : 4;编码：UTF-16 字节数 : 2;编码：UTF-16BE 字节数 : 2;编码：UTF-16LE 中文汉字： 字节数 : 2;编码：GB2312 字节数 : 2;编码：GBK 字节数 : 2;编码：GB18030 字节数 : 1;编码：ISO-8859-1 字节数 : 3;编码：UTF-8 字节数 : 4;编码：UTF-16 字节数 : 2;编码：UTF-16BE 字节数 : 2;编码：UTF-16LE 1、美国人首先对其英文字符进行了编码，也就是最早的ascii码，用一个字节的低7位来表示英文的128个字符，高1位统一为0； 2、后来欧洲人发现尼玛你这128位哪够用，比如我高贵的法国人字母上面的还有注音符，这个怎么区分，得，把高1位编进来吧，这样欧洲普遍使用一个全字节进行编码，最多可表示256位。欧美人就是喜欢直来直去，字符少，编码用得位数少； 3、但是即使位数少，不同国家地区用不同的字符编码，虽然0–127表示的符号是一样的，但是128–255这一段的解释完全乱套了，即使2进制完全一样，表示的字符完全不一样，比如135在法语，希伯来语，俄语编码中完全是不同的符号； 4、更麻烦的是，尼玛这电脑高科技传到中国后，中国人发现我们有10万多个汉字，你们欧美这256字塞牙缝都不够。于是就发明了GB2312这些汉字编码，典型的用2个字节来表示绝大部分的常用汉字，最多可以表示65536个汉字字符，这样就不难理解有些汉字你在新华字典里查得到，但是电脑上如果不处理一下你是显示不出来的了吧。 5、这下各用各的字符集编码，这世界咋统一？俄国人发封email给中国人，两边字符集编码不同，尼玛显示都是乱码啊。为了统一，于是就发明了unicode，将世界上所有的符号都纳入其中，每一个符号都给予一个独一无二的编码，现在unicode可以容纳100多万个符号，每个符号的编码都不一样，这下可统一了，所有语言都可以互通，一个网页页面里可以同时显示各国文字。 6、然而，unicode虽然统一了全世界字符的二进制编码，但没有规定如何存储啊，亲。x86和amd体系结构的电脑小端序和大端序都分不清，别提计算机如何识别到底是unicode还是acsii了。如果Unicode统一规定，每个符号用三个或四个字节表示，那么每个英文字母前都必然有二到三个字节是0，文本文件的大小会因此大出二三倍，这对于存储来说是极大的浪费。这样导致一个后果：出现了Unicode的多种存储方式。 7、互联网的兴起，网页上要显示各种字符，必须统一啊，亲。utf-8就是Unicode最重要的实现方式之一。另外还有utf-16、utf-32等。UTF-8不是固定字长编码的，而是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。这是种比较巧妙的设计，如果一个字节的第一位是0，则这个字节单独就是一个字符；如果第一位是1，则连续有多少个1，就表示当前字符占用多少个字节。 8、注意unicode的字符编码和utf-8的存储编码表示是不同的，例如”严”字的Unicode码是4E25，UTF-8编码是E4B8A5，这个7里面解释了的，UTF-8编码不仅考虑了编码，还考虑了存储，E4B8A5是在存储识别编码的基础上塞进了4E25。 9、UTF-8 使用一至四个字节为每个字符编码。128 个 ASCII 字符（Unicode 范围由 U+0000 至 U+007F）只需一个字节，带有变音符号的拉丁文、希腊文、西里尔字母、亚美尼亚语、希伯来文、阿拉伯文、叙利亚文及马尔代夫语（Unicode 范围由 U+0080 至 U+07FF）需要二个字节，其他基本多文种平面（BMP）中的字符（CJK属于此类-Qieqie注）使用三个字节，其他 Unicode 辅助平面的字符使用四字节编码。 10、最后，要回答你的问题，常规来看，中文汉字在utf-8中到底占几个字节，一般是3个字节，最常见的编码方式是1110xxxx 10xxxxxx 10xxxxxx。 知乎解答 https://www.zhihu.com/question/23374078Unicode 是「字符集」UTF-8 是「编码规则」其中：字符集：为每一个「字符」分配一个唯一的 ID（学名为码位 &#x2F; 码点 &#x2F; Code Point）编码规则：将「码位」转换为字节序列的规则（编码&#x2F;解码 可以理解为 加密&#x2F;解密 的过程）广义的 Unicode 是一个标准，定义了一个字符集以及一系列的编码规则，即 Unicode 字符集和UTF-8、UTF-16、UTF-32 等等编码……Unicode 字符集为每一个字符分配一个码位，例如「知」的码位是 30693，记作 U+77E5（30693的十六进制为 0x77E5）。 UTF-8 顾名思义，是一套以 8 位为一个编码单位的可变长编码。会将一个码位编码为 1 到 4 个字节：","categories":[{"name":"计算机基础知识","slug":"计算机基础知识","permalink":"https://smartxia.github.io/blog/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"wiki","slug":"wiki","permalink":"https://smartxia.github.io/blog/tags/wiki/"},{"name":"编码","slug":"编码","permalink":"https://smartxia.github.io/blog/tags/%E7%BC%96%E7%A0%81/"}]},{"title":"Hello World","slug":"建站/建站-HEXO-hello-world","date":"2019-12-16T09:57:11.000Z","updated":"2024-03-12T03:55:12.898Z","comments":true,"path":"2019/12/16/建站/建站-HEXO-hello-world/","permalink":"https://smartxia.github.io/blog/2019/12/16/%E5%BB%BA%E7%AB%99/%E5%BB%BA%E7%AB%99-HEXO-hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[{"name":"建站","slug":"建站","permalink":"https://smartxia.github.io/blog/categories/%E5%BB%BA%E7%AB%99/"}],"tags":[]},{"title":"图片链接","slug":"建站/建站-图片链接","date":"2019-12-16T09:57:11.000Z","updated":"2024-03-12T03:55:12.915Z","comments":true,"path":"2019/12/16/建站/建站-图片链接/","permalink":"https://smartxia.github.io/blog/2019/12/16/%E5%BB%BA%E7%AB%99/%E5%BB%BA%E7%AB%99-%E5%9B%BE%E7%89%87%E9%93%BE%E6%8E%A5/","excerpt":"","text":"github头像地址链接 https://avatars0.githubusercontent.com/u/23631580?s=400&amp;u=8adfff85bef758535f26ec7c91204d21da557643&amp;v=4 微信头像地址 http://s2-cdn.oneitfarm.com/e12ece12233b4059860acf48637d830a.jpg 动态壁纸链接： https://source.unsplash.com/collection/collectionid/1600x900 https://uploadbeta.com/api/pictures/random/?key=BingEverydayWallpaperPicture https://api.dujin.org/bing/1920.php https://api.dujin.org/bing/1366.php blog背景链接：wechat:http://s2-cdn.oneitfarm.com/ec13d36268ae41d7aaf87d5505324b6a.png (迷你版本)http://s2-cdn.oneitfarm.com/fc44dd8d7da4467da3831cd9e6229e19.jpgalipay:http://s2-cdn.oneitfarm.com/2eef3a681187495aa43ff8bbe1173c09.png (迷你版本)http://s2-cdn.oneitfarm.com/96c2b14feb774e49ae2d110bb500770c.jpg 网站默认背景：https://cdn.jsdelivr.net/gh/jerryc127/CDN/img/top_img_index.jpg 文字默认图片：default_cover: https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png 阅读背景：archive_img: https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/Photo/archive.jpg tag背景：tag_img: https://cdn.jsdelivr.net/gh/jerryc127/CDN/img/tag-bg.png 目录背景：category_img: https://cdn.jsdelivr.net/gh/jerryc127/CDN/img/category-bg 如果你有使用hexo-douban去生成movie界面，可配置這個https://cdn.jsdelivr.net/gh/jerryc127/CDN/Photo/movie.jpg 评论背景http://s2-cdn.oneitfarm.com/94f489ea603c42ed854f035fe491222d.png 404背景http://s2-cdn.oneitfarm.com/b09dd72b0fb94cbaab76bdfbb121c4d6.jpgicp背景http://s2-cdn.oneitfarm.com/850aa332dae84b7c8f82f5d0631aa154.png loading 的svghttp://s2-cdn.oneitfarm.com/7ab2d4e7a3a34c81912580725f45c393.svg algolia的svghttp://s2-cdn.oneitfarm.com/0339c65e9ab74f3e919624ed02755dba.svg 私有的bghttps://s2-cdn.oneitfarm.com/92b19077218b48d8b6c1f8726d736c9f.jpg","categories":[{"name":"建站","slug":"建站","permalink":"https://smartxia.github.io/blog/categories/%E5%BB%BA%E7%AB%99/"}],"tags":[{"name":"photo","slug":"photo","permalink":"https://smartxia.github.io/blog/tags/photo/"}]},{"title":"PV,UV","slug":"建站/建站-My-New-Post","date":"2019-12-16T09:57:07.000Z","updated":"2024-03-12T03:55:12.899Z","comments":true,"path":"2019/12/16/建站/建站-My-New-Post/","permalink":"https://smartxia.github.io/blog/2019/12/16/%E5%BB%BA%E7%AB%99/%E5%BB%BA%E7%AB%99-My-New-Post/","excerpt":"","text":"PV：页面访问量，即PageView，用户每次对网站的访问均被记录，用户对同一页面的多次访问，访问量累计。 UV：独立访问用户数：即UniqueVisitor，访问网站的一台电脑客户端为一个访客。00:00-24:00内相同的客户端只被计算一次。","categories":[{"name":"Diary","slug":"Diary","permalink":"https://smartxia.github.io/blog/categories/Diary/"},{"name":"PlayStation","slug":"Diary/PlayStation","permalink":"https://smartxia.github.io/blog/categories/Diary/PlayStation/"},{"name":"Games","slug":"Diary/Games","permalink":"https://smartxia.github.io/blog/categories/Diary/Games/"},{"name":"Life","slug":"Life","permalink":"https://smartxia.github.io/blog/categories/Life/"}],"tags":[]}],"categories":[{"name":"GOLANG","slug":"GOLANG","permalink":"https://smartxia.github.io/blog/categories/GOLANG/"},{"name":"K8S","slug":"K8S","permalink":"https://smartxia.github.io/blog/categories/K8S/"},{"name":"PHP","slug":"PHP","permalink":"https://smartxia.github.io/blog/categories/PHP/"},{"name":"dapr","slug":"dapr","permalink":"https://smartxia.github.io/blog/categories/dapr/"},{"name":"HTTP","slug":"HTTP","permalink":"https://smartxia.github.io/blog/categories/HTTP/"},{"name":"diary","slug":"diary","permalink":"https://smartxia.github.io/blog/categories/diary/"},{"name":"reids","slug":"reids","permalink":"https://smartxia.github.io/blog/categories/reids/"},{"name":"计算机基础知识","slug":"计算机基础知识","permalink":"https://smartxia.github.io/blog/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"regex","slug":"regex","permalink":"https://smartxia.github.io/blog/categories/regex/"},{"name":"其他","slug":"其他","permalink":"https://smartxia.github.io/blog/categories/%E5%85%B6%E4%BB%96/"},{"name":"前端知识","slug":"前端知识","permalink":"https://smartxia.github.io/blog/categories/%E5%89%8D%E7%AB%AF%E7%9F%A5%E8%AF%86/"},{"name":"git","slug":"git","permalink":"https://smartxia.github.io/blog/categories/git/"},{"name":"设计模式","slug":"设计模式","permalink":"https://smartxia.github.io/blog/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"DOCKER","slug":"DOCKER","permalink":"https://smartxia.github.io/blog/categories/DOCKER/"},{"name":"建站","slug":"建站","permalink":"https://smartxia.github.io/blog/categories/%E5%BB%BA%E7%AB%99/"},{"name":"MYSQL","slug":"MYSQL","permalink":"https://smartxia.github.io/blog/categories/MYSQL/"},{"name":"redis","slug":"redis","permalink":"https://smartxia.github.io/blog/categories/redis/"},{"name":"Diary","slug":"Diary","permalink":"https://smartxia.github.io/blog/categories/Diary/"},{"name":"PlayStation","slug":"Diary/PlayStation","permalink":"https://smartxia.github.io/blog/categories/Diary/PlayStation/"},{"name":"Games","slug":"Diary/Games","permalink":"https://smartxia.github.io/blog/categories/Diary/Games/"},{"name":"Life","slug":"Life","permalink":"https://smartxia.github.io/blog/categories/Life/"}],"tags":[{"name":"error.group","slug":"error-group","permalink":"https://smartxia.github.io/blog/tags/error-group/"},{"name":"K8S","slug":"K8S","permalink":"https://smartxia.github.io/blog/tags/K8S/"},{"name":"php","slug":"php","permalink":"https://smartxia.github.io/blog/tags/php/"},{"name":"Slice","slug":"Slice","permalink":"https://smartxia.github.io/blog/tags/Slice/"},{"name":"golang","slug":"golang","permalink":"https://smartxia.github.io/blog/tags/golang/"},{"name":"转义字符","slug":"转义字符","permalink":"https://smartxia.github.io/blog/tags/%E8%BD%AC%E4%B9%89%E5%AD%97%E7%AC%A6/"},{"name":"wiki","slug":"wiki","permalink":"https://smartxia.github.io/blog/tags/wiki/"},{"name":"regex","slug":"regex","permalink":"https://smartxia.github.io/blog/tags/regex/"},{"name":"http://","slug":"http","permalink":"https://smartxia.github.io/blog/tags/http/"},{"name":"https://","slug":"https","permalink":"https://smartxia.github.io/blog/tags/https/"},{"name":"书籍","slug":"书籍","permalink":"https://smartxia.github.io/blog/tags/%E4%B9%A6%E7%B1%8D/"},{"name":"推荐","slug":"推荐","permalink":"https://smartxia.github.io/blog/tags/%E6%8E%A8%E8%8D%90/"},{"name":"设计模式","slug":"设计模式","permalink":"https://smartxia.github.io/blog/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"farmworker","slug":"farmworker","permalink":"https://smartxia.github.io/blog/tags/farmworker/"},{"name":"gin","slug":"gin","permalink":"https://smartxia.github.io/blog/tags/gin/"},{"name":"zap","slug":"zap","permalink":"https://smartxia.github.io/blog/tags/zap/"},{"name":"gox","slug":"gox","permalink":"https://smartxia.github.io/blog/tags/gox/"},{"name":"module","slug":"module","permalink":"https://smartxia.github.io/blog/tags/module/"},{"name":"rpc()","slug":"rpc","permalink":"https://smartxia.github.io/blog/tags/rpc/"},{"name":"Closure","slug":"Closure","permalink":"https://smartxia.github.io/blog/tags/Closure/"},{"name":"匿名函数","slug":"匿名函数","permalink":"https://smartxia.github.io/blog/tags/%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0/"},{"name":"匿名类","slug":"匿名类","permalink":"https://smartxia.github.io/blog/tags/%E5%8C%BF%E5%90%8D%E7%B1%BB/"},{"name":"cgi","slug":"cgi","permalink":"https://smartxia.github.io/blog/tags/cgi/"},{"name":"fastcgi","slug":"fastcgi","permalink":"https://smartxia.github.io/blog/tags/fastcgi/"},{"name":"cli","slug":"cli","permalink":"https://smartxia.github.io/blog/tags/cli/"},{"name":"Generator","slug":"Generator","permalink":"https://smartxia.github.io/blog/tags/Generator/"},{"name":"yield","slug":"yield","permalink":"https://smartxia.github.io/blog/tags/yield/"},{"name":"Iterator - 等待更新","slug":"Iterator-等待更新","permalink":"https://smartxia.github.io/blog/tags/Iterator-%E7%AD%89%E5%BE%85%E6%9B%B4%E6%96%B0/"},{"name":"网易云 server酱 py 云函数  待更新","slug":"网易云-server酱-py-云函数-待更新","permalink":"https://smartxia.github.io/blog/tags/%E7%BD%91%E6%98%93%E4%BA%91-server%E9%85%B1-py-%E4%BA%91%E5%87%BD%E6%95%B0-%E5%BE%85%E6%9B%B4%E6%96%B0/"},{"name":"docekr images","slug":"docekr-images","permalink":"https://smartxia.github.io/blog/tags/docekr-images/"},{"name":"xhprof docker push","slug":"xhprof-docker-push","permalink":"https://smartxia.github.io/blog/tags/xhprof-docker-push/"},{"name":"PHP","slug":"PHP","permalink":"https://smartxia.github.io/blog/tags/PHP/"},{"name":"数据结构","slug":"数据结构","permalink":"https://smartxia.github.io/blog/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"USE","slug":"USE","permalink":"https://smartxia.github.io/blog/tags/USE/"},{"name":"strlen","slug":"strlen","permalink":"https://smartxia.github.io/blog/tags/strlen/"},{"name":"ssr","slug":"ssr","permalink":"https://smartxia.github.io/blog/tags/ssr/"},{"name":"异常","slug":"异常","permalink":"https://smartxia.github.io/blog/tags/%E5%BC%82%E5%B8%B8/"},{"name":"待更新","slug":"待更新","permalink":"https://smartxia.github.io/blog/tags/%E5%BE%85%E6%9B%B4%E6%96%B0/"},{"name":"索引","slug":"索引","permalink":"https://smartxia.github.io/blog/tags/%E7%B4%A2%E5%BC%95/"},{"name":"MSYQL","slug":"MSYQL","permalink":"https://smartxia.github.io/blog/tags/MSYQL/"},{"name":"排序","slug":"排序","permalink":"https://smartxia.github.io/blog/tags/%E6%8E%92%E5%BA%8F/"},{"name":"日志","slug":"日志","permalink":"https://smartxia.github.io/blog/tags/%E6%97%A5%E5%BF%97/"},{"name":"工具","slug":"工具","permalink":"https://smartxia.github.io/blog/tags/%E5%B7%A5%E5%85%B7/"},{"name":"pubsub","slug":"pubsub","permalink":"https://smartxia.github.io/blog/tags/pubsub/"},{"name":"redis","slug":"redis","permalink":"https://smartxia.github.io/blog/tags/redis/"},{"name":"HEXO","slug":"HEXO","permalink":"https://smartxia.github.io/blog/tags/HEXO/"},{"name":"主题","slug":"主题","permalink":"https://smartxia.github.io/blog/tags/%E4%B8%BB%E9%A2%98/"},{"name":"教程","slug":"教程","permalink":"https://smartxia.github.io/blog/tags/%E6%95%99%E7%A8%8B/"},{"name":"编码","slug":"编码","permalink":"https://smartxia.github.io/blog/tags/%E7%BC%96%E7%A0%81/"},{"name":"photo","slug":"photo","permalink":"https://smartxia.github.io/blog/tags/photo/"}]}